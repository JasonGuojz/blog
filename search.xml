<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>Github项目整理</title>
    <url>/blog/2020/08/25/Github%E9%A1%B9%E7%9B%AE%E6%95%B4%E7%90%86/</url>
    <content><![CDATA[<a id="more"></a>
<p><a href="https://github.com/tensorflow/nmt">Neural Machine Translation (seq2seq) Tutorial</a></p>
]]></content>
  </entry>
  <entry>
    <title>windows下NLP任务环境配置教程</title>
    <url>/blog/2020/08/25/pytorch-nlp-env/</url>
    <content><![CDATA[<a id="more"></a>
<h1 id="Table-of-Contents"><a href="#Table-of-Contents" class="headerlink" title="Table of Contents"></a>Table of Contents</h1><details>

<summary><b>Expand Table of Contents</b></summary><blockquote><p align="justify">

- [Table of Contents](#table-of-contents)
  - [pytorch-gpu环境配置](#pytorch-gpu环境配置)

</p></blockquote></details>

<hr>
<h2 id="pytorch-gpu环境配置"><a href="#pytorch-gpu环境配置" class="headerlink" title="pytorch-gpu环境配置"></a>pytorch-gpu环境配置</h2><p><a href="https://blog.csdn.net/qq_27825451/article/details/89082978">各个版本的CUDA以及Cudnn版本对应关系</a><br><a href="https://www.cnblogs.com/yhjoker/p/10972795.html">Pytorch 使用不同本地不同版本的 cuda 进行运行的方法</a><br><a href="https://developer.nvidia.com/cuda-gpus"> NVidia’s site of GPUs that support CUDA </a></p>
<p>CUDA版本向下兼容<br><a href="https://blog.csdn.net/qq_27825451/article/details/89135592">windows下同一个显卡配置多个CUDA工具包以及它们之间的切换</a><br><a href="https://developer.nvidia.com/cudnn">cuDNN download</a><br><a href="https://developer.nvidia.com/cuda-10.2-download-archive?target_os=Linux&amp;target_arch=x86_64&amp;target_distro=Ubuntu&amp;target_version=1804&amp;target_type=deblocal">CUDA Toolkit download</a><br><a href="https://zhuanlan.zhihu.com/p/107683614">win10+CUDA+cuDNN</a><br><a href="https://gsy00517.github.io/anaconda20190913231748/">Anaconda基本操作</a><br><a href="https://www.cnblogs.com/wuliytTaotao/p/11453265.html#%E6%9F%A5%E7%9C%8B-cuda-%E7%89%88%E6%9C%AC">Linux 和 Windows 查看 CUDA 和 cuDNN 版本</a></p>
]]></content>
      <categories>
        <category>Pytorch</category>
      </categories>
      <tags>
        <tag>pytorch</tag>
        <tag>gpu</tag>
      </tags>
  </entry>
  <entry>
    <title>On Calibration of Modern Neural Networks</title>
    <url>/blog/2020/07/30/On%20Calibration%20of%20Modern%20Neural%20Networks/</url>
    <content><![CDATA[<a id="more"></a>
<h3 id="『On-Calibration-of-Modern-Neural-Networks』阅读笔记"><a href="#『On-Calibration-of-Modern-Neural-Networks』阅读笔记" class="headerlink" title="『On Calibration of Modern Neural Networks』阅读笔记"></a>『On Calibration of Modern Neural Networks』阅读笔记</h3><p><a href="https://geoffpleiss.com/nn_calibration">geoffpleiss作者博客</a></p>
<p><a href="https://github.com/gpleiss/temperature_scaling">code</a></p>
<p><strong>方向：</strong></p>
<p>对于 dataset shift 和 out-of-distribution dataset 问题相关的论文，包括了 Temperature scaling [1]，Deep Ensemble [2]，Monte-Carlo Dropout [3] 等方法。而 [4] 在统一的数据集上对上述一系列方法，测试了他们在 data shift 和 out-of-distribution 问题上的 accuracy 和 calibration</p>
<p>[1] Guo, C., Pleiss, G., Sun, Y. and Weinberger, K.Q. On Calibration of Modern Neural Networks. In International Conference on Machine Learning, 2017</p>
<p>[2] Lakshminarayanan, Balaji, Alexander Pritzel, and Charles Blundell. “Simple and scalable predictive uncertainty estimation using deep ensembles.” Advances in neural information processing systems. 2017.</p>
<p>[3] Gal, Y. and Ghahramani, Z. Dropout as a Bayesian approximation: Representing model uncertainty in deep learning. In ICML, 2016</p>
<p>[4] Snoek, Jasper, et al. “Can you trust your model’s uncertainty? Evaluating predictive uncertainty under dataset shift.” Advances in Neural Information Processing Systems. 2019.</p>
<p><a href="https://www.jishuwen.com/d/p402/zh-tw">reference</a></p>
<h3 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h3><p>置信度校准（代表真实正确的可能性 与 预测概率估计值间匹配 的问题）对于许多应用中的分类模型非常重要。 我们发现，与十年前不同的是，现代神经网络的校准效果很差。通过广泛的实验，我们发现深度，宽度，重量衰减和批次归一化是影响校准的重要因素。 我们评估具有图像和文档分类数据集的最新体系结构上各种后处理校准方法的性能。 我们的分析和实验不仅提供了对神经网络学习的见解，而且为实际设置提供了简单明了的方法：在大多数数据集上，温度标定是Platt Scaling的单参数变体，在标定中非常有效 预测</p>
<h3 id="1-Introduction"><a href="#1-Introduction" class="headerlink" title="1. Introduction"></a>1. Introduction</h3><p>在现实世界的决策系统中，分类网络不仅必须准确，而且还应指出何时可能不正确。具体地说，一个网络除了它的预测之外，还应该提供一个校准的置信度a calibrated  confidence——the probability associated with the predicted class label should reflect its ground truth correctness likelihood。良好的置信度估计提供了一个有价值的额外信息来建立用户的可信度，特别是对于神经网络，其分类决策通常很难解释。此外，良好的概率估计可用于将神经网络纳入其他概率模型。例如，可以通过将网络输出与语音识别中的language model相结合 或 带有相机信息相结合以进行物体检测 来 提高检测性能</p>
<p>在2005年，Niculescu-Mizil＆Caruana（2005）表明，神经网络通常会在二元分类任务中产生经过良好校准的概率。 尽管当今的神经网络无疑比十年前更加准确，但我们惊奇地发现现代神经网络已不再经过良好的校准。 这在图1中可视化，在CIFAR-100数据集上比较了5层LeNet（左）（LeCun等，1998）和110层ResNet（右）（He等，2016）。 </p>
<p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/On Calibration of Modern Neural Networks/image-20200808101408889.png" alt="image-20200808101408889"></p>
<p>第一行以直方图的形式显示了the distribution of prediction confidence（即与predicted label相关的概率）.LeNet的平均置信度与其准确度非常匹配，而ResNet的平均置信度实质上高于其准确性。 底部的 reliability diagrams（DeGroot和Fienberg，1983； Niculescu-Mizil和Caruana，2005）进一步说明了这一点，该图显示了准确度作为置信度的函数 accuracy as a function of confidence。 我们可以看到LeNet进行了很好的校准，因为置信度非常接近预期的准确性（即条形图沿对角线大致对齐）。 另一方面，ResNet的准确性更高，但并没有与其置信度相符。</p>
<p> 在本文中，我们演示了几种计算机视觉和NLP任务，即神经网络所产生的置信度不能代表真实的概率。 此外，我们为可能会导致校准错误的网络训练和架构趋势提供了见识和直觉。 最后，我们在最先进的神经网络上比较了各种后处理校准方法，并介绍了我们自己的一些扩展。令人惊讶的是，我们发现了a single-parameter variant of Platt scaling (Platt et al., 1999) – 也就是我们说的 temperature scaling 通常是获得校准过的概率calibrated  probabilities的最有效方法。 由于此方法很容易与现有的深度学习框架一起实施，因此可以在实际环境中轻松采用</p>
<h3 id="2-Definitions"><a href="#2-Definitions" class="headerlink" title="2. Definitions"></a>2. Definitions</h3><p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/On Calibration of Modern Neural Networks/image-20200808105847139.png" alt="image-20200808105847139"></p>
<p>即要求 confidence $\hat{P}$ represents  a  true  probability $p$</p>
<h4 id="Reliability-Diagrams"><a href="#Reliability-Diagrams" class="headerlink" title="Reliability Diagrams"></a>Reliability Diagrams</h4><p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/On Calibration of Modern Neural Networks/image-20200808110558163.png" alt="image-20200808110558163"></p>
<p>对角线 $ y=x$ 表示 perfectly calibrated</p>
<ul>
<li>Confidence <img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/On Calibration of Modern Neural Networks/image-20200808111927786.png" alt="image-20200808111927786"></li>
<li>Sccuracy  <img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/On Calibration of Modern Neural Networks/image-20200808111944989.png" alt="image-20200808111944989"></li>
</ul>
<h4 id="Expected-Calibration-Error-ECE"><a href="#Expected-Calibration-Error-ECE" class="headerlink" title="Expected  Calibration  Error  (ECE)"></a>Expected  Calibration  Error  (ECE)</h4><p>a scalar summary statistic of calibration：</p>
<p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/On Calibration of Modern Neural Networks/image-20200808112247508.png" alt="image-20200808112247508"></p>
<p>即 对每个 bin 做 weighted average 后的结果</p>
<p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/On Calibration of Modern Neural Networks/image-20200808112418276.png" alt="image-20200808112418276"></p>
<h4 id="Maximum-Calibration-Error-MCE"><a href="#Maximum-Calibration-Error-MCE" class="headerlink" title="Maximum Calibration Error (MCE)"></a>Maximum Calibration Error (MCE)</h4><p>估计最大偏差 deviation，is the largest calibration gap。对误差敏感的任务需要评估这个指标</p>
<p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/On Calibration of Modern Neural Networks/image-20200808112801012.png" alt="image-20200808112801012"></p>
<h4 id="Negative-log-likelihood"><a href="#Negative-log-likelihood" class="headerlink" title="Negative log likelihood"></a>Negative log likelihood</h4><h3 id="3-Observing-Miscalibration"><a href="#3-Observing-Miscalibration" class="headerlink" title="3. Observing Miscalibration"></a>3. Observing Miscalibration</h3><p>对改变 <strong>Model capacity</strong>、<strong>Batch Normalization</strong>、<strong>Weight decay</strong>、<strong>NLL</strong> 进行实验</p>
<p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/On Calibration of Modern Neural Networks/image-20200808115442558.png" alt="image-20200808115442558"></p>
<ul>
<li><p><strong>Model capacity</strong></p>
<p>Recent work shows that very deep or wide models are able to generalize better than smaller ones, while exhibiting the capacity to easily fit the training set 越深的网络capacity越大则越容易过拟合。</p>
<p>现象：ECE度量随着模型的容量而显着增长。在训练期间，在模型能够正确（几乎）对所有训练样本进行分类之后，可以通过增加预测的置信度increasing the confidence of predictions来进一步最小化NLL(怎么增加的confidence)。模型容量的增加会降低训练的NLL，因此模型平均而言会更加（过度）自信</p>
</li>
<li><p><strong>Batch Normalization</strong></p>
<p> minimizing <strong>distribution shifts</strong> in activations within the neural network’s hidden  layers</p>
<p>现象：使用批次归一化训练的模型往往tend to be more miscalibrated。 在图2的右中图中，我们看到，即使分类精度稍有提高，但应用批归一化时，六层ConvNet的  calibration 也较差。 我们发现，不管BatchNormalization模型上使用的超参数如何（即低或高学习率等），该结果都成立。</p>
</li>
<li><p><strong>Weight decay</strong></p>
<p>it is now common to train models with <em>little weight decay</em>, if any at all.</p>
<p>测试的时候，正则化的其他形式只有数据增强和 Batch Normalization。</p>
<p>现象：training with less weight decay has a negative impact on calibration</p>
</li>
<li><p><strong>NLL</strong> can  be  used  to  indirectly  measure  model  calibration.</p>
<p>现象：<em>disconnect  between  NLL and accuracy</em>。   Both error and NLL immediately drop at epoch 250, when the learning rate is dropped; however, NLL overfits during the remainder of training.</p>
<p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/On Calibration of Modern Neural Networks/image-20200808142028191.png" alt="image-20200808142028191"></p>
<p><strong>overfitting to NLL is beneficial to classification accuracy.</strong></p>
<p>这一现象给出了 miscalibration错误校准 的具体解释:  网络以牺牲模型良好的概率为代价学习更好的分类精度。</p>
<p>我们可以将这一发现与最近研究大型神经网络泛化的工作联系起来。Zhang等人(2017)观察到，深度神经网络似乎违反了学习理论的普遍理解，即大的模型和少量的正则化将不能很好地泛化。观察到的 NLL 和 0/1损失(分类精度) 之间的断开表明，这些高容量模型不一定不会过拟合，而是，过拟合表现为概率误差probabilistic error 而不是分类误差classification error</p>
</li>
</ul>
<h3 id="4-Calibration-Methods"><a href="#4-Calibration-Methods" class="headerlink" title="4. Calibration Methods"></a>4. Calibration Methods</h3><h4 id="4-1-Calibrating-Binary-Models"><a href="#4-1-Calibrating-Binary-Models" class="headerlink" title="4.1. Calibrating Binary Models"></a>4.1. Calibrating Binary Models</h4><p>符号设置：</p>
<p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/On Calibration of Modern Neural Networks/image-20200808143349676.png" alt="image-20200808143349676"></p>
<h5 id="Histogram-binning"><a href="#Histogram-binning" class="headerlink" title="Histogram binning"></a>Histogram binning</h5><p>对   $\hat{p_i}$  划分区间 $B_m:a_m\le\hat{p_i}\le a_{m+1}$，落在区间内 则 calibrated probability $\hat{q_i} = \theta_m$</p>
<p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/On Calibration of Modern Neural Networks/image-20200808144014272.png" alt="image-20200808144014272"></p>
<h5 id="Isotonic-regression保序回归"><a href="#Isotonic-regression保序回归" class="headerlink" title="Isotonic regression保序回归"></a>Isotonic regression保序回归</h5><p>学习一个分段函数 $f$  来将输出概率映射到校正概率  $\hat{q_i} = f(\hat{p_i})$</p>
<p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/On Calibration of Modern Neural Networks/image-20200808150238811.png" alt="image-20200808150238811"></p>
<h5 id="Bayesian-Binning-into-Quantiles-BBQ"><a href="#Bayesian-Binning-into-Quantiles-BBQ" class="headerlink" title="Bayesian Binning into Quantiles (BBQ)"></a>Bayesian Binning into Quantiles (BBQ)</h5><h5 id="Platt-scaling"><a href="#Platt-scaling" class="headerlink" title="Platt scaling"></a>Platt scaling</h5><p>a parametric approach to  calibration 参数化校正方法，前述均为非参数化</p>
<h4 id="4-2-Extension-to-Multiclass-Models"><a href="#4-2-Extension-to-Multiclass-Models" class="headerlink" title="4.2. Extension to Multiclass Models"></a>4.2. Extension to Multiclass Models</h4><p>对于多分类任务</p>
<h5 id="Extension-of-binning-methods"><a href="#Extension-of-binning-methods" class="headerlink" title="Extension of binning methods"></a>Extension of binning methods</h5><p>解决方法是 treating  the  problem  as K one-versus-all  problems (Zadrozny &amp; Elkan, 2002).</p>
<p> This extension can be applied to histogram binning, isotonic regression, and BBQ</p>
<h5 id="Matrix-and-vector-scaling"><a href="#Matrix-and-vector-scaling" class="headerlink" title="Matrix  and  vector  scaling"></a>Matrix  and  vector  scaling</h5><p>是 Platt scaling 的两种  multi-class  拓展</p>
<p>线性变化，优化目标 改变参数W和b， define vector scaling as a variant where W is restricted to be a diagonal matrix</p>
<p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/On Calibration of Modern Neural Networks/image-20200808152010989.png" alt="image-20200808152010989"></p>
<h5 id="Temperature-scaling"><a href="#Temperature-scaling" class="headerlink" title="Temperature  scaling"></a>Temperature  scaling</h5><p>Platt scaling 的简单拓展，对比上面的方法</p>
<p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/On Calibration of Modern Neural Networks/image-20200808152119969.png" alt="image-20200808152119969"></p>
<p><strong>T</strong> is optimized with respect to NLL(Negative log likelihood) on the validation set.</p>
<p> In other words, temperature scaling <strong>does not affect the model’s accuracy</strong>. 改变的是模型输出的confidence。</p>
<p>常用在 knowledge distillation (Hinton et al., 2015) and statistical mechanics (Jaynes, 1957). </p>
<p>第一次在模型校正使用 calibrating probabilistic models，该模型等价于在对最后logits的约束下对输出概率分布的熵最大化 maximizing the entropy of the output probability distribution subject to certain constraints on the logits</p>
<h3 id="5-Results"><a href="#5-Results" class="headerlink" title="5. Results"></a>5. Results</h3><p> image classification and document classification neural networks</p>
<p><strong>Calibration Results</strong></p>
<p>实验结果发现   <strong>surprising effectiveness of temperature scaling</strong></p>
<p>在视觉任务上优于其他所有方法，并在NLP数据集上与其他方法有竞争力</p>
<p>temperature scaling outperforms the vector and matrix Platt scaling variants, which are strictly more general methods</p>
<p>事实上，vector scaling基本上与temperature scaling的解决方案相同——学习过的向量有几乎恒定的分量，因此与每个分量除以 T 没有区别。换句话说，<strong>网络错误校准本质上是低维的network miscalibration is intrinsically low dimensional</strong>(怎么理解？)</p>
<p>Matrix scaling在有上百个类的数据集(例如鸟、汽车和CIFAR-100)上表现不佳，在1000个类的ImageNet数据集上也无法收敛。这是预期的，因为参数的数量与类的数量平方关系。任何具有数万(或更多)参数的校准模型，即使在应用正则化时，也会对一个小的验证集<strong>过度拟合</strong></p>
<p>Binning methods 可以改善大多数数据集的校准，但不会超过temperature scaling。此外，分类方法往往会改变分类预测，这会损害准确性（请参见第S3节）。Histogram binning, the simplest binning method，尽管实际上这两种方法严格得多，但通常优于保序回归和BBQ。这进一步支持了我们的发现，即通过简单的模型可以最好地校正校准</p>
<h5 id="Reliability-diagrams"><a href="#Reliability-diagrams" class="headerlink" title="Reliability  diagrams."></a>Reliability  diagrams.</h5><p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/On Calibration of Modern Neural Networks/image-20200808161544002.png" alt="image-20200808161544002"></p>
<p>Using a <strong>conjugate gradient solver</strong>, the optimal temperature can be found in 10 iterations, or a fraction of a second on most modern hardware. </p>
<p>即使是optimal temperature的简单行搜索也比其他任何方法都要快。 vector and matrix scaling 的计算复杂度在 number of classes上(N )分别为线性和二次，反映了每种方法中参数对应 number of classes的数量。CIFAR-100 (K= 100)中 寻找一个接近最优的vector scaling  solution 用共轭梯度下降至少需要多2个数量级的时间。Histogram binning and isotonic regression比temperature scaling多一个数量级， BBQ t比temperature scaling多约3个数量级</p>
]]></content>
      <categories>
        <category>Uncertainty in deep learning</category>
        <category>Dataset Shift</category>
        <category>confidence calibration</category>
        <category>Confidence Calibration</category>
      </categories>
      <tags>
        <tag>Temperature scaling</tag>
        <tag>out-of-distribution dataset</tag>
        <tag>dataset shift</tag>
      </tags>
  </entry>
  <entry>
    <title>Dropout as a Bayesian Approximation Representing Model Uncertainty in Deep Learning</title>
    <url>/blog/2020/07/29/Dropout%20as%20a%20Bayesian%20Approximation%20Representing%20Model%20Uncertainty%20in%20Deep%20Learning/</url>
    <content><![CDATA[<a id="more"></a>
<h3 id="『Dropout-as-a-Bayesian-Approximation-Representing-Model-Uncertainty-in-Deep-Learning』阅读笔记"><a href="#『Dropout-as-a-Bayesian-Approximation-Representing-Model-Uncertainty-in-Deep-Learning』阅读笔记" class="headerlink" title="『Dropout as a Bayesian Approximation Representing Model Uncertainty in Deep Learning』阅读笔记"></a>『Dropout as a Bayesian Approximation Representing Model Uncertainty in Deep Learning』阅读笔记</h3><p><a href="http://www.cs.ox.ac.uk/people/yarin.gal/website/blog_3d801aa532c1ce.html#uncertainty-sense">作者博客</a></p>
<p><a href="https://oatml.cs.ox.ac.uk/publications.html">后续工作——Inter-domain Deep Gaussian Processes with RKHS Fourier Features</a></p>
<p><a href="https://zhuanlan.zhihu.com/p/82108924">reference——黄伟zhihu blog</a></p>
<h3 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h3><p><strong>从 Bayesian 角度，解释了 why dropout works</strong>，以及如何对dropout神经网络的不确定性进行建模 。</p>
<p>深度学习工具的回归和分类不能捕捉模型的不确定性。在比较中，贝叶斯模型提供了一个数学基础框架来解释模型的不确定性，但计算成本高。</p>
<p>本文提出了一种新的理论框架，将深度神经网络中的dropout training  as  approximate Bayesian inference in deep Gaussian processes。这一理论的一个直接结果是使用dropout NNs 从现有的模型中提取不确定性。这在不牺牲计算复杂度或测试精度的情况下，减轻了representing uncertainty in deep-learning的问题。我们对dropout uncertainty的性质进行了深入的研究。以MNIST为例，在回归和分类任务上评估了各种网络结构和非线性。我们显示了一个相当大的改进在预测对数似然和RMSE相比前先进的方法，并完成我们的dropout uncertainty在深度强化学习的应用</p>
<h3 id="1-Introduction"><a href="#1-Introduction" class="headerlink" title="1. Introduction"></a>1. Introduction</h3><p>softmax输出不能表示为不确定性，普通模型优化目标得到的是参数的点估计，However, passing the distribution (shaded area 1a) through a softmax (shaded area 1b) better reflects classification uncertainty far from the training data：下图中对训练集外的数据给出预测为class 1，且给出很高的probabiliity值</p>
<p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/Dropout as a Bayesian Approximation Representing Model Uncertainty in Deep Learning/image-20200806232800050.png" alt="image-20200806232800050"></p>
<p>有了<strong>模型置信度</strong>，我们可以显式地处理不确定输入和特殊情况。例如，在分类的情况下，模型可能返回一个具有高不确定性的结果。不确定性在强化学习(RL)中也很重要。有了不确定性信息，agent就可以决定何时利用和何时探索其环境。</p>
<p>贝叶斯概率论为我们提供了基于数学的工具来推断模型的不确定性，但通常伴随着高昂的计算成本。也许令人惊讶的是，在不改变模型或优化的情况下，将最近的深度学习工具转换为贝叶斯模型是可能的。我们表明，在<strong>神经网络中使用dropout(and its variants)可以解释为高斯过程(GP)的概率模型。</strong>在深度学习的许多模型中，Dropout作为一种避免过度拟合的方法被使用，我们的解释表明dropout approximately <strong>integrates</strong> over the models’ weights。我们开发了一些工具来表示现有dropout神经网络的不确定性。</p>
<p>本文<strong>对高斯过程和dropout之间的关系进行了完整的论证，</strong>并开发了表示深度学习中不确定性的必要工具。我们在回归和分类的任务上，对dropout神经网络和卷积神经网路得到的不确定性的性质进行了广泛的探索性评估。本文以MNIST为例，比较了<strong>不同模型体系结构和非线性回归得到的不确定性</strong>，表明<strong>模型不确定性是分类任务不可缺少的</strong>。然后，与SOTA相比，我们在<strong>预测对数似然和RMSE方面显示了相当大的改进</strong>。最后，我们针对类似于深度强化学习的实际任务，<strong>对强化学习设置中的模型不确定性进行了定量评估</strong>。</p>
<h3 id="2-Related-Research"><a href="#2-Related-Research" class="headerlink" title="2. Related Research"></a>2. Related Research</h3><p> <strong>infinitely  wide  (single  hid-den layer) NNs with distributions placed over their weights converge  to  Gaussian  processes  (Neal,  1995;  Williams,1997).</strong>  因为带有 limit极限运算，所以一般研究  finite NNs s with distributions placed over their weights 一般称为 <strong>Bayesian neural networks</strong>，也为过拟合提供了鲁棒性，但<strong>challenging  inference</strong>  and  additional  <strong>computational costs.</strong></p>
<p> 最近的变分推理 <strong>sampling-based variational inference</strong> and <strong>stochastic variational inference</strong> ，这些已经被用来获得贝叶斯神经网络的新近似，表现得和dropout一样好t (Blundell et al.,2015). 然而，这些模型的计算成本高得令人望而却步。为了表示不确定性，对于相同的网络规模，这些模型中的参数数量增加了一倍。此外，它们需要更多的时间来收敛，也没有改进现有的技术。考虑到良好的非确定性估计可以从常见的dropout模型中廉价获得，这可能会导致不必要的额外计算。变分推断的另一种方法利用了 <strong>expectation  propagation</strong>  (Hern ́andez-Lobato  &amp;  Adams,  2015)  ，在RMSE评价和对 VI  approaches的不确定性估计上有很可观的改进。</p>
<h3 id="3-Dropout-as-a-Bayesian-Approximation"><a href="#3-Dropout-as-a-Bayesian-Approximation" class="headerlink" title="3. Dropout as a Bayesian Approximation"></a>3. Dropout as a Bayesian Approximation</h3><p>我们证明了具有任意深度和非线性的神经网络，在每个权重层之前都应用了dropout，在数学上等价于概率深度高斯过程  probabilistic  deep  Gaussian  process的近似(Damianou &amp;Lawrence, 2013)(在其协方差函数参数上的边际分布)。我们想强调的是，在文献中没有对dropout的使用进行简化，并且所推导出的结果适用于任何在实际应用中使用dropout的网络体系结构。此外，我们的结果也与dropout的其他变体相关联(比如drop-connect)，(Wan et al., 2013), multiplicative Gaussian noise (Srivas-tava et al., 2014), etc.). </p>
<p>结果表明，<strong>dropout，实际上，最小化了一个近似分布和一个deep Gaussian process的后验之间的 KL散度</strong> (marginalised over its finite rank covariance function协方差函数 parameters)。</p>
<ul>
<li><h5 id="common-dropout-NN-non-probabilistic-NN"><a href="#common-dropout-NN-non-probabilistic-NN" class="headerlink" title="common dropout NN( non-probabilistic NN)"></a>common dropout NN( non-probabilistic NN)</h5><p>常见的最小化目标公式：</p>
<p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/Dropout as a Bayesian Approximation Representing Model Uncertainty in Deep Learning/image-20200807111630605.png" alt="image-20200807111630605"></p>
<p>使用dropout，我们为每个输入点和每个层中的每个网络单元(除了最后一个)采样伯努利分布变量(为隐层创建一个mask，对每个隐变量为伯努利分布)。</p>
</li>
<li><h5 id="deep-Gaussian-process"><a href="#deep-Gaussian-process" class="headerlink" title="deep Gaussian process"></a>deep Gaussian process</h5><p>用于为新输入预测的公式</p>
<p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/Dropout as a Bayesian Approximation Representing Model Uncertainty in Deep Learning/image-20200807152741325.png" alt="image-20200807152741325"></p>
<p>对于第二项 后验概率，采用变分近似 </p>
<p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/Dropout as a Bayesian Approximation Representing Model Uncertainty in Deep Learning/image-20200807155235695.png" alt="image-20200807155235695"></p>
<p>损失函数 第一项为普通 dropout NN的的最大似然估计损失，第二项为让替代的分布更接近</p>
</li>
</ul>
<p>  应用到高斯过程中：</p>
<p>  参数方法需要推断参数的分布，而在非参数方法中，比如高斯过程，它可以直接推断函数的分布,allows us to model distributions over functions.  假设我们有一个协方差函数(核函数)：</p>
<p>  <img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/Dropout as a Bayesian Approximation Representing Model Uncertainty in Deep Learning/image-20200807114931629.png" alt="image-20200807114931629"></p>
<p>  <img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/Dropout as a Bayesian Approximation Representing Model Uncertainty in Deep Learning/image-20200807144618946.png" alt="image-20200807144618946"></p>
<p>  频谱分析?</p>
<ul>
<li><h5 id="深度高斯过程变分推断"><a href="#深度高斯过程变分推断" class="headerlink" title="深度高斯过程变分推断"></a>深度高斯过程变分推断</h5><p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/Dropout as a Bayesian Approximation Representing Model Uncertainty in Deep Learning/image-20200807163946175.png" alt="image-20200807163946175"></p>
<p>dropoutu NN 中的权重用 伯努利分布作为mask 相乘来建模</p>
<p>推导部分在作者博客中更详细</p>
</li>
</ul>
<blockquote>
<p>详情见作者的博客<a href="http://www.cs.ox.ac.uk/people/yarin.gal/website/blog_3d801aa532c1ce.html#uncertainty-sense"><strong>What My Deep Model Doesn’t Know…中的Why Does It Even Make Sense?</strong></a>·</p>
<p>这个积分用 Monte Carlo integration 蒙特卡洛积分来近似</p>
<p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/Dropout as a Bayesian Approximation Representing Model Uncertainty in Deep Learning/image-20200807152600466.png" alt="image-20200807152600466"></p>
<p>用了重参数化，使得可微：可结合<a href="https://zhuanlan.zhihu.com/p/81170602">nameoverflow的 zhihu blog</a></p>
<p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/Dropout as a Bayesian Approximation Representing Model Uncertainty in Deep Learning/image-20200807160424278.png" alt="image-20200807160424278"></p>
<p>对 $q(W)$ 的形式，给出了一个混合尺度高斯先验（scale mixture gaussian prior）</p>
<p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/Dropout as a Bayesian Approximation Representing Model Uncertainty in Deep Learning/image-20200807160603257.png" alt="image-20200807160603257"></p>
<p>对上面损失函数的第一项做近似，用 w 的一个点估计？蒙特卡洛积分的累加和 1/n抵消</p>
<p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/Dropout as a Bayesian Approximation Representing Model Uncertainty in Deep Learning/image-20200807160755395.png" alt="image-20200807160755395"></p>
<p>scaling 防止 个数越多影响越大？可以证得这是前面损失函数的一个无偏估计，形式上已经可以看出是 dropout NN的经典损失函数形式 (对于回归问题而言)</p>
<p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/Dropout as a Bayesian Approximation Representing Model Uncertainty in Deep Learning/image-20200807160900121.png" alt="image-20200807160900121"></p>
</blockquote>
<p><strong>从 Bayesian 角度，解释了 why dropout works</strong>。与dropout as noise regularization 很相似，approximation 也在引入 noise</p>
<h3 id="4-Obtaining-Model-Uncertainty"><a href="#4-Obtaining-Model-Uncertainty" class="headerlink" title="4. Obtaining Model Uncertainty"></a>4. Obtaining Model Uncertainty</h3><p>对dropout NN 做 T 次前向传播，每次dropout 的权重都不同，数学表达即 T 组 mask：</p>
<p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/Dropout as a Bayesian Approximation Representing Model Uncertainty in Deep Learning/image-20200807165529067.png" alt="image-20200807165529067"></p>
<p>对输出分布做一阶矩估计，求输出分布的期望，采用蒙特卡洛积分：</p>
<p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/Dropout as a Bayesian Approximation Representing Model Uncertainty in Deep Learning/image-20200807165714931.png" alt="image-20200807165714931"></p>
<p>对输出分布做二阶矩估计，同样用蒙特卡洛积分：</p>
<p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/Dropout as a Bayesian Approximation Representing Model Uncertainty in Deep Learning/image-20200807170037550.png" alt="image-20200807170037550"></p>
<p>对输出的不确定性估计，在二阶矩的基础上还要减去一阶矩的平方：</p>
<p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/Dropout as a Bayesian Approximation Representing Model Uncertainty in Deep Learning/image-20200807170124788.png" alt="image-20200807170124788"></p>
<p>​                                                                                      <img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/Dropout as a Bayesian Approximation Representing Model Uncertainty in Deep Learning/image-20200807170131131.png" alt="image-20200807170131131"></p>
<p>Gaussian process precision：</p>
<p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/Dropout as a Bayesian Approximation Representing Model Uncertainty in Deep Learning/image-20200807170803587.png" alt="image-20200807170803587"></p>
<p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/Dropout as a Bayesian Approximation Representing Model Uncertainty in Deep Learning/image-20200807170842588.png" alt="image-20200807170842588"></p>
<p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/Dropout as a Bayesian Approximation Representing Model Uncertainty in Deep Learning/image-20200807171402274.png" alt="image-20200807171402274"></p>
<p>我们的预测分布 $q(y^∗|x^∗)$ 预计是高度多模态的，上面的近似只给出了它的属性的一个粗略的了解。这是因为在每个权重矩阵列上放置的近似变分分布是双模态的，因此在每一层的权重上的联合分配是多模态的(附录3.2节)。注意，dropout NN模型本身并没有改变。为了估计预测均值和预测不确定性，我们简单地收集随机正向通过模型的结果。因此，该信息可以用于现有的基于dropout训练的神经网络模型。此外，向前传播可以同时进行，在恒定的运行时间内完成，与标准 dropout一致</p>
<p><strong>双模态</strong> <strong>多模态</strong>说法可以看： 即 混合高斯先验模型和 dropout 的 伯努利分布 的混合</p>
<p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/Dropout as a Bayesian Approximation Representing Model Uncertainty in Deep Learning/image-20200807172120631.png" alt="image-20200807172120631"></p>
<h3 id="5-Experiments"><a href="#5-Experiments" class="headerlink" title="5. Experiments"></a>5. Experiments</h3><p>接下来，我们在回归和分类的任务上，对从dropout  NNs and convnets 中获得的不确定性估计的性质进行了广泛的评估。以MNIST (LeCun &amp; Cortes, 1998)为例，比较了不同模型体系结构和非线性对分类任务的不确定性，表明模型不确定性对分类任务很重要。然后，我们表明，使用dropout的不确定性，我们可以在预测对数似然和RMSE log-likelihood and RMSE  方面取得相当大的改进，与现有的先进的方法。最后，我们以使用 model’s  uncertainty  in  a  Bayesian  pipeline. </p>
<h5 id="5-1-Model-Uncertainty-in-Regression-Tasks"><a href="#5-1-Model-Uncertainty-in-Regression-Tasks" class="headerlink" title="5.1. Model Uncertainty in Regression Tasks"></a>5.1. Model Uncertainty in Regression Tasks</h5><p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/Dropout as a Bayesian Approximation Representing Model Uncertainty in Deep Learning/image-20200807223933825.png" alt="image-20200807223933825"></p>
<p>蓝色虚线右边是寻来你集外的数据，蓝色阴影部分different shades of blue represent half a standard deviation b、c两图表示模型输出的不确定性，d图输出零附近，也是输出了模型对结果的不确定性。</p>
<p>外推结果如图2所示。模型在训练数据(蓝色虚线的左边)上进行测试，并在整个数据集上进行测试。图2a显示了5层模型的标准dropout(即with weight averaging and without assessing model uncertaint)的结果。图2b显示了用平方指数协方差函数的高斯过程 Gaussian process with a squared exponential covariance function得到的结果。图2c显示了与图2a相同的网络的结果，但是使用了MC dropout来评估训练集和测试集的预测均值和不确定性。最后，图2d使用5层的TanH网络显示了相同的结果(为实现可视化目的，用8倍的标准偏差绘制)。蓝色的阴影表示模型的不确定性:每个颜色梯度colour gradient 表示半个标准偏差( 在预测平均值的正/负总共2个标准偏差内，代表95%的置信度 )。没有绘制的是具有4层的模型，因为它们收敛于相同的结果。</p>
<p>通过对观测数据的外推，没有一个模型可以消除这种周期性(尽管有了合适的covariancefunction，GP可以很好地捕捉到它)。标准的dropout NN模型(图2a)对point $x^∗$(用虚线标记)的值预测为0，具有很高的可信度，尽管这显然不是一个合理的预测。GP模型通过增加其预测的不确定性来表示这一点——实际上宣布预测值可能为0，但模型是不确定的。这种行为也在MC dropout中捕获。即使图2中的模型有一个不正确的预测平均值，增加的标准差表达了模型关于点的不确定性。请注意，ReLU模型的不确定性远远大于数据，而TanH模型的不确定性是有界的。图3。对于mcdropout模型的relnm -linear的Mauna loaco2浓度数据集的预测平均值和不确定性，近似于10个样本。</p>
<p>因为dropout的不确定性来自GP的属性，在GP中，不同的协方差函数对应于不同的不确定性估计。ReLU和TanH近似具有不同的GP协方差函数（附录中的第3.1节），TanH饱和，而ReLU不饱和。对于TanH模型，我们使用dropout概率0.1和dropout概率0.2来评估不确定性。最初以dropout概率0.1初始化的模型显示出的不确定性要比以dropout概率0.2初始化的模型要小，但是当模型converged the uncertainty后，接近优化的末尾几乎无法区分dropout概率的不同。dropout模型的矩收敛到近似GP模型的矩——它的均值和不确定性。值得一提的是，我们尝试将数据与层数较少的模型拟合失败。为进行绘图，用于估计不确定度（T）的正向迭代次数为1000。可以使用更小的数字来对预测平均值和不确定性进行合理估计（例如，图3，T = 10）    </p>
<h5 id="5-2-Model-Uncertainty-in-Classification-Tasks"><a href="#5-2-Model-Uncertainty-in-Classification-Tasks" class="headerlink" title="5.2. Model Uncertainty in Classification Tasks"></a>5.2. Model Uncertainty in Classification Tasks</h5><p>为了评估模型分类的可信度，我们测试了一个在完整MNIST数据集上训练的卷积神经网络(LeCun &amp; Cortes, 1998)。我们训练了LeNet卷积神经网络模型(Le-Cun et al.， 1998)，在最后一个完全连接的内积层(convnets中使用dropout的通常方式)之前使用dropout。dropout概率是0.5。我们使用相同的 learning rate policy训练了10^6个迭代的模型，就像之前使用的一样，使用的是(= 0.0001andp= 0.75)。我们使用Caffe (Jia et al.， 2014)作为本实验的参考实现。</p>
<p>我们用数字1的连续旋转图像(如图4的x轴所示)输入评估了训练后的模型，For the 12 images, the model predicts classes [11 1 1 1 5 5 7 7 7 7 7]</p>
<p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/Dropout as a Bayesian Approximation Representing Model Uncertainty in Deep Learning/image-20200807234027807.png" alt="image-20200807234027807"></p>
<p> if the uncertainty envelopeintersects that of other classes (such as in the case of themiddle input image), then even though the softmax outputcan be arbitrarily high (as far as 1 if the mean is far fromthe means of the other classes), the softmax output uncer-tainty can be as large as the entire space</p>
<h4 id="5-3-Predictive-Performance"><a href="#5-3-Predictive-Performance" class="headerlink" title="5.3. Predictive Performance"></a>5.3. Predictive Performance</h4><p>预测对数似然表示模型拟合数据的程度，数值越大表示模型拟合得越好。不确定性的质量也可以从这个数量来确定(见附录中的4.4节)。我们复制了Herńandez Lobato&amp;Adams（2015）中的实验设置，并比较了RMSE和 predictive  log-likelihood  of dropout （在实验中称为“dropout ”）与概率反向传播 Probabilistic  Back-propagation（称为“PBP”, (Hern ́andez-Lobato &amp; Adams, 2015)到贝叶斯网络中的一种流行的变分推理技术(即“VI”，(Graves, 2011))。本实验的目的是 比较 在 naive 神经网络中应用 dropout 获得的不确定度质量 与 为获取不确定度而开发的专门方法的不确定度质量</p>
<p>根据我们对dropout的贝叶斯解释Bayesian interpretation of dropout(eq.(4))，我们需要定义一个先验的长度尺度，并找到一个optimal模型精度参数<img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/Dropout as a Bayesian Approximation Representing Model Uncertainty in Deep Learning/image-20200807235518120.png" alt="image-20200807235518120">，该参数将允许我们评估预测对数似然(eq.(8))。我们使用Bayesian optimisation  (BO, (Snoek et al., 2012; Snoek &amp; authors,2015))在验证集的log-likelihood to find optimal <img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/Dropout as a Bayesian Approximation Representing Model Uncertainty in Deep Learning/image-20200807235518120.png" alt="image-20200807235518120">，并设置 prior length-scale为 $10^{−2}$的大多数数据集基于数据的范围。请注意，这是一个标准的dropoutNN，其中，具体操作：</p>
<p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/Dropout as a Bayesian Approximation Representing Model Uncertainty in Deep Learning/image-20200807235911802.png" alt="image-20200807235911802"></p>
<h5 id="5-4-Model-Uncertainty-in-Reinforcement-Learning"><a href="#5-4-Model-Uncertainty-in-Reinforcement-Learning" class="headerlink" title="5.4. Model Uncertainty in Reinforcement Learning"></a>5.4. Model Uncertainty in Reinforcement Learning</h5><p>强化学习一个agent从不同的状态得到不同的回报，它的目标是随着时间的推移使其期望的结果最大化。agent试图学会避免掉到rewards小的state，并选择能导致更好的state的action。在这项任务中，不确定性是非常重要的——有了不确定性信息，agent就可以决定何时利用其所知道的奖励，以及何时探索它环境。</p>
<p>最近RL的发展利用NNs来估计 agents’  Q-value  functions（称为Q网络），这种函数可以估计不同行为的质量agent可以采取不同的状态。这导致了在Atari游戏模拟方面取得了令人印象深刻的结果，在这些模拟中，agents 在各种游戏中超过人的表现（Mnih et al.，2015）。在这个集合中使用了Epsilon贪心搜索Epsilon greedy search ，在这个集合中，智能体以一定的概率根据当前的Q函数估计选择最佳动作，否则进行解释。利用dropout  Q-network给出的不确定性估计，我们可以使用诸如康普逊抽样（汤普森，1933）等技术来更快地收敛epsilon greedy并且avoiding over-fitting</p>
<p>我们训练了原始模型，并在每个权重层之前应用了一个概率为0.1的additional  modelwith dropout。注意，为了进行比较，在这个实验中，两个agent使用相同的网络结构。在使用dropout的真实世界场景中，我们将使用一个更大的模型(因为原始模型被有意地选择为较小的以避免过度拟合)。为了利用dropout Q-network的不确定性估计，我们使用Thompson sampling而不是epsilon贪婪。实际上，这意味着每次我们需要采取action时，我们都会执行一个单一的随机正向通过网络 a  single  stochastic  forward  pass 。在回放中，我们执行一个随机正向传递，然后用抽样的伯努利随机变量进行反向传播。在appendix的第E.2节中给出了确切的实验设置</p>
<h3 id="6-Conclusions-and-Future-Research"><a href="#6-Conclusions-and-Future-Research" class="headerlink" title="6. Conclusions and Future Research"></a>6. Conclusions and Future Research</h3>]]></content>
      <categories>
        <category>Uncertainty in deep learning</category>
        <category>Dropout Uncertainty</category>
        <category>Gaussian Processes</category>
      </categories>
      <tags>
        <tag>MC dropout</tag>
        <tag>bi-model</tag>
        <tag>deep Gaussian processes</tag>
      </tags>
  </entry>
  <entry>
    <title>What Uncertainties Do We Need in Bayesian DeepLearning for Computer Vision?</title>
    <url>/blog/2020/07/28/What%20Uncertainties%20Do%20We%20Need%20in%20Bayesian%20DeepLearning%20for%20Computer%20Vision/</url>
    <content><![CDATA[<a id="more"></a>
<h3 id="『What-Uncertainties-Do-We-Need-in-Bayesian-DeepLearning-for-Computer-Vision-』阅读笔记"><a href="#『What-Uncertainties-Do-We-Need-in-Bayesian-DeepLearning-for-Computer-Vision-』阅读笔记" class="headerlink" title="『What Uncertainties Do We Need in Bayesian DeepLearning for Computer Vision?』阅读笔记"></a>『What Uncertainties Do We Need in Bayesian DeepLearning for Computer Vision?』阅读笔记</h3><h3 id="专有名词"><a href="#专有名词" class="headerlink" title="专有名词"></a>专有名词</h3><p>逐像素语义分割 <a href="https://blog.csdn.net/qq_41997920/article/details/96479243">综述解析</a></p>
<h3 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h3><p>可以建模的不确定性有两种主要类型：偶然事件不确定性（Aleatoric Uncertainty）捕获观测中固有的噪声(不可约)。另一方面，模型的不确定性说明了模型中的认知不确定性Epistemic Uncertainty-如果有足够的数据，就可以解释不确定性。传统上，很难对计算机视觉中的认知不确定性进行建模，但是现在有了新的<strong>贝叶斯深度学习工具</strong>，这是可能的。我们研究了在<strong>视觉任务</strong>的贝叶斯深度学习模型中<strong>对认知不确定性（Epistemic Uncertainty）与偶然事件不确定性（Aleatoric Uncertainty）建模</strong>的好处。为此，我们提出了一种贝叶斯深度学习框架，将输入依赖input-dependent的偶然不确定性 与 认知不确定性相结合。我们在具有<strong>逐像素语义分割和深度回归任务的框架下研究模型</strong>。此外，我们明确的不确定性公式 explicit uncertainty formulation  产生这些任务的新损失函数，这可以解释为学习衰减 learned attenuation。这使得损失对噪声数据的鲁棒性更高，还为分割和深度回归基准提供了最新的最新结果。</p>
<h3 id="1-Introduction"><a href="#1-Introduction" class="headerlink" title="1    Introduction"></a>1    Introduction</h3><p>很多机器学习算法可以很好地将高维空间的数据映射成低维数组，但很少考虑这些映射的准确率，从而导致很多灾难性的后果。</p>
<p><strong>计算机视觉</strong>应用程序中的<strong>不确定性量化</strong>可以大致分为诸如<strong>regression</strong> settings such as <strong>depth regression</strong>, and <strong>classification</strong> settings such as <strong>semantic segmentation</strong>。在计算机视觉的这种设置中，对不确定性进行建模的现有方法包括<strong>粒子滤波和条件随机场</strong> particle filtering andconditional random fields。大多数深度学习模型都无法表示不确定性。深度学习在现有的回归设置中不能表示不确定性，深度学习分类模型通常会提供归一化的分数向量，(softmax输出向量)无法捕获模型不确定性。对于这两种设置，都可以使用<strong>贝叶斯深度学习方法</strong>捕获不确定性，这为理解深度学习模型的不确定性提供了实用的框架[6]。</p>
<p>在贝叶斯建模中，可以对模型进行建模的不确定性有两种主要类型[7]。Aleatoric uncertainty，这可能是传感器噪声或运动噪声，从而导致不确定性，即使要<strong>收集更多的数据也无法降低不确定性</strong>。另一方面，epistemic uncertainty 是模型参数中的不确定性——这抓住了我们对哪个模型产生了对我们收集的数据的无知。如果<strong>有足够的数据，就可以解释这种不确定性</strong>，它通常被称为模型不确定性。Aleatoric uncertainty可以进一步分为同方差不确定性：对不同输入保持不变的不确定性和异方差不确定性；异方差不确定性取决于模型的输入，其中一些输入可能比其他输入具有更大的噪声输出。<strong>异方差不确定性对于计算机视觉应用尤其重要</strong>。例如，对于深度回归，具有强烈消失线的高度纹理化的输入图像预期会产生不自信的预测，而像无明显特征的墙 作为输入图像，预期会有非常高的不确定性</p>
<p>在本文中，我们观察到在许多<strong>大数据体系中(比如那些与图像数据有关的深度学习的体系)，建模偶然不确定性aleatoric uncertainty是最有效的</strong>——这类不确定性是不能被解释的。这是与认知的不确定性相比较，而认知的不确定性通常可以用机器视觉中大量的数据来解释。我们进一步证明建模 aleatoric uncertainty 是有代价的。数据外的例子，可以用epistemic uncertainty识别，不能单独用 aleatoric uncertainty 识别。</p>
<p>为此，我们提出了一个统一的贝叶斯深度学习框架，它允许我们从输入数据 映射到 aleatoric uncertainty，并将这些与epistemic uncertainty的估计组合在一起。我们推导了回归和分类应用的框架，并给出了逐像素深度回归和语义分割任务的结果(示例见图1和补充视频)。我们展示了如何在回归任务中建模aleatoric uncertainty，并可用于学习loss attenuation，并发展一个互补的方法为分类情况。这表明了我们处理困难和大规模任务的方法的有效性</p>
<h4 id="贡献"><a href="#贡献" class="headerlink" title="贡献"></a>贡献</h4><ol>
<li>capture an accurate understanding of aleatoric and epistemic uncertainties, in particular with a novel approach for classification</li>
<li>通过减少噪声数据的影响，在非贝叶斯基线上提高模型性能1 - 3%，从明确表示偶然不确定性  explicitly  representing aleatoric uncertainty 获得的隐含衰减  implied  attenuation</li>
<li>我们通过刻画每个不确定性的性质并比较模型的性能和推理时间来研究建模  aleatoric or epistemic uncertainty  之间的权衡</li>
</ol>
<h3 id="2-Related-Work"><a href="#2-Related-Work" class="headerlink" title="2    Related Work"></a>2    Related Work</h3><p><strong>现有的贝叶斯深度学习方法要么只捕捉认知不确定性，要么只捕捉偶然不确定性[6]。</strong>这些不确定性分别被表示为模型参数的概率分布或模型输出的概率分布。认知的不确定性是通过在模型的权重上放置一个先验分布来建模的，然后尝试捕捉给定一些数据的权重变化的多少。另一方面，偶然不确定性是通过 by placing a distribution over the output of the mode来建模的。<strong>例如，在回归中，我们的输出可能被建模为带有高斯随机噪声的</strong>。在这种情况下，我们感兴趣的是学习噪声的方差作为不同输入的函数(这种噪声也可以为所有数据点建模为一个常数值，但这没有意义)。这些不确定性，在贝叶斯深入的背景下，将在本节更详细地解释</p>
<h4 id="2-1-Epistemic-Uncertainty-in-Bayesian-Deep-Learning认知不确定性建模"><a href="#2-1-Epistemic-Uncertainty-in-Bayesian-Deep-Learning认知不确定性建模" class="headerlink" title="2.1    Epistemic Uncertainty in Bayesian Deep Learning认知不确定性建模"></a>2.1    Epistemic Uncertainty in Bayesian Deep Learning认知不确定性建模</h4><p><a href="https://blog.csdn.net/weixin_39779106/article/details/78968982">Reference—Xieyuanli_Chen 的 cnblog</a></p>
<p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/What Uncertainties Do We Need in Bayesian DeepLearning for Computer Vision/image-20200805225714888.png" alt="image-20200805225714888" style="zoom:80%;" /></p>
<p>为模型参数分布建模，$P(W|X,Y)$，通常通过网络模型参数的概率分布来研究认知不确定性，首先通过将先验分布置于模型的权重上进行建模，然后尝试计算这些权重随着数据变化的规律</p>
<p>在分类问题中，预测不确定性可以利用蒙特卡洛积分来近似</p>
<p>在回归问题中，这一认知不确定性可以通过预测方差来进行计算</p>
<h4 id="2-2-Heteroscedastic-Aleatoric-Uncertainty异方差偶然不确定性计算"><a href="#2-2-Heteroscedastic-Aleatoric-Uncertainty异方差偶然不确定性计算" class="headerlink" title="2.2    Heteroscedastic Aleatoric Uncertainty异方差偶然不确定性计算"></a>2.2    Heteroscedastic Aleatoric Uncertainty异方差偶然不确定性计算</h4><p><a href="https://blog.csdn.net/weixin_39779106/article/details/78968982">Reference—cnblog</a></p>
<p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/What Uncertainties Do We Need in Bayesian DeepLearning for Computer Vision/image-20200805225410026.png" alt="image-20200805225410026" style="zoom:80%;" /></p>
<p>MAP推断</p>
<p>研究网络输出来研究偶然不确定性，通常是对模型的输出进行拟合。例如在回归问题中，我们可以把输出建模为随着高斯随机噪声而衰减</p>
<p>计算回归问题中的偶然不确定性，我们需要对观测噪声参数 $\sigma$ 进行调整，计算异方差偶然不确定性，认为噪声的方差是不同输入的函数。</p>
<h3 id="3-Combining-Aleatoric-and-Epistemic-Uncertainty-in-One-Model"><a href="#3-Combining-Aleatoric-and-Epistemic-Uncertainty-in-One-Model" class="headerlink" title="3    Combining Aleatoric and Epistemic Uncertainty in One Model"></a>3    Combining Aleatoric and Epistemic Uncertainty in One Model</h3><p>我们开发的模型将允许我们研究单独建模偶然不确定性、单独建模认知不确定性或在单个模型中同时建模这两个不确定性的影响。接着观察到回归任务中的偶然不确定性可以解释为学习损失衰减loss attenuation，这使得损失对噪声数据更加稳健。我们将<strong>异方差回归的思想扩展到分类任</strong>务。这也使我们能够了解分类任务的损耗衰减loss attenuation</p>
<h4 id="3-1-Combining-Heteroscedastic-Aleatoric-Uncertainty-and-Epistemic-Uncertainty"><a href="#3-1-Combining-Heteroscedastic-Aleatoric-Uncertainty-and-Epistemic-Uncertainty" class="headerlink" title="3.1    Combining Heteroscedastic Aleatoric Uncertainty and Epistemic Uncertainty"></a>3.1    Combining Heteroscedastic Aleatoric Uncertainty and Epistemic Uncertainty</h4><p>为了同时捕捉认知和任意的不确定性，将§2.2中的异方差神经网络转换为贝叶斯神经网络，方法是将分布置于其权重之上。</p>
<p>我们需要推断一个BNN模型 $f$ 的后验分布，它将输入图像 x 映射到非随机输出<img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/What Uncertainties Do We Need in Bayesian DeepLearning for Computer Vision/image-20200805201612316.png" alt="image-20200805201612316" style="zoom:80%;" />，以及输出方差 $σ^2$ 给出的偶然不确定度的度量。我们使用 §2.1 中的公式，用一个 <strong>dropout变分分布</strong> 来近似BNN模型 $f$ 的后验分布。</p>
<p>结合BNN网络的随机输出分布的均值和方差：<img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/What Uncertainties Do We Need in Bayesian DeepLearning for Computer Vision/image-20200805224525673.png" alt="image-20200805224525673" style="zoom:80%;" /></p>
<p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/What Uncertainties Do We Need in Bayesian DeepLearning for Computer Vision/image-20200805224759550.png" alt="image-20200805224759550" style="zoom:80%;" /></p>
<p>公式(第一张按照#2.1公式，第二张按照#3公式，两者一致，体现在权重表示为分布形式)：</p>
<p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/What Uncertainties Do We Need in Bayesian DeepLearning for Computer Vision/image-20200805225626828.png" alt="image-20200805225626828" style="zoom:80%;" /></p>
<p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/What Uncertainties Do We Need in Bayesian DeepLearning for Computer Vision/image-20200805234050251.png" alt="image-20200805234050251" style="zoom:80%;" /></p>
<p>建模偶然不确定性，第二项正则项防止第一项中的方差取极大：</p>
<p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/What Uncertainties Do We Need in Bayesian DeepLearning for Computer Vision/image-20200805225859353.png" alt="image-20200805225859353" style="zoom:80%;" /></p>
<p>加个对数避免了第一项除以零的数值不稳定性，</p>
<p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/What Uncertainties Do We Need in Bayesian DeepLearning for Computer Vision/image-20200805231547566.png" alt="image-20200805231547566"></p>
<p>combine 体现在将 #2.2 中 $f$ 固定的权重改成 概率分布，噪声方差的计算不同</p>
<h4 id="3-2-Heteroscedastic-Uncertainty-as-Learned-Loss-Attenuation"><a href="#3-2-Heteroscedastic-Uncertainty-as-Learned-Loss-Attenuation" class="headerlink" title="3.2    Heteroscedastic Uncertainty as Learned Loss Attenuation"></a>3.2    Heteroscedastic Uncertainty as Learned Loss Attenuation</h4><p>我们发现允许网络预测不确定性使得其可以通过 $exp(−s_i)$ 有效地减少损失残差(不确定性大时，会迫使第一项中的残差项减小)。这一行为与一个智能鲁棒的回归函数是类似的，它允许网络适应残差的权重，甚至允许网络学习<strong>减弱 错误标签 的影响</strong> (错误标签，高不确定性为小权重)，这使得模型对噪声的鲁棒性增强：针对预测出高不确定性的输入，模型将对损失函数产生较小的影响。</p>
<p>这一模型不鼓励对所有的输入产生高不确定性——通过 $logσ^2$ 的形式实现 (<strong>正则项</strong>) ——因为会使得模型忽略这些输入。因此当高不确定性输入很多时将会对模型进行惩罚——即允许模型学会忽略数据，但会对其做出惩罚。这一模型同样不鼓励预测出不确定性低但残差高的结果，因为低 $\sigma^2$ 值会过于扩大残差的影响，同样会对模型进行惩罚。这种学习衰减不是一种特殊设计的结构，而是模型概率解释的结果——通过加正则项，以及建模出两个因素间的trade off来实现 Loss Attenuation</p>
<h4 id="3-3-Heteroscedastic-Uncertainty-in-Classification-Tasks"><a href="#3-3-Heteroscedastic-Uncertainty-in-Classification-Tasks" class="headerlink" title="3.3    Heteroscedastic Uncertainty in Classification Tasks"></a>3.3    Heteroscedastic Uncertainty in Classification Tasks</h4><p>分类中的异方差神经网络是一种特殊的分类模型，因为从技术上讲，任何分类任务都具有输入依赖的不确定性</p>
<ol>
<li><p>在分类问题中，NN将会对每一个像素 $i$ 预测一个一元数组 $f_i$，当经过一个softmax运算后将形成一个概率数组 $p_i$</p>
</li>
<li><p>We change the model by placing a Gaussian distribution over the unaries vector $f_i$ 把对每个 pixel $i$ 的unary vector $f_i$ 用一个 高斯分布随机变量替代：</p>
<p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/What Uncertainties Do We Need in Bayesian DeepLearning for Computer Vision/image-20200806113531761.png" alt="image-20200806113531761" style="zoom:80%;" /></p>
<p>每个 $f_i$ indexed by i 都被注入了 方差为 $\sigma^W_i$ 的高斯噪声，即 Heteroscedastic Uncertainty </p>
</li>
<li><p>新模型的损失函数：对数似然</p>
<p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/What Uncertainties Do We Need in Bayesian DeepLearning for Computer Vision/image-20200806114448947.png" alt="image-20200806114448947" style="zoom:80%;" /></p>
<p>求这个期望的时候，我们想将这个高斯分布解析地积分出来，但是没有解析解是已知的。我们采用<strong>蒙特卡洛积分</strong>来近似目标，sample unaries through the softmax function.。我们注意到这个操作是非常快的，因为我们只执行一次计算（将输入经过一次模型便可计算得到对数值）。我们只需要对softmax的输出进行抽样，这只是整个网络计算整体的一部分，因此并不会增加测试时的计算时间。因此数值稳定的损失函数如下所示，</p>
<p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/What Uncertainties Do We Need in Bayesian DeepLearning for Computer Vision/image-20200806195558780.png" alt="image-20200806195558780" style="zoom:80%;" /></p>
<p>这个损失函数形式变化，参考<a href="https://zhuanlan.zhihu.com/p/81170602">nameoverflow——Bayesian Neural Networks：贝叶斯神经网络</a>，使得可以应用现有的优化方式</p>
<p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/What Uncertainties Do We Need in Bayesian DeepLearning for Computer Vision/image-20200806195540457.png" alt="image-20200806195540457" style="zoom:80%;" /></p>
</li>
</ol>
<h3 id="4-Experiments"><a href="#4-Experiments" class="headerlink" title="4    Experiments"></a>4    Experiments</h3><p>本文在像素级的深度回归和语义分割问题上对所提出的模型进行了测试。为了展示本文所提出的可以学习的损失衰减的鲁棒性（对不确定性建模的好处之一），我们在CamVid, Make3D和NYUv2 Depth数据集上进行了测试，并取得了目前最好的性能。在实验中，我们利用了DenseNet的框架（用于深度回归问题），并对其稍微进行了改进（在CamVid上进行测试比改进前的性能提高了0.2%）。在所有的实验中，我们将训练图像裁剪成224x224，batch的大小为4，然后利用全尺寸图进行精调，batch大小为1，采用RMS-Prop优化方法，学习率为0.001，权值衰减率为10−410−4。我们<strong>利用蒙特卡洛dropout来对认知不确定性进行建模</strong>，DenseNet框架中采用的dropout概率为 $p=0.2$ ，在每一个卷积层后使用，本文中我们使用50个蒙特卡洛dropout采样。我们利用<strong>上文提到的损失函数进行 MAP推断 从而对偶然不确定性进行建模</strong>。在实际实验过程中，我们采用的是拉普拉斯先验(L1)而不是高斯先验(L2)，因为其采用的L1距离描述残差比高斯采用的L2距离更适合视觉回归问题</p>
<h4 id="4-1-Semantic-Segmentation"><a href="#4-1-Semantic-Segmentation" class="headerlink" title="4.1    Semantic Segmentation"></a>4.1    Semantic Segmentation</h4><p>在此实验中，我们采用了CamVid和NYUv2数据集，其中CamVid是道路场景数据集包含367张训练图片以及233张测试图片，11个类别,实验结果如表一a所示，可以看出偶然不确定性对性能影响更大，结合两种不确定时系统性能最佳。NYUv2数据集是一个具有挑战的室内分类数据集，包含40中语义类别，实验结果如表一b所示。</p>
<p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/What Uncertainties Do We Need in Bayesian DeepLearning for Computer Vision/image-20200806201357626.png" alt="image-20200806201357626" style="zoom:80%;" /></p>
<p>mean intersection over union (IoU) score 显示：this application it is <strong>more important to model aleatoric uncertainty</strong>, suggesting that <strong>epistemic uncertainty can be mostly explained away in this large data setting.</strong></p>
<h4 id="4-2-Pixel-wise-Depth-Regression"><a href="#4-2-Pixel-wise-Depth-Regression" class="headerlink" title="4.2    Pixel-wise Depth Regression"></a>4.2    Pixel-wise Depth Regression</h4><p>在此实验中，我们采用了Make3D和NYUv2 Depth数据集，实验结果如表二所示，结果表明<strong>偶然不确定在此类问题中发挥了很大作用</strong>，如图五、图六所示，在图像深度较深，反射表面以及遮挡边界处large depths, reflective surfaces and occlusion boundaries in the image的偶然不确定性值很大，这些地方往往是单目深度算法容易失败的地方。<strong>反观由于数据量太少，认知不确定很难发挥大作用。</strong>总的来说，我们通过直接学习系统噪声和复杂概念的衰减从而提高了非贝叶斯网络的性能，例如我们观察到遥远物体和物体和遮挡边界的偶然不确定性是比较高的。</p>
<h3 id="5-Analysis-What-Do-Aleatoric-and-Epistemic-Uncertainties-Capture"><a href="#5-Analysis-What-Do-Aleatoric-and-Epistemic-Uncertainties-Capture" class="headerlink" title="5    Analysis: What Do Aleatoric and Epistemic Uncertainties Capture?"></a>5    Analysis: What Do Aleatoric and Epistemic Uncertainties Capture?</h3><p>在这一节中，我们希望研究建模偶然和认知的不确定性的有效性。特别地，我们希望量化这些不确定度测量的性能，并分析它们捕获了什么</p>
<h4 id="5-1-Quality-of-Uncertainty-Metric"><a href="#5-1-Quality-of-Uncertainty-Metric" class="headerlink" title="5.1    Quality of Uncertainty Metric"></a>5.1    Quality of Uncertainty Metric</h4><p>在图二中我们给出了回归问题和分类问题的PR曲线，PR曲线说明了我们的模型性能可以通过消除不确定性大于方差阈值的像素来提高。这表示了不确定性的两种行为，一是不确定性测量与精度是相关的，因为所有曲线都是严格递减函数，当模型有更多不确定的点时，精度会降低；二是两种不确定性的曲线是相似的，在没有其他不确定性的情况下，每个不确定性对像素置信度的排序与其他不确定性相似，即使当只有一个不确定性能被建模时，它会在一定程度上弥补另一不确定性</p>
<p>在图三中我们用我们模型在测试集上的校准图分析不确定性度量。对于分类问题而言，我们通过将我们模型预测的概率离散化成一些数，然后画出正确预测的标注的频率对应的数，不确定性质量越高的预测应该与$y=x$更加接近。对于回归问题而言，我们可以通过比较预测分布的变化阈值内的残差频率来形成校准图we can form calibration plots by comparing the frequency of residuals lying within varying thresholds of the predicted distribution. </p>
<h4 id="5-2-Uncertainty-with-Distance-from-Training-Data"><a href="#5-2-Uncertainty-with-Distance-from-Training-Data" class="headerlink" title="5.2    Uncertainty with Distance from Training Data"></a>5.2    Uncertainty with Distance from Training Data</h4><ol>
<li>偶然不确定性无法通过更多数据解释。</li>
<li>偶然不确定性也不会因为与训练集不同的样本而增加，而认知不确定性会</li>
</ol>
<p>在表三中我们给出了在子集不断增加的数据上训练模型的精度与不确定性，结果表明<strong>认知不确定性将随训练集增大而减小，结果同时表明偶然不确定性保持相对稳定，不能被更多数据解释。利用不同的数据集进行测试时认知不确定性会稍微增加。</strong></p>
<p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/What Uncertainties Do We Need in Bayesian DeepLearning for Computer Vision/image-20200806204638776.png" alt="image-20200806204638776" style="zoom:80%;" /></p>
<h4 id="5-3-Real-Time-Application"><a href="#5-3-Real-Time-Application" class="headerlink" title="5.3    Real-Time Application"></a>5.3    Real-Time Application</h4><p>偶然不确定性增加的时间可以忽略不计，认知不确定性<strong>蒙特卡洛采样是比较耗时的</strong>   ResNet只有最后几层有dropout需要采样，而denseNet require the entire architecture to be sample，因为CPU的显存限制</p>
<h3 id="6-Conclusions"><a href="#6-Conclusions" class="headerlink" title="6   Conclusions"></a>6   Conclusions</h3><p>对以下情形计算偶然不确定性是比较重要的：</p>
<ol>
<li>具有<strong>大量数据</strong>的情况，这种情况下认知不确定性是可以被解释的。</li>
<li><strong>实时系统</strong>，偶然不确定性不会影响实时性。</li>
</ol>
<p>对以下请性计算认知不确定性是比较重要的：</p>
<ol>
<li>对<strong>安全性要求较高</strong>的应用，对uncertainty比较敏感的应用，因为认知性能可以识别出当前场景与训练集是否一致。</li>
<li>小数据集情况，training data is sparse时</li>
</ol>
<hr>
<h4 id="偶然事件不确定性（Aleatoric-Uncertainty）和-认知不确定性（Epistemic-Uncertainty）"><a href="#偶然事件不确定性（Aleatoric-Uncertainty）和-认知不确定性（Epistemic-Uncertainty）" class="headerlink" title="偶然事件不确定性（Aleatoric Uncertainty）和 认知不确定性（Epistemic Uncertainty）"></a><em>偶然事件不确定性（Aleatoric Uncertainty）</em>和 <em>认知不确定性（Epistemic Uncertainty）</em></h4><h4 id="reference—深度学习中的两种不确定性"><a href="#reference—深度学习中的两种不确定性" class="headerlink" title="reference—深度学习中的两种不确定性"></a><a href="https://zhuanlan.zhihu.com/p/56986840">reference—深度学习中的两种不确定性</a></h4><p>传统深度学习算法几乎只能给出一个特定的结果，而不能给出模型自己对结果的置信度。当输入不在训练集出现过的样本时，softmax输出概率不太可能是在标签集上的平均值如(0.5,0.5)<a href="http://www.cs.ox.ac.uk/people/yarin.gal/website/blog_3d801aa532c1ce.html">原因</a></p>
<p>BNN (Bayesian Neural Network)。BNN的原理大体上是，我们网络中每个参数的weight将不再是一个特定的数字，取而代之的是一个先验分布。这样我们train出来的网络将不再是一个函数，而是一个函数的分布<a href="https://towardsdatascience.com/making-your-neural-network-say-i-dont-know-bayesian-nns-using-pyro-and-pytorch-b1c24e6ab8cd">BNN详细</a></p>
<h5 id="1-偶然不确定性"><a href="#1-偶然不确定性" class="headerlink" title="1    偶然不确定性"></a>1    偶然不确定性</h5><p>数据本来就存在误差。<strong>数据集里这样的bias越大</strong>，我们的偶然不确定性就应该越大。(来自数据收集过程的<strong>不可约减的噪声</strong>,这个现象不能通过增加采样数据来削弱，解决这个问题的方法一般是提升数据采集时候的稳定性，或者提升衡量指标的精度以囊括各类客观影响因素)</p>
<p>可以进一步分为同方差不确定性（Task-dependant or Homoscedastic uncertainty）和异方差不确定性（Data-dependant or Heteroscedastic uncertainty）</p>
<ul>
<li>异方差不确定性，取决于输入数据，并预测为模型输出。其中一些输入可能具有比其他输入更多的噪声输出。异方差的不确定性尤为重要，可以防止模型输出非常自信的决策</li>
<li>同方差不确定性，不取决于输入数据。它不是模型输出，而是一个对所有输入数据保持不变并且在不同任务之间变化的数量。因此，它可以被描述为任务相关的不确定性</li>
</ul>
<h5 id="2-认知不确定性"><a href="#2-认知不确定性" class="headerlink" title="2    认知不确定性"></a>2    认知不确定性</h5><p>认知不确定性测量的，是我们的input data是否存在于已经见过的数据的分布之中。(对真实模型的无知，模型自身对输入数据的估计可能因为训练不佳、训练数据不够等原因而不准确，与某一单独的数据无关。可以通过有针对性的调整（增加训练数据等方式）来缓解甚至解决的)</p>
<h4 id="两种不确定性的量化"><a href="#两种不确定性的量化" class="headerlink" title="两种不确定性的量化"></a>两种不确定性的量化</h4><p>对于回归问题</p>
<h5 id="1-认知不确定性的量化"><a href="#1-认知不确定性的量化" class="headerlink" title="1    认知不确定性的量化"></a>1    认知不确定性的量化</h5><p>估计数据集的真实分布 $P(D)$  $D$ 为数据集，$W$ 为权重</p>
<p>蒙特卡洛方法对网络参数的后验概率 $P(W|D)$ 进行估计，后验概率 $P(W|D)$ (我们就可以知道 $D$ 到底在不在我们已经学习的分布中，从而获得认知不确定性)</p>
<p><a href="https://www.cnblogs.com/geo-will/p/10491447.html">reference—贝叶斯深度学习-概述</a></p>
<p><a href="https://aijishu.com/a/1060000000089656">R TALK | 旷视危夷晨：不确定性学习在视觉识别中的应用</a></p>
<hr>
]]></content>
      <categories>
        <category>Uncertainty in deep learning</category>
        <category>Dropout Uncertainty</category>
        <category>Computer Vision</category>
      </categories>
      <tags>
        <tag>异方差不确定性</tag>
        <tag>CV</tag>
        <tag>aleatory and epistemic</tag>
      </tags>
  </entry>
  <entry>
    <title>Aleatory or epistemic? Does it matter?</title>
    <url>/blog/2020/07/27/Aleatory%20or%20epistemic%20Does%20it%20matter/</url>
    <content><![CDATA[<a id="more"></a>
<h3 id="『』阅读笔记"><a href="#『』阅读笔记" class="headerlink" title="『』阅读笔记"></a>『』阅读笔记</h3><ul>
<li>基本变量和派生变量</li>
<li>基本变量的不确定性</li>
<li>模型的不确定性</li>
<li>参数的不确定性</li>
</ul>
<h3 id="专有名词"><a href="#专有名词" class="headerlink" title="专有名词"></a>专有名词</h3><ol>
<li>Truncated normal distribution截断正态分布</li>
<li>贝叶斯学派认为参数是未观察到的随机变量，本身也有分布，因此，假定参数服从一个先验分布，然后基于观测到的数据来计算参数的后验分布。</li>
<li><strong>可靠性分析</strong></li>
<li>linear limit-state function </li>
<li>点估计（point estimation）——用<a href="https://zh.wikipedia.org/wiki/样本">样本</a>数据来估计总体<a href="https://zh.wikipedia.org/wiki/参数">参数</a>， 估计结果使用一个点的数值表示“最佳估计值”，因此称为点估计。</li>
<li>高斯过程——参数方法需要推断参数的分布，而在非参数方法中，比如高斯过程，它可以直接推断函数的分布。<a href="https://www.kesci.com/home/project/5d8da105037db3002d3a4c4a">reference 高斯过程Gaussian Process教程</a></li>
</ol>
<h3 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h3><p>在工程模型领域对于风险和可靠度分析的不确定性的资源和特征将在这里讨论。有很多不确定性的资源可能存在着，它们可以总体被分为<strong>偶然的和认知的</strong>。不确定性被描述为认知的，是当建模者看到了可以通过更多的数据或者重新定义模型来降低不确定性的可能性。不确定性被分类为偶然的，是当建模者并不能提前看到降低这种不确定性的可能性。从务实的角度来看，对模型中的不确定性进行分类是有用的，因为这样就清楚了哪些不确定性具有减少的潜力。<strong>更重要的是，认知不确定性可能会导致事件之间的依赖，如果不正确地建模它们的特性，则可能无法正确地注意到这一点。</strong>讨论了在可靠性评估、成文设计、基于性能的工程和基于风险的决策中两种不确定性的影响。两个简单的例子说明了由认知不确定性引起的统计依赖对系统和时变可靠性问题的影响。</p>
<h3 id="1-Introduction"><a href="#1-Introduction" class="headerlink" title="1   Introduction"></a>1   Introduction</h3><p>不确定性的性质和处理方法长期以来一直是统计学家、工程师和其他专家讨论的话题 (see, e.g., Paté-Cornell 1996, Vrouwenvelder 2003, Faber 2005)。本文试图再次在结构可靠性和风险分析structural reliability and risk analysis 的背景下重新讨论这一问题。这份文件不大可能结束这一讨论。然而，我们希望它<strong>能在结构可靠性评估、成文法设计、基于性能的设计和基于风险的决策等structural reliability, codified design, performance-based design and risk-based decision-making. 问题上提供一些启示</strong>。特别是，我们将考虑<strong>系统可靠性和时变可靠性问题 systems reliability and time-variant reliability </strong>，对于这些问题，适当处理 of uncertainties 比对时不变元件可靠性问题更为重要。我们认为，不确定性的性质和如何处理这些不确定性取决于上下文和应用。</p>
<p><strong>工程问题，包括可靠性问题、风险问题和决策问题，无一例外地在模型范围内得到解决</strong>。这个范围包含一组物理和概率模型(或子模型)，这些模型被用作<strong>对现实的数学理想化</strong>，为手头的问题提供一个解。模型范围可能包含内在固有的不确定量；此外，子模型总是不完美的，从而产生<strong>额外</strong>的不确定性。所以，在模型领域内一个重要的部分是对这些不确定性进行建模。对不确定性的性质和特性的任何讨论都应在模型领域的范围内说明。</p>
<p>虽然不确定性的来源可能很多，但在建模的背景下，可以方便地将不确定性的特征归类为 aleatory or epistemic <em>偶然事件不确定性（Aleatoric Uncertainty）</em>和 <em>认知不确定性（Epistemic Uncertainty）</em>。<strong>aleatory这个词源自拉丁语，意思是掷骰子。因此，Aleatoric Uncertainty被认为是一种现象的内在随机性。</strong> <strong>episteme一词来源于希腊语επιστη(认识论)，意思是知识（knowledge）。因此，认知不确定性被认为是由于缺乏知识(或数据)造成的。</strong>在工程分析模型中方便地进行这种区分的原因是，通过<strong>引入辅助的非物理变量</strong>，<em>可以在模型中表示缺乏知识-部分不确定性。</em>这些变量从收集到的更多的数据或者使用更先进的科学准则中捕获信息。最重要的一点是，这些辅助变量以明确和透明的方式定义了统计依赖(相关性)。<strong>重点关注是在这些辅助变量上</strong>。</p>
<p>大多数工程问题都涉及这两种类型的不确定性。在建模阶段，有时，确定一个实际的不确定性是属于A或E是困难的。区分工作是模型建造者的工作。模型建造者做的决定取决于科学知识的总体情况，但是更多的是关于将模型的复杂程度限制在对从模型中产生的决策具有重大工程重要性的实际需要上。</p>
<p>符号约定：</p>
<p>一组输入变量 <img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/Aleatory or epistemic Does it matter/image-20200802235103259.png" alt="image-20200802235103259" style="zoom:70%;display:inline" align="middle"/>将值作为一组相应的基本随机变量<img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/Aleatory or epistemic Does it matter//image-20200802235119463.png" alt="image-20200802235119463" style="zoom:70%;display:inline" align="middle" />的结果的值。参数化概率子模型<img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/Aleatory or epistemic Does it matter//image-20200802235514581.png" alt="image-20200802235514581" style="zoom:70%;display:inline" align="middle" />描述随机向量 $X$ 的分布，一组参数化的物理 子模型<img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/Aleatory or epistemic Does it matter//image-20200802235914474.png" alt="image-20200802235914474" style="zoom:70%;display:inline" align="middle" />描述quantities  $x$ 和 $m$ 的派生quantities <img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/Aleatory or epistemic Does it matter//image-20200803000018284.png" alt="image-20200803000018284" style="zoom:70%;display:inline" align="middle" />之间的关系，这些模型用于对研究中的可靠性或风险问题进行建模。<strong>随机变量 $X$</strong> 之所以称为<strong>基本变量</strong>，是因为我们认为它<strong>们是直接可观察的，因此经验数据可用于它们</strong>。它们可能代表诸如材料特性（强度，延展性，韧性，疲劳寿命等），载荷特性（例如地震幅值，风速，波高），其他环境影响（例如温度，毒素浓度）之类的数量。-in，污染量）和几何尺寸（例如，横截面尺寸，支撑件位置，不平直度）。除非在针对模型开发的实验室或现场研究中，否则通常<strong>无法直接观察到</strong> <strong>derived variables</strong>  $y$ 。工程性能标准通常以这种推导的变量来描述，例如应力，变形，稳定性极限，破坏程度，损失，停机时间，下游水中毒素的浓度。<img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/Aleatory or epistemic Does it matter//image-20200803092642126.png" alt="image-20200803092642126" style="zoom:70%;display:inline" align="middle" /><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/Aleatory or epistemic Does it matter//image-20200803092702064.png" alt="image-20200803092702064" style="zoom:70%;display:inline" align="middle" />总是不完美的现实数学理想化，并且包含不确定的错误。通常通过将这些子模型“拟合”到观测数据的过程来估计这些参数 <img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/Aleatory or epistemic Does it matter//image-20200803092857179.png" alt="image-20200803092857179" style="zoom:70%;display:inline" align="middle" /></p>
<p>在可靠性和分线分析中的很多问题都设计上述元素。通过这篇文章我们会使用这些元素来讨论建模中的不确定性和在不同的应用上下文中评定风险和可靠性评估之间的相关性。</p>
<h3 id="2-Sources-of-uncertainty"><a href="#2-Sources-of-uncertainty" class="headerlink" title="2   Sources of uncertainty"></a>2   Sources of uncertainty</h3><ol>
<li>基本随机变量 <strong>X 固有的不确定性</strong>，例如可以<strong>直接测量的</strong>材料属性常数和载荷值固有的不确定性。</li>
<li>由于选择概率子模型的 form <img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/Aleatory or epistemic Does it matter//image-20200802235514581.png" alt="image-20200802235514581" style="zoom:70%;display:inline" align="middle" />而导致的<strong>不确定模型误差</strong></li>
<li>由选择<strong>物理子模型</strong><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/Aleatory or epistemic Does it matter//image-20200802235914474.png" alt="image-20200802235914474" style="zoom:70%;display:inline" align="middle" />引起的不确定建模误差，用于<strong>描述派生变量</strong></li>
<li>概率和物理子模型的<img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/Aleatory or epistemic Does it matter//image-20200803092857179.png" alt="image-20200803092857179" style="zoom:70%;display:inline" align="middle" /> <strong>参数 估计中的统计不确定性</strong>。</li>
<li>测量观测值涉及的不确定性误差，据此可以估算参数 <img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/Aleatory or epistemic Does it matter//image-20200803092857179.png" alt="image-20200803092857179" style="zoom:70%;display:inline" align="middle" />。这些包括<strong>间接测量中涉及的错误</strong>，例如通过代理进行量测，例如材料强度的无损检测。</li>
<li>由对应于<strong>派生变量 $y$ 的随机变量 $Y$ 建模的不确定性</strong>，除上述所有不确定性外，还可能包括<strong>由计算误差，数值逼近或截断产生的不确定性误差。</strong>例如，通过有限元程序对非线性结构中的荷载效应进行计算时，会采用迭代计算，这总是会涉及收敛容限和截断误差</li>
</ol>
<p><strong>Interpolation errors</strong>、<strong>Model bias</strong> 、<strong>Numerical errors</strong> 、<strong>Observational error</strong> 、<strong>Parameter uncertainty</strong></p>
<h3 id="3-Categorization-of-uncertainties"><a href="#3-Categorization-of-uncertainties" class="headerlink" title="3   Categorization of uncertainties"></a>3   Categorization of uncertainties</h3><h4 id="3-1-Uncertainty-in-basic-variables"><a href="#3-1-Uncertainty-in-basic-variables" class="headerlink" title="3.1. Uncertainty in basic variables"></a>3.1. Uncertainty in basic variables</h4><p>考虑描述材料特性常数（例如混凝土的抗压强度）的基本随机变量X。<strong>直接测量的X中的不确定性应归类为偶然性Aleatoric还是认知性Epistemic？答案取决于具体情况。</strong>如果所需强度是现有建筑物中混凝土的强度，则如果确定可以对从建筑物中<strong>取出的样本进行测试</strong>，从而得出有关强度的信息，则不确定度应归类为<strong>认知性Epistemic</strong>。当然，测试可能会涉及随机的测量误差，尤其是在使用非破坏性方法的情况下。如果有可能考虑替代的测量方法，则该测量不确定度也应归类为认知的Epistemic。另一方面，例如，如果<strong>不尝试</strong>进行与混凝土生产控制有关的<strong>更详细的建模</strong>，则将来建筑物中混凝土强度的<strong>不确定性应归为偶然性Aleatoric</strong>。在建筑物建成之前，不会进行任何测试来减少未来建筑物混凝土强度所固有的可变性。</p>
<p>需求（负载）变量的情况有些不同，因为在评估现有建筑物和未来建筑物的可靠性时，人们通常会对需求值的未来实现感兴趣。因此，在这种情况下，基本需求变量的不确定性通常归为偶然性。</p>
<p><strong>重申基本变量和派生变量之间的区别很重要</strong>。这是建模人员通常根据标准工程实践做出的选择。考虑例如年度最大风速，这在设计塔架时可能会引起关注。建模者可以选择考虑这一点作为基本变量，在这种情况下，他/她将采用概率子模型（可能从某些标准建议中选择）以经验方式 empirically获得年度最大风速数据。或者，如果没有此类数据，则分析人员可以选择对来自<strong>更基本的气象数据的风速使用预测子模型</strong>。在这种情况下，年风速是<img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/Aleatory or epistemic Does it matter//image-20200803095627960.png" alt="image-20200803095627960" style="zoom:70%;display:inline" align="middle" />形式为的导出变量，<img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/Aleatory or epistemic Does it matter//image-20200803095705817.png" alt="image-20200803095705817" style="zoom:70%;display:inline" align="middle" />其中x表示输入气象变量，表示风速的预测子模型 predictive sub-mode。下面将derived variable包含的uncertainties描述为模型不确定性的一部分，如我们所见，<strong>派生变量的不确定性可以归类为偶然不确定性和认知不确定性的组合。</strong></p>
<p>在构建分析模型时，the arbitrariness in the choice of variables as basic or derived 使得问题中不确定性的分类取决于我们对子模型的选择。通过使用子模型，我们将经验数据依赖于其他基本变量，或者有时依赖于先验概率分配。地震危险性分析中有一个很好的例子。在这里，关注的是现场潜在地震地震动的强度，即 a demand variable。由于很难获得在特定地点经历的地面运动强度的经验数据，因此通常的做法是将强度量度与地震震级（可获得经验数据empirical data is available）和距离（与先验子模型相关priori sub-model can be used）相关联。可以使用-模型，例如，可以假定地震沿着活动断层的任何地方发生的可能性均等。这是通过“衰减attenuation”定律完成的，该定律可以看作是地面运动强度的预测子模型。在此公式中，地面运动强度成为一个derived variable，而基本变量是地震震级和距离。在选择此子模型时，我们将引入其他不确定性，这些不确定性可能同时具有偶然性和认知性成分，如以下部分所述。</p>
<p>值得注意的是，现有建筑物与未来建筑物中<strong>不确定性的不同分类</strong>规定了用于评估其可靠性的方法的根本差异。对于现有建筑物，可靠性评估应旨在评估<strong>以已知建筑物历史为条件conditioned on the known history of the building</strong>的可靠性。例如，有关建筑物在已知强度的地震中幸存下来的知识<strong>可用于截断强度分布的下尾部truncate the lower tail of the strength distribution</strong>。随着更多信息的收集，评估中的不确定性降低。本质上，这是<strong>信息更新的问题，贝叶斯技术</strong>非常适合于此。另一方面，例如在设计过程中，评估未来建筑物的可靠性的问题是确定从总体中抽取随机样本的状态之一determining the state of a random sample taken from a population。在考虑了所有合理的控制措施之后，在实现建筑物之前，无法使用直接信息进行更新。在评估现有结构与未来结构的可靠性时，这种区别在有关结构可靠性的文献中经常被忽略。</p>
<h4 id="3-2-Model-uncertainty"><a href="#3-2-Model-uncertainty" class="headerlink" title="3.2  Model uncertainty"></a>3.2  Model uncertainty</h4><p>考虑物理量 $y$，其根据两组基本变量 x 和 z 唯一确定。我们希望开发一个数学模型（或子模型）来预测 y。y和(x,z)之间关系的确切形式通常是未知的。此外，建模者可能不知道y对z的依赖性，或者出于实用主义的考虑，他/她可能不希望include these variables in a predictive model of y。例如，实际上不可能在变量 z 上收集数据，因此将其包括在模型中将无济于事</p>
<p>作为一个具体示例，请考虑上述地面运动强度衰减模型ground motion intensity attenuation model。我们深知，除了地震的震级和距离外，一个地点的烈度还很重要，诸如断层破裂的传播速度，地震波传播路径的机械特征，场地周围的地质特征等变量。但是，从务实的角度来看，很难甚至不可能测量给定站点的这些变量。因此，我们将它们排除在衰减模型中。这些变量以及我们可能不知道的其他变量构成了地震动衰减模型中缺失的变量z，地震动衰减模型中仅根据地震震级和距离来表示，这些变量构成模型基本变量x的向量。</p>
<p>&lt;img src=”<a href="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/Aleatory">https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/Aleatory</a> or epistemic Does it matter//image-20200803114118997.png” alt=”image-20200803114118997” style=”zoom:80%;/&gt;</p>
<p> 残差值 $\epsilon$  建模成 random variable 两个原因：</p>
<ol>
<li>模型中缺少的 missing variables z 的影响</li>
<li>模型的 potentially inaccurate form 的影响。例如，y 和 x之间的关系可以是非线性的，而模型使用的线性形式。</li>
</ol>
<p>通常，人们会对无偏模型unbiased model感兴趣。在这种情况下，<img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/Aleatory or epistemic Does it matter//image-20200803114456344.png" alt="image-20200803114456344" style="zoom:70%;display:inline" align="middle" />，通过将 ε 的 mean 设置为zero 来确定，此外，通过对模型进行适当的转换，通常可以使 ε 具有 标准偏差为 $\sigma_\epsilon$ 的正态分布——测量模型的不准确性——分布独立于x</p>
<p>这被称为模型的同方差形式 homoskedastic form of the mode（Box and Tiao 1992）。因此，为了完全定义模型，需要估计的模型参数集为 <img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/Aleatory or epistemic Does it matter//image-20200803114931701.png" alt="image-20200803114931701" style="zoom:70%;display:inline" align="middle" />当涉及多个子模型时，除了所有子模型的参数和标准偏差 <img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/Aleatory or epistemic Does it matter//image-20200803114931701.png" alt="image-20200803114931701" style="zoom:70%;display:inline" align="middle" /> 外，还需要确定不同子模型的误差项之间的相关系数 correlation coefficients </p>
<p>现在，我们在（1）中的形式模型中检查不确定性的性质。如上所述，ε 解释了缺失变量 z 的不确定影响以及模型的潜在不准确形式。如果对模型进行改善以包括一个或多个缺失变量和/或数学表达式（解析或算法），则可以减少这两种不确定性，从而可以更好地近似正确的形式。从这个意义上讲，ε中的不确定性至少被归类为认知的。但是，由于我们有限的科学知识状态，可能无法让我们进一步完善模型的形式，而我们无法测量缺失的变量则可能会排除扩展模型的可能性。在这种情况下，ε 中至少一部分不确定性被归类为偶然性。尤其是，如果这些变量（尽管未知）被表征为偶然随机变量，则由于缺失变量的影响而引起的ε不确定性部分可以合理地分类为偶然变量。</p>
<p>现在转到概率模型（或子模型）<img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/Aleatory or epistemic Does it matter//image-20200802235514581.png" alt="image-20200802235514581" style="zoom:70%;display:inline" align="middle" />。通常通过对可用数据进行理论分布拟合来选择此模型。有评估拟合优度goodness of the fit的各种方法 。但是，当<strong>关注概率较小的事件时</strong>（如大多数结构可靠性和风险问题的情况一样），概率分布的尾巴the tail of the probability distribution 就变得很重要。不幸的是，标准的拟合优度测试<strong>不能保证尾部贴合fit in the tail的准确性</strong>。例如，Ditlevsen（1994）表明，同样拟合的分布可能会导致概率估计值明显不同。因此，在计算概率时，特别是对于罕见事件，<strong>从假定的分布模型中会产生不确定幅度的误差</strong>。可以将这种<strong>错误归类为认知类别epistemic category</strong>，因为<strong>收集更多数据将可以更好地拟合分布，因此可以减少模型的不确定性</strong>。但是，与上述物理模型的情况不同，<strong>难以评估由分配模型的选择引起的误差的大小</strong>。一个有逻辑的方法是为<strong>所有可行的分布模型distribution models计算感兴趣的概率</strong>，并评估计算出的概率值的variability 。Der Kiureghian（1989）建议的第二种方法是<strong>参数化分布的选择parameterize the choice of the distribution。</strong>然后，通过参数中的不确定性来表示分布模型中的不确定性。但是，这两种方法都需要大量分析。</p>
<p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/Aleatory or epistemic Does it matter//image-20200803142500338.png" alt="image-20200803142500338" style="zoom:70%;display:inline" align="middle" /></p>
<p>只是在<strong>非常特殊的问题</strong>中，人们才能将事件的可能性视为事件在发生变化的一长串独立重复中的物理发生的相对频率。在结构安全领域structural safety中，<strong>几个非常重要的不确定性来源在相同情况下不会表现出这种重复性行为。</strong>可以肯定地说，将稳定的长期发生频率解释为物理意义上的绝对概率属于乌托邦。因此，概率概念的有用性必须建立在另一个理性的基础上。但是，作为一种思维构造（和一种仿真工具），数学概率的相对频率解释relative frequency interpretation对于其作为<strong>有关事件发生的可信度</strong>的有用性起着决定性作用。为了使概率置信度模型经受伪造的务实测试 To make a probabilistic degree-of-belief model subject to a pragmatic test of falsification (a concept by Matheron based on Popper)，因此可以作为客观工具辩护，有必要将某种类型的相对频率行为与概率相关联that some type of relative frequency behavior be associated with the prob-abilistic mode。</p>
<p>提到的所选概率分布的编码应视为结构可靠性工程专业人士对计算出的概率敏感的模型元素的共识。否则，由于竞争原因，工程实践将对不合理的分配尾部选择开放。此外，以此方式获得了有用的公共知识库，尤其是在认识不确定性分布的选择方面。显然，对于基于样本数据的分发，随着更多数据和更好质量的数据的出现，知识库应受到修订。</p>
<p>为了克服任意分布选择arbitrary distribution choice的问题，通过对公认的实践进行校准过程来开发概率代码probabilistic codes ，从而至少将概率用作比较和调整的手段是合理的。如果对无形效用值也进行了校准calibration，那么甚至可以在模型中使用标准化分布standardized distributions i进行最优决策，以使平均可接受的实践成为最优实践。</p>
<p>近年来，人们对基于性能的工程开发给予了极大的关注，特别是在建筑物和其他结构的设计上，以抵抗地震的力量（Cornell and Krawinkler 2000）。该方法的核心是承诺计算与各种结构性能要求相关的风险，包括罕见事件（例如极端损坏和倒塌）的风险。在该领域迅速发展的文献中，很少关注<strong>诸如尾部敏感性问题或建模和估计中固有的不确定性表征之类的问题</strong>。尽管本文可能对解决这个问题没有帮助，但它引起了人们的关注，并希望为依赖于罕见事件概率值的方法的基本问题和问题提供一些启示</p>
<h4 id="3-3-Parameter-uncertainty"><a href="#3-3-Parameter-uncertainty" class="headerlink" title="3.3.Parameter uncertainty"></a>3.3.Parameter uncertainty</h4><p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/Aleatory or epistemic Does it matter//image-20200803150008361.png" alt="image-20200803150008361" style="zoom:70%;display:inline" align="middle" /><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/Aleatory or epistemic Does it matter//image-20200803150054249.png" alt="image-20200803150054249" style="zoom:70%;display:inline" align="middle" /></p>
<p>首选方法是贝叶斯分析，该方法允许以参数形式包含主观专家意见的先验知识。参数估计中的不确定性直接与可用信息的数量和质量有关。<strong>在数量上，我们指的是可用观察样本的大小。 By quality, we refer to the accuracy in the observations. </strong> 观测中出现的任何测量误差都会使信息内容变差，从而使数据质量变差。质量也指先验的信息内容。这种分析现在已成为常规，我们将不再讨论更多细节。</p>
<p>参数不确定性是严格认知的 strictly epistemic ，因为估计中的不确定性会降低，并且可能随着可用观测数据的数量和质量的增加而渐近消失。</p>
<h4 id="3-4-Final-remark"><a href="#3-4-Final-remark" class="headerlink" title="3.4.Final remark"></a>3.4.Final remark</h4><p>上面的讨论可能会引发哲学上的问题，即是否存在任何偶然的不确定性。显然，这个问题在模型世界之外没有任何意义。从语言学的角度来看，所有不确定性都与缺乏知识一样。但是，如上所述，在概率模型（尤其是数学统计模型）中，将不确定性的分类为偶然的Aleatoric Uncertainty和认知的Epistemic Uncertainty是很方便的。因此，在模型世界中，认知一词的含义比没有知识的含义更窄the word epistemic assumes a more narrow meaning than just lack of knowledge。</p>
<p>假设我们了解了所有缺失的变量和确切的模型形式，那么考虑不需要偶然类别aleatory category的模型可能只是时间问题。甚至可以通过精确的预测模型来解释基本变量basic variables。在这样的世界中，如果存在不确定性，那只会是认知的epistemic。但是，这个乌托邦式的世界与当今的工程实践相距太远。将不确定性分为偶然性和认知aleatory and epistemic 的优势在于，我们由此可以弄清楚哪些不确定性可以减少，哪些不确定性至少在短期内不那么容易减少。这种分类有助于我们分配资源和开发选择工程模型。此外，为了正确地表述风险或可靠性问题 risk or reliability problems，必须更好地理解不确定性的分类。例如，认知不确定性可能会在系统组件的估计性能之间引入依赖关系 introduce dependence among the estimated performances of the components of a system,，非遍历不确定性non-ergodic uncertainties可能会在时间或空间事件序列之间引入依赖关系。在实践中，由于对不确定性的不正确处理，这些依赖性通常被忽略。下节中的示例演示了这种影响的影响</p>
<h3 id="4-Influence-of-uncertainties"><a href="#4-Influence-of-uncertainties" class="headerlink" title="4     Influence of uncertainties"></a>4     Influence of uncertainties</h3><p>在本节中，我们提供两个示例来说明不确定性对可靠性评估uncertainties on reliability assessment的影响。第一个例子说明了由系统不确定性在系统组件之间引入的统计依赖性statistical dependence 的影响。第二个例子说明了时变可靠性问题中非遍历不确定性的影响，无论是认知的还是偶然的both epistemic and aleatory</p>
<h4 id="4-1-System-reliability"><a href="#4-1-System-reliability" class="headerlink" title="4.1.System reliability"></a>4.1.System reliability</h4><p>考虑一个  k-out-of-N  的系统。如果N个分量中至少有k个存活，则该系统将存活，其中$1\le k\le N$。极值k=1和k =N分别定义了并联和串联系统的特殊情况。为简单起见，我们假设组件具有统计独立且相同分布的capacities ，capacities 由随机变量 $X_1$ 表示，并且统计独立且相同分布的需求demands 由随机变量 $X_2$  表示。本质上，组件capacities 和 demands 分别是random realizations from the distributions of $X_1$ 和 $X_2$ 。因此，组件具有相同极限状态函数 定义为：<img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/Aleatory or epistemic Does it matter//image-20200803154648873.png" alt="image-20200803154648873" style="zoom:70%;display:inline" align="middle" /></p>
<p>$g(x)\le0$ 为失败事件，我们进一步假设  $X_1$ 和 $X_2$ 是正态分布的随机变量，with unknown means $\mu_1 \mu_2$ and known standard deviations $\sigma_1  \sigma_2$ <img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/Aleatory or epistemic Does it matter//image-20200803155137129.png" alt="image-20200803155137129" style="zoom:70%;display:inline" align="middle" /><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/Aleatory or epistemic Does it matter//image-20200803155152486.png" alt="image-20200803155152486" style="zoom:70%;display:inline" align="middle" />假设为了估计 $\mu_1 \mu_2$ 的可用信息是 以 <img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/Aleatory or epistemic Does it matter//image-20200803155405749.png" alt="image-20200803155405749" style="zoom:70%;display:inline" align="middle" />采样均值的对 size 为 n 的 capacity and demand values的 sample observations。使用贝叶斯建模很方便，其中 $\mu_1 \mu_2$ 被认为是贝叶斯随机变量<img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/Aleatory or epistemic Does it matter//image-20200803161328220.png" alt="image-20200803161328220" style="zoom:70%;display:inline" align="middle" />的实现。假设 <img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/Aleatory or epistemic Does it matter//image-20200803161355774.png" alt="image-20200803161355774" style="zoom:70%;display:inline" align="middle" />和 <strong>diffuse priors 扩散先验</strong>，these imply posterior distributions of  <img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/Aleatory or epistemic Does it matter//image-20200803161751223.png" alt="image-20200803161751223" style="zoom:70%;display:inline" align="middle" />，关于 <img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/Aleatory or epistemic Does it matter//image-20200803161918579.png" alt="image-20200803161918579" style="zoom:70%;display:inline" align="middle" />的后验分布是正态的，有均值<img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/Aleatory or epistemic Does it matter//image-20200803155405749.png" alt="image-20200803155405749" style="zoom:70%;display:inline" align="middle" />和<img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/Aleatory or epistemic Does it matter//image-20200803162005209.png" alt="image-20200803162005209" style="zoom:70%;display:inline" align="middle" /></p>
<p>如前所述，分布参数 $\mu_1 \mu_2$ 的统计不确定性本质上是 epistemic  。由于组件的容量和需求<strong>component capacities and demands</strong> are identically distributed同分布的。因此，分布参数的估计中固有的统计不确定性在系统组件的估计状态之间引入了统计依赖性。为了研究这种影响，我们进行如下操作：</p>
<p>观察到，对于线性极限状态函数和正态随机变量，对于给定<img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/Aleatory or epistemic Does it matter//image-20200803162518996.png" alt="image-20200803162518996" style="zoom:70%;display:inline" align="middle" />值，典型组件的条件可靠性指标</p>
<p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/Aleatory or epistemic Does it matter//image-20200803162540537.png" alt="image-20200803162540537" style="zoom:70%;display:inline" align="middle" /></p>
<p><strong>reliability index对应结构失效概率——材料背景</strong></p>
<p><strong>显然，由于统计不确定性，可靠性指标的不确定性与观察样本的大小直接相关。</strong></p>
<h4 id="4-2-Time-variant-reliability"><a href="#4-2-Time-variant-reliability" class="headerlink" title="4.2.Time-variant reliability"></a>4.2.Time-variant reliability</h4><h3 id="5-Conclusions"><a href="#5-Conclusions" class="headerlink" title="5   Conclusions"></a>5   Conclusions</h3><h4 id="What-My-Deep-Model-Doesn’t-Know"><a href="#What-My-Deep-Model-Doesn’t-Know" class="headerlink" title="What My Deep Model Doesn’t Know"></a><a href="http://www.cs.ox.ac.uk/people/yarin.gal/website/blog_3d801aa532c1ce.html"><strong>What My Deep Model Doesn’t Know</strong></a></h4><ol>
<li><p>Gaussian processes,   A network with <em>infinitely</em> many weights with a distribution on each weight is a Gaussian process</p>
</li>
<li><p>The same network with <em>finitely</em> many weights, put a probability distribution over each weight  is known as a <em>Bayesian neural network</em></p>
</li>
<li><p>dropout : can give us principled uncertainty estimates从某种意义上讲，不确定性估计基本上近似于我们的高斯过程的估计，在使用dropout防止过拟合时，可以把这个有限模型视为高斯过程的近似，you can extract model uncertainty without changing a single thing. 在优化目标函数时，实际上也在减小 KL divergence between your model and the Gaussian process。</p>
</li>
<li><p>以 a <em>single hidden layer</em> 的模型  and the task of regression.为例 <img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/Aleatory or epistemic Does it matter//image-20200804104111738.png" alt="image-20200804104111738">用两个 binary vectors做输入层和一层隐层的dropout<img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/Aleatory or epistemic Does it matter//image-20200804104846712.png" alt="image-20200804104846712">，这个回归 task 的目标函数定义为<img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/Aleatory or epistemic Does it matter//image-20200804105041906.png" alt="image-20200804105041906"><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/Aleatory or epistemic Does it matter//image-20200804105052679.png" alt="image-20200804105052679"></p>
</li>
<li><p>Gaussian process has been applied in both the supervised and unsupervised domains, for both regression and classification tasks 都在用。Gaussian process offers nice properties such as <strong>uncertainty estimates</strong> over the function values, <strong>robustness to over-fitting</strong>, and <strong>principled ways for hyper-parameter tuning</strong>. 对给定的输入集和相应的输出集，要估计一个函数 $y=f(x)$  Following the <strong>Bayesian approach</strong> we would put some <strong><em>prior</em> distribution over the space of functions</strong> $p(f)$，then look for the <strong><em>posterior</em> distribution over the space of functions given our dataset 条件后验概率</strong> <img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/Aleatory or epistemic Does it matter//image-20200804112004514.png" alt="image-20200804112004514">得到的分布作为 极大似然估计 We can then perform a prediction with a test point $x^<em>$ <img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/Aleatory or epistemic Does it matter//image-20200804112101973.png" alt="image-20200804112101973">  输出的 $y^</em>$ 的<strong>期望</strong>称为<em>predictive <strong>mean</strong></em> of the model, and its <strong>variance</strong> is called the <em>predictive <strong>uncertainty</strong></em>. 通过使用高斯过程对函数空间上的分布进行建模，我们可以分析评估回归任务中的相应后验，并估计分类任务中的后验。实际上，这意味着对于回归，我们在所有函数值上放置一个联合高斯分布，高斯先验？</p>
<p>   <img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/Aleatory or epistemic Does it matter//image-20200804155032610.png" alt="image-20200804155032610" style="zoom:70%;display:inline" align="middle" /></p>
</li>
</ol>
<h3 id="Fun-With-Uncertainty"><a href="#Fun-With-Uncertainty" class="headerlink" title="Fun With Uncertainty"></a>Fun With Uncertainty</h3><h5 id="从-dropout-中学习不确定性"><a href="#从-dropout-中学习不确定性" class="headerlink" title="从 dropout 中学习不确定性"></a>从 dropout 中学习不确定性</h5><p>一个用dropout训练的网络，输入$x^{*}$ 输出预测的期望为 $\Bbb{E}(y^{*})$ 以及网络对这个预测的 confidence为 方差 $Var(y^{*})$ </p>
<p>我们的dropout网络只是一个高斯过程近似，因此在回归任务中它将具有一定的模型精度(与我们假设的观测噪声相反)。我们如何得到这个模型的精度?</p>
<p>推导的<img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/Aleatory or epistemic Does it matter//image-20200804172056994.png" alt="image-20200804172056994"></p>
<p>在输出预测时也使用 dropout(一般在训练时使用而在预测时不用)，输入 $x^*$ 来仿真网络的输出，重复 T 次，with different units dropped every time。这些是我们的近似预测性后验样本。我们可以从这些样本中得到我们的近似后验均值和预测方差（我们的不确定性）的经验估计量。我们只需遵循这两个简单的方程式</p>
<h4 id="reference—深度学习中的两种不确定性"><a href="#reference—深度学习中的两种不确定性" class="headerlink" title="reference—深度学习中的两种不确定性"></a><a href="https://zhuanlan.zhihu.com/p/56986840">reference—深度学习中的两种不确定性</a></h4>]]></content>
      <categories>
        <category>Uncertainty in deep learning</category>
      </categories>
      <tags>
        <tag>truncated normal distribution</tag>
        <tag>aleatory and epistemic</tag>
        <tag>bayesian deep learning</tag>
        <tag>uncertainty in deep learning</tag>
      </tags>
  </entry>
  <entry>
    <title>The Neuro-Symbolic Concept Learner Interpreting Scenes Words and Sentences From Natural Supervision</title>
    <url>/blog/2020/07/26/The%20Neuro-Symbolic%20Concept%20Learner%20Interpreting%20Scenes%20Words%20and%20Sentences%20From%20Natural%20Supervision/</url>
    <content><![CDATA[<a id="more"></a>
<h3 id="『The-Neuro-Symbolic-Concept-Learner-Interpreting-Scenes-Words-and-Sentences-From-Natural-Supervision』阅读笔记"><a href="#『The-Neuro-Symbolic-Concept-Learner-Interpreting-Scenes-Words-and-Sentences-From-Natural-Supervision』阅读笔记" class="headerlink" title="『The Neuro-Symbolic Concept Learner Interpreting Scenes Words and Sentences From Natural Supervision』阅读笔记"></a>『The Neuro-Symbolic Concept Learner Interpreting Scenes Words and Sentences From Natural Supervision』阅读笔记</h3><p><a href="https://github.com/vacancy/NSCL-PyTorch-Release">official project</a></p>
<ol>
<li>Learns visual concepts, words, and semantic parsing of sentences without explicit supervision on any of them, but just by looking at images and reading paired questions and answers</li>
<li><strong><em>符号主义和连接主义的结合。符号主义体现在程序执行器program execution：定义了DSL，学习到显示的嵌套任务，每个在执行任务时，根据定义执行每个DSL定义的功能，没有参数需要学习；连接主义体现在视觉感知R-CNN和自然语言处理时的autoencoder模型</em></strong></li>
<li>模型学习到解耦的视觉和语言概念，可以通过组合来泛化到训练集没出现的样本</li>
<li>使用paired images, questions, and answers 三元组 来共同训练视觉和语言模块</li>
<li>针对这个数据集进行设计的模型，比如在<strong>Concept quantization</strong>设计时，就对数据集中 shape attribute 中的典型编码构成一个 shape embedding空间；以及设计的DSL(Domain Specific Language)</li>
</ol>
<h3 id="专有名词"><a href="#专有名词" class="headerlink" title="专有名词"></a>专有名词</h3><ol>
<li>视觉推理(visual reasoning) <a href="https://zhuanlan.zhihu.com/p/28654835">视觉推理(Visual Reasoning)神经网络也可以有逻辑</a></li>
</ol>
<h3 id="ABSTRACT"><a href="#ABSTRACT" class="headerlink" title="ABSTRACT"></a>ABSTRACT</h3><p>我们提出了神经符号概念学习器（NS-CL），该模<strong>型可以学习视觉概念，单词和句子的语义解析，而无需对它们中的任何一个进行监督。相反，我们的模型只是通过查看图像并阅读配对的问题和答案来学习。</strong>我们的模型建立了一个基于对象的场景表示并将句子翻译成可执行的符号程序。为了<strong>简化两个模块的学习，我们使用了神经符号推理模块</strong>，该模块在<strong>潜在场景</strong>表示上执行这些程序。类似于人类概念学习，感知模块基于所引用对象的语言描述来学习视觉概念。同时，学习到的视觉概念有助于学习新单词和解析新句子。我们使用课程学习curriculum learning  来指导对图像和语言的巨大组成空间的搜索。大量实验证明了我们的模型在学习视觉概念，单词表示和句子的语义解析方面的准确性和效率。此外，我们的方法允许轻松地将其推广到新的对象属性，组成，语言概念，场景和问题，甚至是新的程序域。它还支持包括视觉问题解答和双向图像文本检索在内的应用程序</p>
<p>(<strong>利用一种符号化推理过程联结视觉概念、词以及句子的语义分析，根据场景表征来推理答案，且无需对其中任何一种提供显式注释</strong>)</p>
<h3 id="1-INTRODUCTION"><a href="#1-INTRODUCTION" class="headerlink" title="1    INTRODUCTION"></a>1    INTRODUCTION</h3><p>人类有能力通过共同理解视觉和语言来学习视觉概念（Fazlyet等，2010；Chrupała等，2015； Gauthier等，2018）。考虑图1-I所示的示例。想象一下，一个没有先验颜色知识的人看到了红色和绿色立方体的图像，以及问题和答案。他们可以轻松地识别对象的视觉外观差异（在这种情况下为颜色），并将其与问题和答案中的相应单词对齐（红色和绿色）。可以类似的方式学习其他对象属性（例如形状）。从那里开始，人类能够归纳地学习视觉概念和单词语义之间的对应关系（例如 空间关系和引用表达式，图1-II），并且解构复杂问题的逻辑结合学习的视觉概念（图1-III，另请参见Abend等人（2017））</p>
<p>为此，我们提出了一种 <strong>神经符号概念学习器（NS-CL）</strong>，它可以从<strong>图像和问答对中共同学习</strong>： 视觉感知、单词、语义语言解析。NS-CL具有三个模块：基于神经的<strong>感知模块</strong>从场景中<strong>提取对象级别</strong>的表示，将问题转换为<strong>可执行程序的可视化语义解析器</strong>以及读取对象的感知表示，对<strong>对象的属性/关系进行分类的符号程序执行器</strong>，并执行程序以获取一个答案</p>
<p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/The Neuro-Symbolic Concept Learner Interpreting Scenes Words and Sentences From Natural Supervision/image-20200730152043861.png" alt="image-20200730152043861"  /></p>
<p>NS-CL从自然监督natural supervision中学习（即 图像 和 QA对 ），不需要在图像上注释或 用于句子语义注释的程序。相反，类似于人类概念学习，它通过<strong>课程学习来学习curriculum learning</strong>。NS-CL首先从简单场景（≤3个对象）中的简短问题 (What’s the color of the cylinder)  中学习单个对象的表示/概念开始。通过这样做，它学习了基于对象的概念，例如颜色和形状。然后，NS-CL通过利用这些基于对象的概念 来解释对象引用，从对象引用学习关系概念 (e.g., Is there a box right of a cylinder?).  该模型可<strong>迭代地适应更复杂的场景和高度复杂组合的问题</strong></p>
<p>NS-CL的模块化设计实现了可解释，鲁棒和准确的视觉推理 interpretable, robust, and accurate visual reasoning：在<strong>CLEVR数据集</strong>上实现了最先进的性能（Johnson等，2017a）。更重要的是，它自然地学习了解耦的视觉和语言概念，从而通过组合来泛化到训练集没出现的样本。视觉场景和语义程序。特别是，我们展示了四种形式的概括。首先，与训练集中的场景相比，NS-CL泛化到具有更多对象和更长语义程序的场景。其次，它概括了CLEVR-CoGenT（Johnson et al。，2017a）数据集上演示的新视觉属性组成。第三，它可以快速适应新的视觉概念，例如学习新的颜色。最后，学习到的视觉概念无需任何微调即可转移到新任务，例如图像字幕检索</p>
<h3 id="2-RELATED-WORK"><a href="#2-RELATED-WORK" class="headerlink" title="2    RELATED  WORK"></a>2    RELATED  WORK</h3><p>我们的模型与视觉和自然语言的联合学习有关。尤其是，有许多论文从描述性语言中学习视觉概念，例如图像说明或视觉基础的问答对 image-captioning or visually-grounded question-answer pair (Kiros等人，2014; Shi等人，2018; Mao等人，2016; Vendrov等人等人,  2016; Ganju等人，2017)，场景的密集语言描述dense language descriptions for scenes（Johnson等人，2016），视频字幕（Donahue等人，2015）和视频文本对齐（Zhu等人，2015）.</p>
<p>视觉问题解答（VQA）脱颖而出，因为它需要了解视觉内容和语言。最先进的方法通常使用神经注意力 neural attention（Malinowski＆Fritz，2014; Chen et al，2015; Yang et al，2016; Xu＆Saenko，2016）。除了 question answering 之外，约翰逊（Johnsonet）等。（2017a）提出了CLEVR（VQA）数据集来诊断推理模型 diagnose reasoning mode。CLEVR包含综合的视觉场景和从潜在程序生成的问题。表1将我们的模型与最新的视觉推理模型（Andreas等，2016; Suarez等，2018; Santoro等，2017）沿四个方向进行了比较：视觉特征，语义，推理和要求附加标签。 visual features, semantics, inference, and the requirement of extra labels</p>
<p>对于视觉表示 visual representations，Johnson等人（2017b）将视觉场景编码为程序操作符program operator 的 卷积特征图。    Mascharka等（2018）;  Hudson＆Manning（2018）使用注意力作为中间表示法来透明地执行程序。       最近，Yi等（2018）探索了用于视觉推理的可解释的，基于对象的视觉表示interpretable, object-based visual representation。它的表现很好，但是在训练过程中需要 有注释的场景 fully-annotated scenes。我们的模型还采用了基于对象的视觉表示，但是该表示只能在自然监督下学习（问题和答案）</p>
<p>Anderson et al. (2018) 也提出将图像表示为卷积对象特征convolutional object features的集合，并在VQA上获得了实质性的改进。他们的模型使用神经网络编码问题并通过  question-conditioned attention over the object features 来回答问题。相反，NS-CL将问题输入解析到程序中，并在对象特征上执行它们以获得答案。这使得<strong>推理过程可以解释</strong>，<strong>and supports combinatorial generalization over quantities (e.g., counting objects)</strong>。我们的模型还学习一般的视觉概念及其与语言符号表示的关联。然后，可以将这些学习到的概念明确地解释并部署到其他视觉语言应用程序中，例如图像标题检索</p>
<p>用于视觉推理的语义语句解析有两种方法：作为条件神经操作的隐式程序（例如，条件卷积和双重注意）（Perez等人，2018； Hudson＆Manning，2018）和显式程序作为序列象征性代币的交易（Andreaset等，2016; Johnson等，2017b; Mascharka等，2018）。作为代表，Andreas等人（2016年）基于用于回答问题的程序构建了模块化和结构化的神经体系结构，<strong>显式程序具有更好的可解释性，但通常需要额外的监督</strong>，例如用于训练的真实的程序注释。这限制了它们的应用。<strong>我们建议使用视觉基础作为远程监督， to parse questions in natural languages into explicit programs, with zero program annotations</strong>。给定问题的 semantic parsing，Yi等人。（2018）提出了一个纯粹的符号执行器 symbolic executor 来推理逻辑空间中的答案。与他们的相比，我们为VQA提出了一个we propose a quasi-symbolic executor for VQA</p>
<p><strong>我们的工作还涉及使用神经网络为视觉场景学习可解释和解耦的表示形式。</strong>Kulkarni等提出了卷积逆图形网络，用于学习和推断人脸姿势。（Yang et al2015年）从图像中学到了椅子姿势的 解耦表示disentangled representation。Wu等（2017）提出了神经场景去渲染框架，作为任何渲染过程的逆过程。Siddharth等; (2017)希金斯等。（2018）使用深度生成模型学习 解耦的表示形式。相反，我们提出了一种通过语言联合推理 joint reasoning的替代表示学习方法</p>
<h3 id="3-NEURO-SYMBOLIC-CONCEPT-LEARNER"><a href="#3-NEURO-SYMBOLIC-CONCEPT-LEARNER" class="headerlink" title="3    NEURO-SYMBOLIC CONCEPT LEARNER"></a>3    NEURO-SYMBOLIC CONCEPT LEARNER</h3><p>我们介绍了我们的神经符号概念学习器  neuro-symbolic concept learner，它使用符号推理过程来桥接视觉概念，单词和句子的语义解析的学习，而无需显式注释</p>
<p>我们首先使用视觉感知模块visual perception module ，构建基于对象的表示object-based representation for a scene，然后运行语义解析模块将问题semantic parsing module转换为可执行程序。然后我们使用 quasi-symbolic program executor使用这个场景目前所得到的representation来推断答案，我们<strong>使用paired images, questions, and answers 三元组 来共同训练视觉和语言模块</strong></p>
<p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/The Neuro-Symbolic Concept Learner Interpreting Scenes Words and Sentences From Natural Supervision/image-20200730163434248.png" alt="image-20200730163434248"></p>
<p><strong>用 symbolic, functional 的 modules 增加可解释性，可组合性和可泛化性</strong></p>
<p><strong>给定输入图像：</strong>(1) the visual perception module detects objects in the scene and extracts a deep, latent representation for each of them. (2) 语义分析模块负责将输入的问题解析为一个程序，这个程序是由该问题的领域特定语言（Domain Specific Language, DSL）中的操作定义的。(3) quasi-symbolic program executor根据视觉产生的场景描述和问题解析生成的可执行程序来回答问题  (4) 可微分，可以基于现有的优化器优化</p>
<h4 id="3-1-MODEL-DETAILS"><a href="#3-1-MODEL-DETAILS" class="headerlink" title="3.1  MODEL DETAILS"></a>3.1  MODEL DETAILS</h4><h5 id="视觉感知模块（Visual-perception）"><a href="#视觉感知模块（Visual-perception）" class="headerlink" title="视觉感知模块（Visual perception）"></a>视觉感知模块（Visual perception）</h5><p>对于视觉感知，研究人员使用了预训练的Mask R-CNN 作为 proposal generator 生成 object proposals。然后，由于需要获取到<strong>Object在场景中的位置信息</strong>，则将 The bounding box for each single object <strong>paired with the original image</strong> 输入到Res-Net-34，到的是不同的object feature. 一张图有多少个object 就有多少个object feature。bounding box 通过  RoI Align提取object区域内的特征 和 original image 提供基于图像的 context 特征信息(对于推断相关属性（例如大小或空间位置）必不可少)。 concatenate 两个特征 to represent each object</p>
<h5 id="视觉概念的量化（Concept-quantization"><a href="#视觉概念的量化（Concept-quantization" class="headerlink" title="视觉概念的量化（Concept quantization)"></a>视觉概念的量化（Concept quantization)</h5><p>进行视觉推理需要获取每个对象的属性（例如颜色、形状等）。每一个属性类别（<code>Attribute</code>，例如：颜色）可以有多个视觉概念（<code>Concept</code>，例如：红色、绿色）的取值。</p>
<p> <strong>In NS-CL, 视觉属性被实现为 neural operators (每个operator代表一个属性的投影方程)。</strong>operator 接收 Object 的 表示向量，将其映射到特定属性的编码空间（attribute specific embedding space）中的向量，并且与视觉概念在嵌入空间中的向量计算距离(论文中metric采用  cosine  distances $&lt;·,·&gt;$)，sigmoid输出[0,1]范围内的概率值，以此确定 object 在 object  attribute 的 object concept 值</p>
<p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/The Neuro-Symbolic Concept Learner Interpreting Scenes Words and Sentences From Natural Supervision/image-20200731090912827.png" alt="image-20200731090912827"></p>
<p>同样地，将 a pair of objects 间的关系分类成不同的 relational concepts (e.g.,Left) ，除了分类，我们将两个对象的视觉表示串联，以形成它们之间关系的表示</p>
<h5 id="DSL和语义分析（DSL-and-semantic-parsing）"><a href="#DSL和语义分析（DSL-and-semantic-parsing）" class="headerlink" title="DSL和语义分析（DSL and semantic parsing）"></a>DSL和语义分析（DSL and semantic parsing）</h5><p><strong>概括：</strong>语义分析模块负责将输入的问题解析为一个程序，这个程序是由 对领域 VQA 的特定语言（Domain Specific Language, DSL）中的操作定义的 一个有层次结构的程序。</p>
<p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/The Neuro-Symbolic Concept Learner Interpreting Scenes Words and Sentences From Natural Supervision/image-20200731100249802.png" alt="image-20200731100249802" style="zoom:80%;" /></p>
<p><strong>DSL</strong> 中包含的基本操作 for visual reasoning 有：such as <strong>filtering out objects with certain concepts</strong> or <strong>query the attribute of an object</strong>。 为了模块化，基本操作模块共享相同的输入和输出接口：</p>
<p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/The Neuro-Symbolic Concept Learner Interpreting Scenes Words and Sentences From Natural Supervision/image-20200731094828737.png" alt="image-20200731094828737"></p>
<p>有的操作对象是 Object 而不是 objectSet，这里有个<code>Unique</code> 的概念</p>
<p>具体实现上，该模块将 顺序句子转化成 树状结构。首先<code>a bidirectional GRU &#39;IEncoder&#39;</code>负责将自然语言编码成一个固定维度的向量；随后<code>decoder based on GRU cells &#39;OpDecoder&#39;</code>determines the operation tokens；  <code>ConceptDecoder</code>负责产生操作需要的Concept或Attribute参数；对于operation tokens输入为 non-concept input ，<code>OEncoder_i</code>将当前的state $f$  transform into 两个 sub-state $f_1, f_2$ 成为两个branch，如此递归执行。算法流程如下：</p>
<p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/The Neuro-Symbolic Concept Learner Interpreting Scenes Words and Sentences From Natural Supervision/LKj6I3eOF2xcZbh.png" alt="img" style="zoom:80%;" /></p>
<p>$c\{i\}$是 natural language 问句中出现过的所有Concept和Attribute的合集</p>
<p><strong>具体实现见文章的 附录</strong>B</p>
<h5 id="程序执行器"><a href="#程序执行器" class="headerlink" title="程序执行器"></a>程序执行器</h5><p>为了让最终结果（即程序执行器最终给出的答案）相对于模型参数（感知模块的参数、概念编码、Attribute操作符）可导，两者均采用基于概率的表示方法：输入是<code>Object</code> 类型变量的Representations，输出一个mask over object，mask长度为object数量，mask每个位置数值代表概率</p>
<p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/The Neuro-Symbolic Concept Learner Interpreting Scenes Words and Sentences From Natural Supervision/image-20200731104717152.png" alt="image-20200731104717152" style="zoom:80%;" /></p>
<p><strong>详见 appendix C</strong></p>
<h4 id="3-2-TRAINING-PARADIGM-训练方法"><a href="#3-2-TRAINING-PARADIGM-训练方法" class="headerlink" title="3.2  TRAINING PARADIGM 训练方法"></a>3.2  TRAINING PARADIGM 训练方法</h4><p><strong>优化目标</strong></p>
<p>训练目标是找到最优参数 $\Theta_V、\Theta_S$   $\Theta_V$ 是感知模块 Perception Module的参数(包括ResNet-34的参数，属性操作符的参数，concept embeddings)，$ \Theta_S$ 是语义分析模块Visually-Grounded Semantic Parser的参数，使得回答出正确答案的概率最大：</p>
<p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/The Neuro-Symbolic Concept Learner Interpreting Scenes Words and Sentences From Natural Supervision/image-20200731111058421.png" alt="image-20200731111058421" style="zoom:80%;" /></p>
<p><strong>如何优化这个目标函数？</strong></p>
<p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/The Neuro-Symbolic Concept Learner Interpreting Scenes Words and Sentences From Natural Supervision/image-20200731111330281.png" alt="image-20200731111330281" style="zoom:80%;" /></p>
<p>课程学习（Curriculum Learning）的训练方法，即先让模型学习简单的例子，然后慢慢扩展到复杂的场景</p>
<p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/The Neuro-Symbolic Concept Learner Interpreting Scenes Words and Sentences From Natural Supervision/image-20200731112319231.png" alt="image-20200731112319231" style="zoom:80%;" /></p>
<h3 id="4-EXPERIMENTS"><a href="#4-EXPERIMENTS" class="headerlink" title="4    EXPERIMENTS"></a>4    EXPERIMENTS</h3><h4 id="4-1-VISUAL-CONCEPT-LEARNING"><a href="#4-1-VISUAL-CONCEPT-LEARNING" class="headerlink" title="4.1  VISUAL CONCEPT LEARNING"></a>4.1  VISUAL CONCEPT LEARNING</h4><p><strong>Classification</strong></p>
<p>在  CLEVR 拆分的验证集中 evaluate the concept quantization</p>
<p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/The Neuro-Symbolic Concept Learner Interpreting Scenes Words and Sentences From Natural Supervision/image-20200731112828234.png" alt="image-20200731112828234" style="zoom:80%;" /></p>
<p><strong>Count</strong></p>
<p><strong>SOTA方法无法提供单个对象的可解释表示</strong>（Johnson等，2017a; Hudson＆Manning，2018; Mascharka等，2018）。为评估此类模型学习的视觉概念，我们生成了一个综合问题集。诊断问题集包含以下形式的简单问题：“有多少个红色物体？”。我们评估了CLEVR数据集中出现的所有概念的性能。</p>
<p>实验说明基于对象的视觉表示和符号推理有助于解释视觉概念。</p>
<h4 id="4-2-DATA-EFFICIENT-AND-INTERPRETABLE-VISUAL-REASONING"><a href="#4-2-DATA-EFFICIENT-AND-INTERPRETABLE-VISUAL-REASONING" class="headerlink" title="4.2  DATA-EFFICIENT AND INTERPRETABLE VISUAL REASONING"></a>4.2  DATA-EFFICIENT AND INTERPRETABLE VISUAL REASONING</h4><p>表4总结了CLEVR验证拆分的结果。我们的模型使用<strong>零程序注释</strong>（包括MAC（Hudson＆Manning，2018）和FiLM（Perez et al，2018））在所有基线中实现了最先进的性能。我们的模型通过强大的基线TbD-Nets（Mascharka et al。，2018）达到了可比的性能，它的<strong>语义解析器</strong>使用CLEVR中的700K程序进行了训练（我们<strong>需要0训练数目</strong>）。Yi等人最近的NS-VQA模型（2018）在CLEVR上取得了更好的性能;但是，他们的系统在训练过程中需要带注释的视觉属性和程序 trace，而<strong>我们的NS-CL不需要额外的标签</strong></p>
<p>在这里，<strong>视觉感知模块在ImageNet上进行了预训练</strong>（Deng等，2009）。如果不进行预培训，则概念学习的准确性平均下降0.2％，而QA准确性下降0.5％。同时，<strong>NS-CL可以准确地恢复基本的问题程序</strong>（准确度&gt; 99.9％）。NS-CL还可<strong>以检测到模棱两可或无效的程序并指示异常</strong>。有关更多详细信息，请参见附录F。NS-CL也可以应用于其他视觉推理测试平台。我们在Minecraft数据集上的结果请参考附录G.1（Yi等人，2018）。</p>
<p>为了对视觉特征和数据效率进行系统研究，我们实现了基线模型的两个变体：TbD-Object and MAC-Object。受（Anderson等人，2018）的启发，TbD-Object and MAC-Object 代替输入图像，而将<strong>a stack of 对象特征作为输入</strong>。TbD-Mask 和 MAC-Mask <strong>integrate the masks of objects</strong> by using them to <strong>guide the attention over the images</strong></p>
<p>这源于<strong>视觉概念学习和符号推理的完全解耦</strong>：如何根据所学概念concept 执行程序指令。</p>
<p>在我们的实验中， TbD-Object and MAC-Object 显示的结果较差。我们将其归因于模型架构的设计，并在附录F.3中进行了详细分析。尽管TbD-Mask和MAC-Mask的性能不比原始产品好，但我们发现using masks to guide attentions speeds up the training</p>
<h4 id="4-3-GENERALIZATION-TO-NEW-ATTRIBUTES-AND-COMPOSITIONS"><a href="#4-3-GENERALIZATION-TO-NEW-ATTRIBUTES-AND-COMPOSITIONS" class="headerlink" title="4.3  GENERALIZATION TO NEW ATTRIBUTES AND COMPOSITIONS"></a>4.3  GENERALIZATION TO NEW ATTRIBUTES AND COMPOSITIONS</h4><h5 id="Generalizing-to-new-visual-compositions"><a href="#Generalizing-to-new-visual-compositions" class="headerlink" title="Generalizing to new visual compositions."></a><strong>Generalizing to new visual compositions.</strong></h5><p>CLEVR-CoGenT数据集旨在评估模型推广到新视觉组成的能力。它具有 two splits: Split A 仅包含灰色，蓝色，棕色和黄色的立方体，但是包含红色，绿色，紫色和青色的圆柱体；split B 在立方体和圆柱体上施加了相反的颜色约束。<strong>如果我们直接在 split A 上学习视觉概念，则它会过度拟合以根据颜色对形状进行分类，从而导致split B 的泛化性很差</strong>  </p>
<p>我们的解决方案基于将属性视为运算符<strong>seeing attributes as operator的想法(感觉这里引入了先验的知识，有哪些attributes，强制学到这些attributes，而直接学习，没有强制学习这些attributes，可能因为attributes的冗余，只需要少量的attributes就能达到好的分类效果使得泛化能力差</strong> )。具体来说，我们在拆分A上联合训练概念嵌入（例如Red，Cube等）以及语义解析器，同时保留经过预训练的冻结属性运算符。当我们学习不同属性的不同表示空间时，我们的模型在A组中的准确性达到98.8％，在  split B 中的准确性达到98.9％</p>
<h5 id="Generalizing-to-new-visual-concepts"><a href="#Generalizing-to-new-visual-concepts" class="headerlink" title="Generalizing to new visual concepts."></a>Generalizing to new visual concepts.</h5><p>我们期望 concept learning 的过程可以逐步进行：学习了7种不同的颜色后，人类可以逐步有效地学习第8种颜色。为此，我们构建了CLEVR数据集的综合拆分，以复制增量概念学习的设置 replicate the setting of <strong>incremental concept learning</strong>。 Split A 仅包含没有任何紫色对象的图像，而 split B 包含具有至少一个紫色对象的图像。我们先在  split A 上训练了所有模型，并在 split B 中的100张图像上对其进行了微调。我们报告了 split B 的验证集的最终质量检查效果。所有模型都在完整的CLEVR数据集上使用了预训练的语义解析器。</p>
<h4 id="4-4-COMBINATORIAL-GENERALIZATION-TO-NEW-SCENES-AND-QUESTIONS"><a href="#4-4-COMBINATORIAL-GENERALIZATION-TO-NEW-SCENES-AND-QUESTIONS" class="headerlink" title="4.4  COMBINATORIAL GENERALIZATION TO NEW SCENES AND QUESTIONS"></a>4.4  COMBINATORIAL GENERALIZATION TO NEW SCENES AND QUESTIONS</h4><p>在小规模场景（仅包含少量对象）和简单问题（仅 single-hop 问题）上学习了视觉概念之后，我们人类可以轻松地将知识推广到更大范围的场景并回答复杂的问题。为了对此进行评估，我们将CLEVR数据集分为四个部分：<strong>Split A</strong> 仅包含少于6个对象的场景，以及由自然语言问题转换成的 latent programs 深度小于5的问题;     <strong>Split B</strong> 包含少于6个对象的场景，但是有任意问题;     <strong>Split C</strong>  问题包含任意场景，但将程序深度限制为小于5； <strong>Split D</strong>  包含任意场景和问题。   图6显示了一些说明性示例。</p>
<p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/The Neuro-Symbolic Concept Learner Interpreting Scenes Words and Sentences From Natural Supervision/image-20200731142738579.png" alt="image-20200731142738579"></p>
<p>由于VQA基线无法计算一组任意大小的对象，为了进行公平的比较，所有包含“ count”运算超过6个对象的程序都将从该集合中删除。</p>
<p>对于使用  explicit program semantics  的方法，语义解析器在完整数据集上进行预训练并固定。具有隐式程序语义的方法implicit program semantics (Hudson &amp; Manning, 2018) 学习了耦合的表示法以进行感知和推理，因为耦合所以无法简单地将其推广到更复杂的程序中，我们仅使用Split A的训练数据，然后在其他三个split上对泛化能力进行量化。如表5所示，我们的NS-CL可以将大范围场景和更复杂的问题几乎完美地泛化，在质量保证准确性方面，所有基线均优于至少4％。</p>
<p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/The Neuro-Symbolic Concept Learner Interpreting Scenes Words and Sentences From Natural Supervision/image-20200731143122080.png" alt="image-20200731143122080" style="zoom:80%;" /></p>
<h4 id="4-5-EXTENDING-TO-OTHER-PROGRAM-DOMAIN"><a href="#4-5-EXTENDING-TO-OTHER-PROGRAM-DOMAIN" class="headerlink" title="4.5  EXTENDING TO OTHER PROGRAM  DOMAIN"></a>4.5  EXTENDING TO OTHER PROGRAM  DOMAIN</h4><p>学到的视觉概念也可以用于其他领域，例如图像检索image retrieval。通过固定视觉场景，可以将学习到的视觉概念直接转移到新领域With <strong>the visual scenes fixed</strong>, the <strong>learned visual concepts</strong> can be directly transferred into the new domain.。我们只需要学习自然语言的语义解析到 新领域的DSL中。</p>
<p>我们建立了用于图像检索的综合数据集synthetic dataset，并采用了基于场景图的图像检索scene graph–based image retrieval （Johnson等，2015）中的DSL。数据集仅包含简单的标签 an $ <object A><relation> <object B> .”$（例如，There is a box right of a cylinder）。语义解析器学习从<strong>句子</strong>中提取<strong>相应的视觉概念（</strong>例如，box,right, and cylinder）。然后可以在视觉表示上执行该程序，以确定视觉场景是否包含此类关系三元组.</p>
<p>为了简单起见，我们将<strong>检索</strong>视为  <strong>classifying whether a relational triple exists in the image</strong>。无法在CLEVR VQA program domain 上直接实现此功能，因为如果场景中存在多个圆柱体，则诸如“圆柱体的盒子右边是否存在”之类的问题可能会模棱两可。由于视觉表示与特定的DSL 是耦合在一起的，因此在CLEVR QA上训练的基线无法直接应用于此任务。为了与它们进行公平的比较，我们在生成的 image-caption pairs 的子集上在表5b中显示了结果，其中底层程序对对象B的引用没有歧义。针对VQA基线训练了一个单独的语义解析器，which translates captions into a CLEVR QA-compatible program $(e.g.,Exist(Filter(Box, Relate(Right, Filter(Cylinder)))$</p>
<h4 id="4-6-EXTENDING-TO-NATURAL-IMAGES-AND-LANGUAGE"><a href="#4-6-EXTENDING-TO-NATURAL-IMAGES-AND-LANGUAGE" class="headerlink" title="4.6  EXTENDING TO NATURAL IMAGES AND LANGUAGE"></a>4.6  EXTENDING TO NATURAL IMAGES AND LANGUAGE</h4><p>我们进一步在MS-COCO（Lin等人，2014）图像上进行实验。结果显示在VQS数据集上（Gan等人，2017）。VQS包含来自原始VQA 1.0数据集的图像和问题的子集（Antol等，2015）。VQS数据集中的所有问题都can be visually grounded：每个问题都与多个图像区域相关联，这多个区域都是回答问题的必要条件人，于是都有标注。图7说明了VQS上NS-CL的执行轨迹</p>
<p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/The Neuro-Symbolic Concept Learner Interpreting Scenes Words and Sentences From Natural Supervision/image-20200731144606694.png" alt="image-20200731144606694" style="zoom:80%;" /></p>
<p>附录H中提供了有关NS-CL的其他示例性执行痕迹。除了回答问题以外，NS-CL还可以从数据中有效学习视觉概念。图8显示了学习到的视觉概念的示例，包括对象类别，属性和关系。实验设置和实现的详细信息在附录G.2中。</p>
<p>Indeed, visual question answering requires AI systems to reason about more general concepts such as events or activities (Levin, 1993). We leave the extension of NS-CL along this direction and its application to general VQA datasets (Antol et al., 2015) as future work</p>
<h3 id="5-DISCUSSION-ANDFUTUREWORK"><a href="#5-DISCUSSION-ANDFUTUREWORK" class="headerlink" title="5    DISCUSSION ANDFUTUREWORK"></a>5    DISCUSSION ANDFUTUREWORK</h3><h4 id="reference1"><a href="#reference1" class="headerlink" title="reference1"></a><a href="https://analyticsindiamag.com/now-a-model-that-learns-visual-concepts-words-and-semantic-parsing-of-sentences-without-explicit-supervision/">reference1</a></h4><p>神经符号概念学习器使用人工神经网络技术来从图像中提取特征并将信息构造为符号，然后将准符号程序执行器应用于模型，以基于场景表示(image)来推断问题的答案。</p>
<p>对于视觉感知，研究人员使用了预训练的Mask R-CNN技术，以便为所有对象生成对象建议object proposals。然后，采用Res-Net 提取基于区域和基于图像的特征。为了将自然语言问题转换为基本上设计用于视觉问题回答（VQA）的可执行程序，应用了语义解析模块 semantic parsing module。 </p>
<h5 id="Behind-the-Model"><a href="#Behind-the-Model" class="headerlink" title="Behind the Model"></a>Behind the Model</h5><p>研究人员使用称为<a href="https://cs.stanford.edu/people/jcjohns/clevr/">CLEVR</a>的数据集来测试深度学习模型。这是一个诊断数据集，有助于解决视觉问题解答（VQA）。该模型通过课程学习 curriculum learning 来学习，即从简单场景中的简短问题中学习单个对象的表示形式或概念representations or concepts开始。这有助于模型学习基于对象的概念 object-based concepts ，例如颜色和形状。然后，模型通过利用这些基于对象的概念来学习关系概念 relational concepts，去解释 对象引用 object referrals.。 </p>
<p>此外，该模型自然地学习了纠缠的视觉和语言概念，从而<strong>可以针对视觉场景和语义程序 visual scenes and semantic programs进行组合概括 combinatorial generalisation。</strong>在这种情况下，有四种形式的泛化，该模型首先泛化到比训练集中的场景具有更多对象和更长语义程序的场景。其次，模型推广到新的视觉属性组成visual attribute compositions。第三，它概括为能够快速适应新颖的视觉概念，最后，将学习到的视觉概念转移到诸如图像字幕检索之类的新任务上。</p>
<p>NS-CL包含以下三个模块：</p>
<ul>
<li><strong>基于神经的感知模块Neural-Based Perception Module：</strong>该模块通过从场景中提取对象级别的表示来工作</li>
<li><strong>可视化语义分析器Visually-Grounded Semantic Parser：</strong>此模块用于将问题翻译为可执行程序</li>
<li><strong>符号程序执行器Symbolic Program Executor：</strong>此模块读取对象的感知表示perceptual representation，对对象的属性或关系进行分类，然后执行程序以获得答案</li>
</ul>
<p>NS-CL的优势：</p>
<ul>
<li>这种深度学习模型以很高的准确率学习视觉概念。研究人员对所有物体属性的分类精度均达到近99</li>
<li>该模型允许在CLEVR数据集上进行数据高效的视觉推理。data-efficient visual reasoning</li>
<li>NS_CL很好地泛化到新属性，新视觉外观以及新的领域特定语言。</li>
<li>该模型可以直接应用于视觉问题解答（VQA）。</li>
</ul>
<h4 id="reference2"><a href="#reference2" class="headerlink" title="reference2"></a><a href="https://yym6472.github.io/2019/09/16/《The-Neuro-Symbolic-Concept-Learner-Interpreting-Scenes-Words-and-Sentences-from-Natural-Supervision》阅读笔记/#本文拟解决的问题">reference2</a></h4><h4 id="reference3-MIT-amp-IBM提出结合符号主义和连接主义的高效、准确新模型"><a href="#reference3-MIT-amp-IBM提出结合符号主义和连接主义的高效、准确新模型" class="headerlink" title="reference3-MIT&amp;IBM提出结合符号主义和连接主义的高效、准确新模型"></a><a href="https://zhuanlan.zhihu.com/p/68421615">reference3-MIT&amp;IBM提出结合符号主义和连接主义的高效、准确新模型</a></h4><h4 id="reference4-结合符号主义和深度学习，DeepMind提出新型端到端神经网络架构-PrediNet"><a href="#reference4-结合符号主义和深度学习，DeepMind提出新型端到端神经网络架构-PrediNet" class="headerlink" title="reference4-结合符号主义和深度学习，DeepMind提出新型端到端神经网络架构 PrediNet"></a><a href="https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650762961&amp;idx=4&amp;sn=0f60dcd50ecff53c60c40eb1bd25e17f&amp;chksm=871aaaafb06d23b98581c5a8dec180c6356d6c8e63665cd9990e37304b029d944242a8d29f01&amp;scene=21#wechat_redirect">reference4-结合符号主义和深度学习，DeepMind提出新型端到端神经网络架构 PrediNet</a></h4><h4 id="reference5—论文笔记"><a href="#reference5—论文笔记" class="headerlink" title="reference5—论文笔记"></a><a href="https://blog.csdn.net/weixin_40400177/article/details/99844864">reference5—论文笔记</a></h4><h4 id="Learning-to-Reason-End-to-End-Module-Networks-for-Visual-Question-Answering"><a href="#Learning-to-Reason-End-to-End-Module-Networks-for-Visual-Question-Answering" class="headerlink" title="Learning to Reason: End-to-End Module Networks for Visual Question Answering"></a><a href="http://ronghanghu.com/n2nmn/">Learning to Reason: End-to-End Module Networks for Visual Question Answering</a></h4>]]></content>
      <categories>
        <category>Visual Reasoning</category>
      </categories>
      <tags>
        <tag>CLEVR dataset</tag>
        <tag>NS-CL</tag>
        <tag>curriculum learning</tag>
        <tag>Mask R-CNN</tag>
      </tags>
  </entry>
  <entry>
    <title>Neural Module Networks</title>
    <url>/blog/2020/07/25/Neural%20Module%20Networks/</url>
    <content><![CDATA[<a id="more"></a>
<h3 id="『Neural-Module-Networks』阅读笔记"><a href="#『Neural-Module-Networks』阅读笔记" class="headerlink" title="『Neural Module Networks』阅读笔记"></a>『Neural Module Networks』阅读笔记</h3><ol>
<li>网络模块的基本组成，使得compositional 的 structure能覆盖大部分的问题</li>
<li>将自然语言问题 映射 到 布局 layouts，布局包括所用模块和模块间的连接关系，根据 layouts to assemble the final prediction networks。</li>
<li>自然语言问题通过<strong>依存句法分析和基本的词法处理</strong></li>
<li>因为动态的网络结构，some weights are updated much more frequently than others<strong>. 自适应学习率算法</strong>更好，但有人指出调参能力一般</li>
<li>Created <strong>SHAPES,</strong> a synthetic dataset that places such compositional phenomena at the forefront</li>
</ol>
<h3 id="code"><a href="#code" class="headerlink" title="code"></a><a href="https://github.com/jacobandreas/nmn2">code</a></h3><h3 id="专有名词"><a href="#专有名词" class="headerlink" title="专有名词"></a>专有名词</h3><ol>
<li><p><strong>VQA: </strong>   Visual question answering </p>
</li>
<li><p><strong>modeling common sense</strong> knowledge </p>
</li>
<li><p><strong>dataset biases</strong></p>
</li>
<li><p><strong>grounding the question in the image</strong>——grounding task</p>
</li>
<li><p><strong>更普遍地是利用 集理论 set-theoretic approaches  之于 经典语义解析方法 classical semantic parsing 和 注意方法attentional approaches 之于计算机视觉 之间的自然相似性。</strong></p>
</li>
<li><p><a href="https://bindog.github.io/blog/2018/02/10/model-explanation/">CAM 和 Grad-CAM</a></p>
</li>
<li><p><strong>lexical analysis——词法分析</strong> 是计算机科学中将字符序列转换为<strong>标记</strong>（token）序列的过程</p>
</li>
<li><p>adaptive per-weight learning rates</p>
</li>
<li><p>hard perceptual problems </p>
</li>
<li><p>monolithic network</p>
</li>
</ol>
<h3 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h3><p><strong>Visual question answering</strong> 本质上是<strong>组合的</strong>，——例如 where is the dog ？与 what color is the dog? where is the cat?  这些问题都<strong>有同样的语言学的子结构 substructure</strong> 。 本文旨在同时<strong>利用深层网络的表示能力  representational capacity 和 question的 语言结构  compositional linguistic structure</strong> 。建立和学习<strong>neural module networks</strong>，该过程将联合训练 jointly-trained 的模块 组成了用于回答问题的深层网络。 我们的方法<strong>将问题分解为它们的语言子结构 linguistic substructures，并使用这些结构动态实例化 模块化的网络 dynamically instan-tiate modular networks</strong>（具有可重复使用的组件， recognizing dogs, classifying colors 等 ）。由模块组合成的复合网络 are jointly trained。我们在两个具有挑战性的数据集上评估我们的方法，在 VQA natural图像数据集和有关抽象形状的复杂问题的新数据集上均获得了最新的结果</p>
<h3 id="1-Introduction"><a href="#1-Introduction" class="headerlink" title="1. Introduction"></a>1. Introduction</h3><p><strong>NMN——neural module networks</strong> 动态地基于语言结构，将模块是组成深层网络dynamically composed into deep networks based on linguistic structure.</p>
<p><strong>VQA</strong>这些问题需要计算机结合常识及视觉，语言的理解作出回答。</p>
<p><strong>recent work： </strong> </p>
<ol>
<li>将问题表示为词袋，或使用递归神经网络对问题进行编码[A neural-based approach to answering questions aboutimages.] 然后训练一个简单的分类器。</li>
<li>对于文本 QA[23] 和 图片 QA[27]，使用语义解析器 semantic parsers 将问题分解为逻辑表达式 logical expressions 。These logical expressions are evaluated against a purely logical representation of the world, which may be provided directly or extracted from an image [21]</li>
</ol>
<p><strong>并不是像传统的神经网络模型一样用一个整体，我们的方法是用多个模块化网络组合一个网络模型，模块是  specialized 和 jointly-learned。</strong> 不使用逻辑表达，<strong>我们模型输出的表达  remain entirely in the domain of visual features and attentions.</strong></p>
<p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/Neural Module Networks/image-20200724165527393.png" alt="image-20200724165527393"></p>
<p><strong>模型简要：</strong></p>
<ol>
<li>使用自然语言解析器解析每个问题，以此分析出回答问题所需要的基础组成单元（attention， classification 等）以及组成单元之间的联系。</li>
<li>以上图为例，首先产生一个对狗的attention，将其输出到位置描述器  location describer。</li>
<li>根据模型具体结构，模块间传递的这些消息可能是原始图像特征、attention或分类决策 classification decision；</li>
<li>每个模块将特定输入映射到输出类型。图中用不通的颜色表示不同的模块，用绿色表示attetion-producing模块(like dog)，用蓝色表示标签模块 labeling modules (like where)。需要注意的是，所有NMN中的模块都是独立的，可组合的，这使得NMN可以对每个问题实例组合成不同的网络，在测试中出现的结构，训练过程中可能并不曾出现过，NMN也能work。</li>
<li>除NMN以外，用LSTM模块去读取question，用来学习常识性的知识。</li>
<li>additional step which has been shown to be importantfor <strong>modeling common sense</strong> knowledge and <strong>dataset biases</strong>[28]</li>
</ol>
<p><strong>evaluation:</strong></p>
<ol>
<li><strong>VQA:  </strong> VQA数据集中的许多问题都非常简单，几乎不需要 composition or reasoning。</li>
<li>一个新的合成图像数据集，其中包含涉及空间关系，集合理论推理以及形状和属性识别的复杂问题。——SHAPES——This dataset consists of complex questions about simple arrangements of colored shapes ， 问题包含两个到四个属性，对象类型或关系。SHAPES数据集包含244个唯一问题，每个问题与64个不同的图像配对（总共15616个唯一问题/图像对，训练集中有14592个，测试集中有1024个）。</li>
</ol>
<p><strong>expension: </strong></p>
<p>尽管本文考虑的所有应用程序都涉及视觉问题解答，但该体系结构更为通用，可以轻松应用于视觉参照表达解析 visual referring expression resolution[9,34]或有关自然语言文本的问题 natural language texts 解答</p>
<h3 id="2-Motivations"><a href="#2-Motivations" class="headerlink" title="2. Motivations"></a>2. Motivations</h3><ol>
<li>There is no single “best network” for full range of computer vision tasks</li>
<li>用 a prefix of a network trained for classification 作为系统的初始状态是现在的常态，大幅减少训练时间并提高准确性</li>
</ol>
<p>因此，尽管网络结构不是通用的（就同一网络而言，它适用于所有问题），但它们至少在经验上是模块化的（就一项任务而言，中间表示对于许多其他任务都是有用的）</p>
<p>语言的组成性质意味着此类步骤的处理数量可能不受限制，从问题和图像到答案的回答过程看成  highly-multitask learning setting。<strong>Moreover, multiple kinds f processing might be required—repeated convolutions might identify a truck, but some kind of recurrent architecture is likely necessary to count up to arbitrary numbers.</strong></p>
<p>所以构建 modular, composable, jointly-trained neural networks.</p>
<h3 id="3-Related-work"><a href="#3-Related-work" class="headerlink" title="3. Related work"></a>3. Related work</h3><h5 id="1-Visual-Question-Answering"><a href="#1-Visual-Question-Answering" class="headerlink" title="1. Visual Question Answering"></a>1. Visual Question Answering</h5><p>回答有关图像的问题有时称为“视觉图灵测试”，在由配对图像，问题和答案组成的合适的数据集出现之后变得热门。</p>
<p> <strong>DAQUAR dataset</strong> 仅限于室内场景 indoor scenes，并且包含的示例相对较少。</p>
<p><strong>COCOQA数据集 </strong> 和  <strong>VQA数据集</strong>  明显更大，并且具有更多的视觉多样性 visual variety。两者都是基于来自<strong>COCO dataset</strong> 的图像。尽管 COCOQA 包含从与 COCO 数据集相关联的描述 descriptions 中自动生成的问题-答案对，但 has crowed sourced questions-answer pairs 。我们评估了VQA的方法，这是两个数据集中更大，更自然的一个。</p>
<p><strong>“经典”方法包括[27,21]</strong>。这两种方法在<strong>使用 semantic parser</strong> 上类似于我们的方法，但是它们<strong>依赖于固定的逻辑推理器 logical inference</strong> ，而<strong>不是学习的合成操作  compositional operations</strong> 。</p>
<p>文献[33,26,10]中已经提出了<strong>几种用于 视觉询问 visual questioning  的神经模型</strong>，所有这些模型都使用<strong>标准的深层序列建模机制 deep sequence modeling machinery </strong>来<strong>构造图像和文本的联合嵌入</strong>，并<strong>立即将其映射 a distribution over answer</strong> 。在这里，我们<strong>试图更显式地对产生每个答案所需的计算过程进行建模</strong>，但是受益于产生序列和图像嵌入的技术，这些技术在先前的工作中已经变得很重要。</p>
<p><strong>视觉质询 visual questioning 的一个重要组成部分是在图像中定位问题</strong>。[18,32,17,20,14]中完成了 <strong>grounding task 这种基础任务</strong>，在此作者试图在图像中的定位短语 localize phrases in an image[39]，使用<strong>注意力机制预测句子生成过程中每个单词的热图 predict a heatmap for each word during sentence generation</strong>。这些方法启发了我们模型的<strong>注意力成分</strong>。</p>
<h5 id="2-General-compositional-semantics"><a href="#2-General-compositional-semantics" class="headerlink" title="2. General compositional semantics"></a>2. General compositional semantics</h5><p>在学习 <strong>如何回答 question–answer pairs 中有关结构化知识表示的问题时，有大量文献，无论有没有联合学习简单谓词的意义  meanings  [23,21]</strong>。 <strong>回答问题的 task 之外</strong>，已经提出了几种用于<strong>指令跟随的模型</strong>，这些<strong>模型在底层连续控制信号上施加了离散的“planning structure”  [</strong>1,30]。我们没有意识到过去<strong>使用 语义解析器 来预测网络结构</strong>，或<strong>更普遍地是利用 集理论 set-theoretic approaches  之于 经典语义解析方法 classical semantic parsing 和 注意方法attentional approaches 之于计算机视觉 之间的自然相似性。</strong></p>
<h5 id="3-Neural-network-architectures"><a href="#3-Neural-network-architectures" class="headerlink" title="3. Neural network architectures"></a>3. Neural network architectures</h5><p>为每个输入数据选择不同的网络图的想法是<strong>递归网络（其中网络随着输入长度的增长而增长）</strong>和<strong>递归神经网络（例如根据句法结构构建网络）</strong>的基础（36）。但是，这两种方法最终都涉及到单个计算模块（例如LSTM [13]或GRU [5]单元）的重复应用。从另一个方向看，某些类型的存储网络[38]可以看做是我们模型的一种特殊情况，带有固定的计算图，由一列   <strong><em>find</em></strong>  modules  和 一个 describe module  组成。具有模块化子结构的其他 policy- and algorithm-learning approaches 包括[16,4]。[31]描述了一种程序，该程序用于学习从行为被完全指定的  functional primitives 集合中汇编程序的过程。</p>
<p><strong>主要的贡献： </strong>  动态组装模块，同时允许节点执行不同类型的“消息”（原始图像特征，关注度和分类预测）来进行异构计算并在模块间传递“消息”</p>
<h3 id="4-Neural-module-networks-for-visual-QA"><a href="#4-Neural-module-networks-for-visual-QA" class="headerlink" title="4. Neural module networks for visual QA"></a>4. Neural module networks for visual QA</h3><p>每个训练的数据项被想象成一个三元组$(w,x,y)$:</p>
<ul>
<li>$w$  is a natural-language question</li>
<li>$x$  is an image</li>
<li>$y$  is an answer</li>
</ul>
<p>整个模型由<strong>一个模块集 $\{m\}$</strong> 完全指定，<strong>相关参数为 $\theta_m$，</strong>以及  <strong>a network layout predictor</strong>   $P$  ，它<strong>将字符串映射成网络</strong>。给定 $(w,x)$ ，通过 $P(w)$ 实例化一个网络。并使用 $x$（或 $w$ ）作为输入，得到一个关于标签的分布( (for the VQA task, we require the output module produce an answer representation))。所以预测分布  predictive distribution 可以表示为 $p(y|w, x; \theta)$</p>
<h4 id="4-1-Modules"><a href="#4-1-Modules" class="headerlink" title="4.1. Modules"></a>4.1. Modules</h4><p>我们的目标是确定可以组装为任务所需的所有配置的<strong>一小部分模块  modules  </strong>。这<strong>对应于识别可组合的视觉原语  composable vision primitives 的最小集合</strong>。这些模块操作<strong>三种基本数据类型：图像， unnormalized attentions 和 标签 labels</strong>。对于本文描述的特定任务和模块，<strong>几乎所有有趣的组合现象都发生在 注意力空间 the space of attentions 中</strong>，并且将我们的贡献更狭义地描述为“注意力组合”网络并非没有道理。但是，将来可能会轻松添加其他类型（用于新应用或在VQA域中具有更大的覆盖范围）    </p>
<p><strong>Notion:</strong>  $\text{TYPE<a href="ARG_1...">INSTANCE</a>}$</p>
<p><strong>example:  </strong> $\text{}$ $\text{find[red]}$ locates red things;      $\text{find[dog]}$  locates dogs</p>
<p><strong>Weights may be shared at both the type and instance level</strong></p>
<p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/Neural Module Networks/image-20200725094320268.png" alt="image-20200725094320268"></p>
<p>$\text{find[c]}$  ：对图像卷积 with a weight vector ,不同 c 是不同的 weight vector，生成 a heatmap or unnormalized attention.</p>
<p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/Neural Module Networks/image-20200725101355203.png" alt="image-20200725101355203"></p>
<p>$\text{transform[c]}$ ：多层感知机实现， performing a fully-connected mapping from one attention to another。不同 c 是不同的 mapping  weight。<strong>作用：</strong> <strong>take an attention and shift the regions of greatest activation upward</strong> 。<strong>$\text{transform[not]}$  should move attention awayfrom the active regions</strong>  实验经验说明，第一个FC层输出向量大小为32，第二个FC输出和transform的输入维度一致</p>
<p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/Neural Module Networks/image-20200725102011503.png" alt="image-20200725102011503"></p>
<p>$\text{combine[c]}$ ： <strong>作用  merges two attentions into a single attention</strong>   $\text{combine[and]}$ ： be active only in the regions that are active <strong>in both inputs</strong>     $\text{combine[or]}$ ： be active where the <strong>first input isactive and the second is inactive</strong>    </p>
<p><strong>transform 和 combine 对应的 问题</strong> —— 识别shape 和 color ，以及 其中的 空间上和 逻辑上的联系，需要转移 和 组合 attention</p>
<p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/Neural Module Networks/image-20200725140429705.png" alt="image-20200725140429705"></p>
<p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/Neural Module Networks/image-20200725102258978.png" alt="image-20200725102258978"></p>
<p>$\text{describe[c]}$  输入：an attention and the input image 。 将两者映射到关于 label 的分布。<strong>过程： </strong> <strong>first computes an average over image features weighted by the attention；  then passes this averaged feature vector through a single fully-connected layer</strong>  例如，describe [color]应该返回所关注区域中颜色的表示</p>
<p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/Neural Module Networks/image-20200725102646051.png" alt="image-20200725102646051"></p>
<p>$\text{measure[c]}$  <strong>takes an attention alone and maps it to a distribution over label</strong>  由于模块之间传递的 attention 是没经过 normalization 的， 所以经过 <strong>$\text{measure}$ 模块可以  evaluating the existence of a detected object, or counting sets of objects</strong></p>
<h4 id="4-2-From-strings-to-networks"><a href="#4-2-From-strings-to-networks" class="headerlink" title="4.2. From strings to networks"></a>4.2. From strings to networks</h4><p>已经建立了模块集合，就需要将它们根据不同问题组装成不同的网络布局。从自然语言问题到神经网络实例化有两个步骤。</p>
<ol>
<li>我们 将自然语言问题 映射 到 布局 layouts，布局包括所用模块和模块间的连接关系；</li>
<li>根据 layouts to assemble the final prediction networks.</li>
</ol>
<p>对<strong>自然语言问题</strong>：use <strong>standard tools pretrained on existing linguistic resources</strong> to obtain <strong>structured representations of questions</strong></p>
<p>之后对这一块的修改，可以是将 question 的结构化表示预测 可以和 后面的 jointly learn</p>
<h4 id="Parsing"><a href="#Parsing" class="headerlink" title="Parsing"></a>Parsing</h4><p>作者使用 <a href="http://nlp.stanford.edu:8080/parser/">Stanford Parser</a> 对每个问题进行解析，<strong>依存句法分析</strong> 表达了句子各部分之间（例如，<strong>对象及其属性或事件及其参与者之间的语法关系</strong>），并提供了一种轻量级的抽象，使其脱离了句子的表面形式。解析器还执行基本的词法处理 lemmatization,，例如将 kites 转成  kite 和  were  转成   be。这减少了模块实例的稀疏性——标准化减少空间。</p>
<p>接下来，我们<strong>过滤出</strong> 与<strong>问题中</strong>的 <strong>wh词疑问词</strong>  和 <strong>copula系动词</strong> 相关联的 <strong>依存关系集</strong>（遍历的确切距离 根据任务的不同 而变化 以及 $how many$ 是作为特殊情况对待 ）。这给出了一个简单的符号形式来表达句子含义的（主要）部分。比如， what is standing in the field 变成了 what(stand)； what color is the truck 变成了 color(truck)；is there a circle next to a square 变成了is(circle, next-to(square))。</p>
<ul>
<li>这些表示与组合逻辑  combinatory logic  [23]有一些相似之处：每个<strong>叶节点都是隐含的以图像为输入的函数，而根表示计算的最终值</strong>。但是，尽管我们的方法是compositional and combinatorial 的，但不是 logical 的： 推论计算对神经网络产生的连续表示进行操作，仅在最终答案的预测中变得离散（啥？）</li>
</ul>
<h4 id="Layout"><a href="#Layout" class="headerlink" title="Layout"></a>Layout</h4><p><strong>modules 的确定 取决于 the structure of the parse</strong></p>
<p><strong>所有的 leaves 都是 $\text{find}$ modules， 所有中间节点都是 $\text{transform}$  或是  $\text{combine}$ modules， dependent on their arity，所有 root 节点 是  $\text{describe}$  或是  $\text{measure}$  depending on the domain</strong> </p>
<p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/Neural Module Networks/image-20200725112729958.png" alt="image-20200725112729958" style="zoom:80%;" />网络结构相同的，在同一个 batch 中处理</p>
<p>此转换过程的某些部分是特定于任务的，我们发现相对简单的表达式最适合自然图像问题 natural image questions，而合成数据（通过设计）则需要更深层次的结构</p>
<h4 id="Generalizations"><a href="#Generalizations" class="headerlink" title="Generalizations"></a>Generalizations</h4><p>输入到 layout 的 input 可以是 natural language parser出来的 dependencies ，也可以是 SQL-like queries </p>
<h4 id="4-3-Answering-natural-language-questions"><a href="#4-3-Answering-natural-language-questions" class="headerlink" title="4.3. Answering natural language questions"></a>4.3. Answering natural language questions</h4><p>我们的最终模型将<strong>神经模块网络的输出</strong> 与 simple <strong>LSTM question encoder 的预测  prediction</strong> 相结合。(提供问题的完整信息)</p>
<ol>
<li>因为 <strong>Parsing</strong> 后的简单表示   what <strong>is</strong> standing in the field 变成了 what(stand)  不会实质性地改变问题的语义的语法提示被丢弃。 The question encoder thus allows us to model underlying <strong>syntactic regularities 句法规则</strong> in the data。</li>
<li>allows us to capture <strong>semantic regularities</strong> 语义规律  it is reasonable to guess that <em>what color is the bear?</em>    is answered by <strong>brown</strong> ，unreasonable to guess <strong>green</strong></li>
</ol>
<p>为了计算 answer，我们<strong>将LSTM的 final hidden state 通过一个 FC</strong>，将其 逐元素 添加到 NMN 的根模块生成的表示中，应用ReLU非线性，然后另一个 FC 层， 一个 softmax  obtain a distribution over answers.</p>
<p>为了与以前的工作保持一致，我们将答案预测视为一个纯粹的分类问题：<strong>该模型从训练过程中观察到的答案中选择（无论它们是否包含多个单词）</strong>，并将<strong>每个答案视为不同的类别</strong>。因此，在该最终预测层中的，例如 <em>left side</em> 和 <em>left</em>  之间没有共享参数。通过循环解码器一次生成一个单词得到的多单词答案的模型可以作为 extension</p>
<h3 id="5-Training-neural-module-networks"><a href="#5-Training-neural-module-networks" class="headerlink" title="5. Training neural module networks"></a>5. Training neural module networks</h3><p><strong>objective：  </strong>  find module parameters maximizing the likelihood of the data——softmax 结果</p>
<p>最后一层都是设计成 输出 在 label 上的概率分布，  so each assembled network also represents a probability distribution.  (视为分类问题)</p>
<p>由于用于回答问题的动态网络结构，某些权重比其他权重更频繁地更新。因此，我们发<strong>现具有单个权重自适应学习率 adaptive per-weight learning rates  的学习算法</strong>在性能上要比简单的梯度下降好得多。下面描述的所有实验<strong>均使用具有标准参数设置的 ADADELTA</strong></p>
<h3 id="6-Experiments-compositionality"><a href="#6-Experiments-compositionality" class="headerlink" title="6. Experiments: compositionality"></a>6. Experiments: compositionality</h3><p>这项工作的主要目标之一是学习用于深层语义组合的模型 deep semantic compositionality。 To eliminate mode-guessing as a viable strategy, all questions have a yes-or-no answer, but good performance requires that the system learn to recognize shapes and colors, and understand both spatial and logical relations among sets of objects.——为了消除模式猜测作为一种可行的策略，所有问题都回答是或否，但是良好的性能要求系统学会识别形状和颜色，并理解各组图形之间的空间关系和逻辑关系对象</p>
<p>为了产生一组初始的图像特征，我们将输入图像通过LeNet [22]的卷积部分，这个卷积部分与模型的  question-answering 部分共同训练。我们比较了我们的方法 与 以类似于[33]所述的方法 重新实现的 VIS + LSTM 基线，再次用LeNet替换了预先训练的图像嵌入。</p>
<p>此外，颜色检测器和注意力转换的行为符合预期（图2b），表明我们的联合训练模型正确地在模块之间分配了责任。这证实了我们的方法能够对复杂的组成现象进行建模，而先前的方法无法解决视觉问题。</p>
<h3 id="7-Experiments-natural-images"><a href="#7-Experiments-natural-images" class="headerlink" title="7. Experiments: natural images"></a>7. Experiments: natural images</h3><p>处理涉及自然图像的硬性感知问题 hard perceptual problems </p>
<p>we <strong>evaluate on the VQA dataset</strong>  ，这是同类资源中最大的一种，由来自MSCOCO的200,000张图像组成[25]，每张图像都由人类注释者生成的三个问题和每个问题十个答案配对。我们使用标准训练/测试集划分 ，仅训练那些 answer 标记 为高置信度的模型。</p>
<p> <strong>The visual input to the NMN</strong>   is <strong>the conv5 layer of a 16-layer VGGNet</strong> [35] after max-pooling, with features normalized to have mean 0 and standard deviation 1.  出来 在 ImageNet 上预训练的 VGG，还比较了在  MSCOCO  上  fine-tuned 过的 VGG。</p>
<p>我们发现，即使始终在问题上涉及 量化 quantification，顶层模块 总是 <strong>describe</strong>，才能最好地完成此任务。</p>
<p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/Neural Module Networks/image-20200725144242301.png" alt="image-20200725144242301" style="zoom:80%;" /></p>
<p>compare to ：</p>
<ol>
<li>a text-only baseline (LSTM), </li>
<li>a pre-vious baseline approach that predicts answers directly from an encoding of the image and the question [3]</li>
<li>an at-tentional baseline (ATT+LSTM). This last baseline shares the basic computational structure of our model without syntactic compositionality: it uses the same network layout for every question (a <strong>find</strong> module followed by a <strong>describe</strong> module), with parameters tied across all problem instances</li>
</ol>
<p>稀有 rare 单词（在训练数据中出现的次数少于10次）被映射到LSTM编码器和模块网络中的单个 tolen 或 模块实例。</p>
<p>对解析器输出的调查还表明，使用更好的解析器还有很大的空间可以改进系统性能。</p>
<p><strong>通过手动检查发现： more complicated questions are more prone to picking up irrelevant predicates. 问题一复杂，可能找到不相关的谓词 。For example $\text{are these people most likely experiencing a workday?}$   is parsed as  $\text{be(people,  likely)}$   when the desired analysis is   $\text{be(people,  work)}$.   Parser errors of this kind could be fixed with joint learning. 即 parse过程和后面的 module 选择等一起learn。</strong></p>
<p><strong>系统做出的谓词误判，包括可能的语义混淆（将纸板解释为皮革，将圆形窗框解释为时钟）(cardboard interpreted as leather, round windows interpreted as clocks)、 正常的词汇变化lexical variation（<em>container</em> for <em>cup</em>），以及使用优先级高但与图片无关的答案（describing a horse as located in a pen rather than a barn）。</strong></p>
<h3 id="8-Conclusions-and-future-work"><a href="#8-Conclusions-and-future-work" class="headerlink" title="8. Conclusions and future work"></a>8. Conclusions and future work</h3><p>到目前为止，我们在预测网络结构 (dependency parse) 和学习网络参数之间保持了严格的区分。It is easy to imagine that these two problems might be solved jointly，但在整个训练和解码过程中，网络结构的不确定性仍然存在。这可以通过使用某些高级机制“参与”计算的相关部分，或者通过与现有的用于学习语义分析器learning semantic parsers的工具集成，来通过单片网络 monolithic network 来完成。<strong>我们在这项工作的后续工作中描述了联合学习模块行为和解析器的第一步[2]</strong>。</p>
<p>事实上，我们的神经模块网络可以训练以产生可预测的输出（即使自由组合），这一事实指向了更通用的“程序”范式。由神经网络构建而成。在这种范式中，网络设计人员（人工或自动化）可以访问神经零件的标准套件，从中构造用于执行复杂推理任务的模块。虽然视觉问题回答为该方法提供了自然的测试平台，但它的用途可能更广泛，可扩展到有关文档和结构化知识库的查询，或者扩展到更通用的函数逼近和信号处理。46</p>
<h4 id="reference1"><a href="#reference1" class="headerlink" title="reference1"></a><a href="https://jimlee4530.github.io/Neural Module Networks实验笔记及总结">reference1</a></h4><h4 id="reference2"><a href="#reference2" class="headerlink" title="reference2"></a><a href="https://bair.berkeley.edu/blog/2017/06/20/learning-to-reason-with-neural-module-networks/">reference2</a></h4><h4 id="reference3"><a href="#reference3" class="headerlink" title="reference3"></a><a href="http://ronghanghu.com/n2nmn/">reference3</a></h4>]]></content>
      <categories>
        <category>Visual Reasoning</category>
        <category>VQA</category>
        <category>Neural Module Networks</category>
      </categories>
      <tags>
        <tag>dependency parsing</tag>
        <tag>CLEVR dataset</tag>
        <tag>SHAPES dataset</tag>
        <tag>dynamic network structure</tag>
      </tags>
  </entry>
  <entry>
    <title>DL2- TRAINING AND QUERYING NEURAL NETWORKS WITH LOGIC</title>
    <url>/blog/2020/07/23/DL2%20TRAINING%20AND%20QUERYING%20NEURAL%20NETWORKS%20WITH%20LOGIC/</url>
    <content><![CDATA[<a id="more"></a>
<h3 id="『』阅读笔记"><a href="#『』阅读笔记" class="headerlink" title="『』阅读笔记"></a>『』阅读笔记</h3><ol>
<li>将rules 逻辑规则，论文中的是在网络中纳入约束。方式是通过将 包含逻辑比较符号以及合取析取求反的rules通过论文中给出的<strong>转化</strong>方式转化成几乎处处<strong>可微的损失函数</strong>。</li>
<li>将逻辑约束转换为具有所需数学特性的可微分损失函数 differentiable loss，基于标准梯度方法进行优化</li>
<li>用期望来建模，把最大化满足约束找到满足的输入集转化成最小化对约束的最大冲突，然后拆成内部的最大化目标，找到满足的输入集，再带入外部的最小化目标，优化网络的参数。</li>
<li>因为 3 中描述的第一步往往很难优化，因此对输入的变量 z 先投影到一个 convex set，而不是将变量是从convex set采样的作为constraint</li>
</ol>
<h4 id="code-for-DL2"><a href="#code-for-DL2" class="headerlink" title="code for DL2 "></a><a href="https://github.com/eth-sri/dl2">code for DL2 </a></h4><h4 id="project-地址"><a href="#project-地址" class="headerlink" title="project 地址"></a><a href="https://www.sri.inf.ethz.ch/publications/fischer2019dl2">project 地址</a></h4><h3 id="专有名词"><a href="#专有名词" class="headerlink" title="专有名词"></a>专有名词</h3><ol>
<li><p>projected gradient descent (PGD)</p>
</li>
<li><p>In <a href="https://en.wikipedia.org/wiki/Mathematical_logic">mathematical logic</a>, a <strong>literal</strong> is an <a href="https://en.wikipedia.org/wiki/Atomic_formula">atomic formula</a> (atom) or its <a href="https://en.wikipedia.org/wiki/Negation">negation</a>.</p>
<p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/DL2 TRAINING AND QUERYING NEURAL NETWORKS WITH LOGIC/image-20200729110021659.png" alt="image-20200729110021659" style="zoom:80%;" /></p>
</li>
<li><p>convex combination： <a href="[https://zh.wikipedia.org/wiki/%E5%87%B8%E7%BB%84%E5%90%88](https://zh.wikipedia.org/wiki/凸组合">凸组合</a>)  <a href="https://math.stackexchange.com/questions/910612/convex-combination-of-3-point-in-r2-and-triangle">Convex Combination of 3 point in R2 and Triangle</a></p>
</li>
<li><p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/DL2 TRAINING AND QUERYING NEURAL NETWORKS WITH LOGIC/image-20200729170259031.png" alt="image-20200729170259031" style="zoom:80%;" /><strong>(什么方法？)</strong></p>
</li>
<li><p><a href="https://en.wikipedia.org/wiki/Logit">Logit</a></p>
</li>
<li><p>regression taskin an unsupervised setting, namely training MLP (Multilayerperceptron)</p>
</li>
</ol>
<h3 id="ABSTRACT"><a href="#ABSTRACT" class="headerlink" title="ABSTRACT"></a>ABSTRACT</h3><p>我们提出了DL2，这是一种用于训练和查询具有逻辑约束的神经网络的系统。DL2比以前的工作更具表现力，并且可以捕获对模型的输入，输出和内部的更丰富的约束  a richer class of constraints on inputs,  outputs and internals of model。使用DL2，可以声明性地指定要在模型上训练 或 在查询期间要强制注入的领域知识，其<strong>目的是找到满足给定约束的输入</strong>。DL2的工作原理是将逻辑约束转换为具有所需数学特性的可微分损失函数 differentiable loss ，然后最小化该损失，基于标准梯度方法。</p>
<h3 id="1-INTRODUCTION"><a href="#1-INTRODUCTION" class="headerlink" title="1  INTRODUCTION"></a>1  INTRODUCTION</h3><p>一个关键挑战是<strong>使神经网络更可靠 reliable</strong>。解决这一挑战的可行方向是<strong>在培训过程中纳入约束条件 incorporating constraint</strong>（Madry等人，2017; Min-ervini等人，2017），并通过<strong>执行具体查询来检查已经受过训练的网络</strong>（Goodfellowet等人，2014b; Pei等人，2017;徐等人，2018））。尽管这些方法很有用，但它们被描述并硬编码 described and hardcoded 为特定种类的约束，从而使其难以应用于其他环境。</p>
<p>受先前工作的启发（例如，Cohen等人（2017）; Fu＆Su（2016）; Hu等人（2016））; Bach等人（2017）），我们引入了一种新的方法和系统，称为DL2（具有可微分逻辑with Differentiable Logic)的深度学习的缩写），可用于</p>
<ol>
<li><strong>查询网络中满足约束条件的输入，</strong></li>
<li><strong>训练网络以满足逻辑规范 logical specification，所有这些都是声明式的</strong></li>
</ol>
<p><strong><em>我们的约束语言 constraint language 可以使用求反，合取和析取negations, conjunctions, and disjunctions  在神经网络的输入，神经元和输出上表达算术比较arithmetic comparisons 的丰富组合</em>。</strong>得益于它的表现力，DL2使用户能够在训练期间加强领域知识或与网络进行交互，以便通过查询来了解其行为</p>
<p>DL2通过将逻辑约束<strong>转换为具有两个关键属性的非负损失函数</strong>来工作：</p>
<ol>
<li><strong>（P1）损失为零的值可以保证满足约束条件，</strong></li>
<li><strong>（P2）损失函数 都是可微分的。</strong></li>
</ol>
<p>这些属性相结合，使我们能够通过使用 现成的优化器 将损失降到最低 来 解决带有约束的神经网络 的 查询或训练的问题。</p>
<h4 id="Training-with-DL2"><a href="#Training-with-DL2" class="headerlink" title="Training with DL2"></a>Training with DL2</h4><p>为了使优化易于处理，我们<strong>排除了捕获凸集的输入约束，并将其作为优化目标的约束</strong>。我们使用<strong>投影梯度下降进行优化 projected gradient descent (PGD)</strong>，该方法<strong>在进行具有鲁棒性约束robustness constraints的训练</strong>是成功的(Madryet al., 2017). DL2的表现力以及通过PGD进行的易于处理的优化使我们能够训练新的有趣约束，比如：我们可以表达对概率的约束，而网络无法明确计算这些内容</p>
<p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/DL2 TRAINING AND QUERYING NEURAL NETWORKS WITH LOGIC/image-20200728221751057.png" alt="image-20200728221751057"></p>
<p>上面这个约束，在CIFAR-100的背景下，对于任何网络输入 x（网络由θ参数化），$people$  的概率 $p_{people}$  很小或很大。但是，CIFAR-100没有 $people$  这个类别，因此我们将其定义为 <em>a function of <strong>other probabilities</strong></em> <img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/DL2 TRAINING AND QUERYING NEURAL NETWORKS WITH LOGIC/image-20200728222100274.png" alt="image-20200728222100274" style="zoom:80%;" />我们显示，在类似的约束条件下（但有20个类），DL2在<strong>半监督的情况下</strong>提高了CIFAR-100网络的预测精度.</p>
<p>DL2 可以<strong>捕获在分类和回归任务中产生的约束</strong>。例如， GalaxyGAN （Schawinski等人，2017）要求网络遵守底层物理系统施加的约束，例如 通量flux：输入像素之和应等于输出像素之和。现在可以使用DL2，用声明性的方式表示为：$sum(x)= sum(\text{GalaxyGAN(x)})$，而不是将这种约束硬性地硬编码到网络中。</p>
<h4 id="Global-training"><a href="#Global-training" class="headerlink" title="Global training"></a>Global training</h4><p>DL2的一个<strong>突出特点是它能够训练对输入施加限制的约束 outside the training set</strong></p>
<p>先前关于约束训练的工作（例如Xu等人（2018））专注于给定的训练集，以对网络进行<strong>本地训练 local training</strong>以满足约束。使用DL2，我们可以首次 <strong>query for inputs</strong> which are <strong>outside the training set</strong>, and use them to <strong>globally train the network </strong>.</p>
<p>在 examples outside the training set 上进行训练的先前方法要么针对特定任务量身定制（Madry等，2017），要么针对网络类型（Minervini等，2017）。</p>
<p>我们的方法将全局训练的任务划分为：（i）<strong>优化器</strong>，它训练网络满足对输入的约束  the constraints for the given inputs，以及（ii）<strong>oracle</strong>，它为优化器提供旨在违反约束的新输入，考虑以下 Lipschitz 条件：</p>
<p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/DL2 TRAINING AND QUERYING NEURAL NETWORKS WITH LOGIC/image-20200728230500048.png" alt="image-20200728230500048" style="zoom:80%;" /></p>
<p>上式说明，对于训练集中的两个输入 $x^1,x^2$ ，在其 $\epsilon$ - neighborhood $(z^q,z^2)$ must satisfy the condition</p>
<p>如果满足Lipschitz条件，则神经网络会更稳定。</p>
<h4 id="Querying-with-DL2"><a href="#Querying-with-DL2" class="headerlink" title="Querying  with  DL2"></a>Querying  with  DL2</h4><p>我们还设计了一种类似于SQL的语言，该语言使用户能够通过声明式查询posing declarative queries  来与模型进行交互。例如，考虑一下近期工作研究的场景（Song等人，2018），其中作者展示了如何使用AC-GAN生成对抗性示例（Odena等人，2016）。生成器用于从某个类别（例如类别1）创建图像，而该图片会混淆分类器（例如分类为7）。对于DL2，这可以表述为：</p>
<p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/DL2 TRAINING AND QUERYING NEURAL NETWORKS WITH LOGIC/image-20200728234543352.png" alt="image-20200728234543352"></p>
<p>This <strong>query</strong></p>
<p> aims to <strong>find an input</strong> $n\in \Bbb{R}^{100}$  满足两条约束：</p>
<ol>
<li>domain constraint： 100维的 n 的每个元素都是在 -1 和 1 之间</li>
<li>ACGAN输出的结果是 本应该是类别 1 由 $\text{M_ACGAN_G(n,1)}$ 约束，  但 NN 分类的结果是 类别7   $\text{M_NN1}$ 的输出结果是 7</li>
</ol>
<p>DL2自动将此 query 转换为 DL2 的 loss，并使用现成的优化器（L-BFGS-B）对其进行优化以找到solution，在这种情况下为右侧的图像。</p>
<p>我们的语言可声明性地表述先前的许多工作，包括发现对给定预测负责 neurons responsible for a given prediction的神经元（Olah等人，2018），区分两个网络的输入（Peiet等人，2017）以及对抗性示例生成（例如Szegedy等人）等（2013年））</p>
<h4 id="Main-Contributions"><a href="#Main-Contributions" class="headerlink" title="Main Contributions"></a>Main Contributions</h4><p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/DL2 TRAINING AND QUERYING NEURAL NETWORKS WITH LOGIC/image-20200729102545691.png" alt="image-20200729102545691" style="zoom:80%;" /></p>
<h3 id="2-RELATED-WORK"><a href="#2-RELATED-WORK" class="headerlink" title="2  RELATED WORK"></a>2  RELATED WORK</h3><p><strong>Adversarial example generation</strong> 以看作是 as a fixed query to the network，while <strong>adversarial training</strong> (Madry et al., 2017) aims to enforce a specific constraint</p>
<ol>
<li><p>大多数工作旨在 ，train networks with logic <strong>impose soft constraints,</strong> 通过添加 an additional loss(正则项？) (Pathak et al., 2015; Xu et al., 2018)。</p>
</li>
<li><p>(M ́arquez-Neila et al., 2017) 表明硬约束比软约束没有经验优势。</p>
</li>
<li><p><strong>Probabilistic Soft Logic (PSL)</strong> (Kim-mig et al., 2012) translates logic into <strong>continuous functions</strong> over[0,1].  如我们所示，PSL不易于进行基于梯度的优化，因为梯度很容易变为零。 </p>
</li>
<li><p><strong>Hu</strong> et al. (2016) <strong>builds on PSL and presents a teacher-student framework which distills rules into the training phase。</strong>  idea is to <strong>formulate rule satisfaction as a convex problem</strong> with <strong>a closed-form solution</strong> (对teacher network 的 输出分布 直接通过闭式解给出 避免对网络参数的训练)。然而，这种 formulation构造的公式 仅限于关于随机变量的rules，而不能表达关于概率分布的rules。但 DL2可以表达这样的约束，例如 $p_1&gt;p_2$ 这要求类别1的网络输出概率大于类别2，而且，网络输出中 rules 的 线性性 导致的 凸性和闭式解 也是如此，这意味着非线性约束（例如，Lipschitz条件，可以用DL2表示）根本上是该方法无法实现的。</p>
</li>
<li>work of Xu et al. (2018) 还限制于对随机变量的约束，对于复杂的约束是棘手的。</li>
<li>Fu &amp; Su (2016)  reduces the satisfiability of floating-point formulas 转换成了数值优化，但是，它们的损失函数 不可微分，并且不支持对 分布 的约束。</li>
<li>没有先前的工作支持 <strong>回归任务 的约束</strong></li>
</ol>
<h3 id="3-FROM-LOGIC-TO-A-DIFFERENTIABLE-LOSS"><a href="#3-FROM-LOGIC-TO-A-DIFFERENTIABLE-LOSS" class="headerlink" title="3  FROM LOGIC  TO A DIFFERENTIABLE LOSS"></a>3  FROM LOGIC  TO A DIFFERENTIABLE LOSS</h3><h4 id="Logical-Language"><a href="#Logical-Language" class="headerlink" title="Logical Language"></a>Logical Language</h4><p>包含 quantifier-free constraints， 可以用 conjunction (∧), disjunction (∨) and negation (¬) 来构造。</p>
<p>Atomic constraints (literals) 是比较符<img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/DL2 TRAINING AND QUERYING NEURAL NETWORKS WITH LOGIC/image-20200729110408304.png" alt="image-20200729110408304" style="zoom:80%;" /> 这些比较符 是用于标量的，逐元素应用于矢量。</p>
<p>不支持 量词 (quantifier-free constraints)  </p>
<p><strong>A term $t$ is :</strong>  对 t 的约定</p>
<p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/DL2 TRAINING AND QUERYING NEURAL NETWORKS WITH LOGIC/image-20200729110918906.png" alt="image-20200729110918906" style="zoom:80%;" /></p>
<h4 id="Translation-into-loss"><a href="#Translation-into-loss" class="headerlink" title="Translation into loss"></a>Translation into loss</h4><p>把约束转化成损失函数形式，损失函数中的 变量间 逻辑运算符 再做 translation</p>
<p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/DL2 TRAINING AND QUERYING NEURAL NETWORKS WITH LOGIC/image-20200729113054171.png" alt="image-20200729113054171" style="zoom:80%;" /></p>
<p><strong>The  translation  rules：</strong></p>
<p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/DL2 TRAINING AND QUERYING NEURAL NETWORKS WITH LOGIC/image-20200729114140098.png" alt="image-20200729114140098" style="zoom:80%;" /></p>
<p><strong><em>比较符 $= \le$ 用距离函数来表示</em></strong>，L为0则表示满足约束，两元的比较符用 一个 连续的 可微的 scalar 表示</p>
<p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/DL2 TRAINING AND QUERYING NEURAL NETWORKS WITH LOGIC/image-20200729115217508.png" alt="image-20200729115217508" style="zoom:80%;" /></p>
<p>函数 $d$ 是就是对 逻辑比较符号的 translation，在论文的实现中，<strong><em>使用的是 absolute distance $\lvert t^1-t^2\rvert $</em></strong>  (因为是标量值，所以距离的度量直接是曼哈顿距离)</p>
<p>其余的比较符号：</p>
<p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/DL2 TRAINING AND QUERYING NEURAL NETWORKS WITH LOGIC/image-20200729141756243.png" alt="image-20200729141756243" style="zoom:80%;" /></p>
<p>合取析取的 translation：</p>
<p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/DL2 TRAINING AND QUERYING NEURAL NETWORKS WITH LOGIC/image-20200729141948167.png" alt="image-20200729141948167" style="zoom:80%;" /></p>
<p>当两个 formula 都满足时，loss 为0，则两个 formula 的 合取式 也满足， loss 为0</p>
<p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/DL2 TRAINING AND QUERYING NEURAL NETWORKS WITH LOGIC/image-20200729142326161.png" alt="image-20200729142326161" style="zoom:80%;" /></p>
<h4 id="Translating-negations"><a href="#Translating-negations" class="headerlink" title="Translating negations"></a>Translating negations</h4><p>包含 Negations 的 constraints 被重写为 不包含 Negations 的 等价 atomic constraint  (note that6=is not a negation). </p>
<p>对于 逻辑比较符</p>
<p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/DL2 TRAINING AND QUERYING NEURAL NETWORKS WITH LOGIC/image-20200729142716002.png" alt="image-20200729142716002" style="zoom:80%;" /></p>
<p>对于 合取析取符，</p>
<p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/DL2 TRAINING AND QUERYING NEURAL NETWORKS WITH LOGIC/image-20200729142835982.png" alt="image-20200729142835982" style="zoom:80%;" /></p>
<p>实例 $\bar x$ 带入 formula $\varphi$ 后使得 loss $L=0$ 则 <img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/DL2 TRAINING AND QUERYING NEURAL NETWORKS WITH LOGIC/image-20200729145018404.png" alt="image-20200729145018404" style="zoom:80%;" />当 loss 大于 一个 渐进于0的变量时，not satisfy</p>
<p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/DL2 TRAINING AND QUERYING NEURAL NETWORKS WITH LOGIC/image-20200729145120347.png" alt="image-20200729145120347" style="zoom:80%;" /></p>
<h3 id="4-CONSTRAINED-NEURAL-NETWORKS"><a href="#4-CONSTRAINED-NEURAL-NETWORKS" class="headerlink" title="4  CONSTRAINED NEURAL NETWORKS"></a>4  CONSTRAINED NEURAL NETWORKS</h3><p>在本节中，我们介绍了用于训练具有约束条件的神经网络的方法。我们首先定义问题，然后提供 min-max formulation，最后讨论如何解决问题</p>
<p>$[\varphi]$ 是 指示函数： <strong>1 if the predicate holds and 0 otherwise</strong> </p>
<h4 id="Training-with-constraints"><a href="#Training-with-constraints" class="headerlink" title="Training with constraints"></a>Training with constraints</h4><p>为了使用单个约束进行训练，我们考虑神经网络权重上的以下最大化问题，取值在[0,1]，最大为1</p>
<p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/DL2 TRAINING AND QUERYING NEURAL NETWORKS WITH LOGIC/image-20200729152436198.png" alt="image-20200729152436198" style="zoom:80%;" /></p>
<p>多个 constrain 的组合，通过 <strong>凸组合</strong>把 constrain 各自对应的 最大化期望问题组合起来</p>
<p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/DL2 TRAINING AND QUERYING NEURAL NETWORKS WITH LOGIC/image-20200729153711364.png" alt="image-20200729153711364" style="zoom:80%;" /></p>
<p><strong>S 为 从训练集中 采样样本</strong></p>
<p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/DL2 TRAINING AND QUERYING NEURAL NETWORKS WITH LOGIC/image-20200729154226150.png" alt="image-20200729154226150" style="zoom:80%;" /></p>
<h4 id="Formulation-as-min-max-optimization"><a href="#Formulation-as-min-max-optimization" class="headerlink" title="Formulation as min-max optimization"></a>Formulation as min-max optimization</h4><p>对上面的式子<img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/DL2 TRAINING AND QUERYING NEURAL NETWORKS WITH LOGIC/image-20200729154520611.png" alt="image-20200729154520611" style="zoom:80%;" />不直接求解这个最大化的优化问题，而是转变成<img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/DL2 TRAINING AND QUERYING NEURAL NETWORKS WITH LOGIC/image-20200729154554466.png" alt="image-20200729154554466" style="zoom:80%;" />最小化不满足约束概率的优化问题，这样可以将这个优化问题拆成两个子优化问题</p>
<p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/DL2 TRAINING AND QUERYING NEURAL NETWORKS WITH LOGIC/image-20200729154711886.png" alt="image-20200729154711886" style="zoom:80%;" /></p>
<p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/DL2 TRAINING AND QUERYING NEURAL NETWORKS WITH LOGIC/image-20200729155217164.png" alt="image-20200729155217164" style="zoom:80%;" /></p>
<p>先找到最大化冲突，即最大不满足约束的实例  $\bar x$ ，然后在已知  $\bar x$ 的条件下，求最小化该情况的期望值</p>
<h4 id="Solving-the-optimization-problems"><a href="#Solving-the-optimization-problems" class="headerlink" title="Solving the optimization problems"></a>Solving the optimization problems</h4><p>求解上面两个式子，通过第三节的方法 把 logical constraints 转换成 differentiable loss</p>
<p>对于<img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/DL2 TRAINING AND QUERYING NEURAL NETWORKS WITH LOGIC/image-20200729163700603.png" alt="image-20200729163700603" style="zoom:80%;" />我们将其 translate 到 损失函数 loss $L$ 。最大化满足 约束的逆，即让满足 约束的逆 的损失 $L$  最小：   根据 theorem1，</p>
<p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/DL2 TRAINING AND QUERYING NEURAL NETWORKS WITH LOGIC/image-20200729164530533.png" alt="image-20200729164530533" style="zoom:80%;" /></p>
<p>从上式解出 $\bar x$ 后，要使得在 约束 $\varphi$ 下出现 满足 约束的逆 的概率越小，所以要最小化下面的 损失函数</p>
<p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/DL2 TRAINING AND QUERYING NEURAL NETWORKS WITH LOGIC/image-20200729164459441.png" alt="image-20200729164459441" style="zoom:80%;" /></p>
<h4 id="Constrained-optimization"><a href="#Constrained-optimization" class="headerlink" title="Constrained optimization"></a>Constrained optimization</h4><p>通常，（4）中的损失有时可能难以优化，</p>
<p>举例：</p>
<p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/DL2 TRAINING AND QUERYING NEURAL NETWORKS WITH LOGIC/image-20200729170004311.png" alt="image-20200729170004311" style="zoom:80%;" /></p>
<p>首先对 $\varphi$ 取反，$\le$  根据<img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/DL2 TRAINING AND QUERYING NEURAL NETWORKS WITH LOGIC/image-20200729165954557.png" alt="image-20200729165954557" style="zoom:80%;display:inline" align="middle" />转成<img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/DL2 TRAINING AND QUERYING NEURAL NETWORKS WITH LOGIC/image-20200729170031260.png" alt="image-20200729170031260" style="zoom:80%;display:inline" align="middle" /><br>$\land$ 转成 <img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/DL2 TRAINING AND QUERYING NEURAL NETWORKS WITH LOGIC/image-20200729170100795.png" alt="image-20200729170100795" style="zoom:80%;display:inline" align="middle" /></p>
<p>这个式子很难优化，因为 the magnitude of the two terms is different，根据Carlini＆Wagner（2017）的报道，这导致 一阶方法 以过于贪婪的方式仅优化了单个项。</p>
<p>但是，某些约束具有闭式的解析解，<img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/DL2 TRAINING AND QUERYING NEURAL NETWORKS WITH LOGIC/image-20200729170259031.png" alt="image-20200729170259031" style="zoom:80%;" />为此，我们确定了逻辑约束，这些约束将变量限制为具有有效投影算法的凸集，<img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/DL2 TRAINING AND QUERYING NEURAL NETWORKS WITH LOGIC/image-20200729170512198.png" alt="image-20200729170512198" style="zoom:80%;" /></p>
<p>.</p>
<p><strong>算法流程：</strong></p>
<p>我们首先从训练集中形成随机样本的 mini-batch，the  oracle 找到上面 式 6 的一个解，在将该解给 optimizer来 solve 式 5。请注意，如果φ没有变量（k = 0），即只有一个 constrain 则 oracle 将变平凡，直接计算 loss</p>
<p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/DL2 TRAINING AND QUERYING NEURAL NETWORKS WITH LOGIC/image-20200729171104065.png" alt="image-20200729171104065" style="zoom:80%;" /></p>
<h3 id="5-QUERYING-NETWORKS"><a href="#5-QUERYING-NETWORKS" class="headerlink" title="5   QUERYING NETWORKS"></a>5   QUERYING NETWORKS</h3><p>我们以DL2为基础，设计了一种用于 查询网络querying networks 的声明性语言。先前工作中研究的硬编码问题现在可以用DL2查询表述：发现对给定预测负责 neurons responsible for a given prediction的神经元（Olah等人，2018），区分两个网络的输入（Peiet等人，2017）以及对抗性示例生成（例如Szegedy等人）等（2013年））</p>
<p><strong>我们支持以下类别的查询：</strong></p>
<p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/DL2 TRAINING AND QUERYING NEURAL NETWORKS WITH LOGIC/image-20200729171314064.png" alt="image-20200729171314064"></p>
<p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/DL2 TRAINING AND QUERYING NEURAL NETWORKS WITH LOGIC/image-20200729171814154.png" alt="image-20200729171814154" style="zoom:80%;" /></p>
<p>我们注意到用户可以用我们的语言指定 张量tensors（我们不假定它们被简化为矢量）。查询时，我们用逗号（，）表示连词（∧）； <strong>in</strong> 表示框约束 box-constraints，而 <strong>class</strong> 表示约束 目标标签target label，这被解释为对标签概率labels’ probabilities的约束</p>
<p>举例 几个有趣的查询。：</p>
<p>他的前两个是通过为CIFAR-10训练的网络定义的，而最后一个是针对MNIST的</p>
<ol>
<li><p>The <strong>first query</strong> is to find an <strong>adversarial example</strong> $i$ of shape(32,32,3), classified as a truck (class9) ，$i$  到 a given deer image(deer) 的距离在 6 到 24 间(距离用 $L_{\infty}$ 计算A)</p>
<p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/DL2 TRAINING AND QUERYING NEURAL NETWORKS WITH LOGIC/image-20200729204215351.png" alt="image-20200729204215351" style="zoom:80%;" /></p>
</li>
<li><p>目标是 找到 $i$ <strong>classified as a deer</strong> where <strong>a specific neuron is deactivated</strong>.</p>
<p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/DL2 TRAINING AND QUERYING NEURAL NETWORKS WITH LOGIC/image-20200729205243397.png" alt="image-20200729205243397" style="zoom:80%;" /></p>
</li>
<li><p>目标是 找到 $i$  <strong>classified differently by two networks</strong> where <strong>part of $i$ is fixed to pixels</strong> of the image <strong>nine</strong></p>
<p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/DL2 TRAINING AND QUERYING NEURAL NETWORKS WITH LOGIC/image-20200729205545246.png" alt="image-20200729205545246" style="zoom: 80%;" /></p>
</li>
</ol>
<h4 id="Solving-queries"><a href="#Solving-queries" class="headerlink" title="Solving queries"></a>Solving queries</h4><p>与训练一样，我们将 约束 编译为 损失loss，但是与训练不同，我们使用 L-BFGS-B 进行优化。虽然训练需要在PGD优化中分批输入，但查询却需要分配，因此有更多的时间使用更复杂但更慢的L-BFGS-B。我们将在附录C中讨论进一步的优化</p>
<h3 id="6-EXPERIMENTAL-EVALUATION"><a href="#6-EXPERIMENTAL-EVALUATION" class="headerlink" title="6  EXPERIMENTAL EVALUATION"></a>6  EXPERIMENTAL EVALUATION</h3><p>现在，我们对DL2在查询和训练具有逻辑约束的神经网络的有效性方面进行了全面的实验评估。我们的系统在PyTorch中实现（Paszkeet等，2017），并在Nvidia GTX 1080 Ti和4.20 GHz的Intel Core i7-7700K上进行了评估</p>
<h4 id="6-1-TRAINING-WITH-DL2"><a href="#6-1-TRAINING-WITH-DL2" class="headerlink" title="6.1    TRAINING  WITH  DL2"></a>6.1    TRAINING  WITH  DL2</h4><p>我们评估了DL2在以下四个数据集上的各种任务（有监督，半监督和无监督学习）上：MNIST，FASHION（Xiao等人，2017），CIFAR-10和CIFAR-100（Krizhevsky＆Hinton，2009）。在所有实验中，约束条件之一是交叉熵（请参见第4节），以进行优化以提高预测精度。对于每个实验，我们都描述了其他逻辑约束</p>
<h4 id="Supervised-learning"><a href="#Supervised-learning" class="headerlink" title="Supervised   learning"></a>Supervised   learning</h4><p>考虑两种 约束</p>
<ol>
<li><em>global constraints</em>，包括z-s,： </li>
<li><em>training  set  constraints ：</em> the only variables are  from the training set (no ·z-s).</li>
</ol>
<p>we write <strong>random samples</strong> (the S-s)     $x_i$ <strong>: inputs from the training set       $y_i$ : corresponding label</strong></p>
<p><strong>For local robustness (Szegedy et al., 2013) </strong> </p>
<ol>
<li><p><strong>training set constraint</strong></p>
<p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/DL2 TRAINING AND QUERYING NEURAL NETWORKS WITH LOGIC/image-20200729220549693.png" alt="image-20200729220549693" style="zoom:80%;" /></p>
</li>
<li><p><strong>Global constraint</strong> </p>
<p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/DL2 TRAINING AND QUERYING NEURAL NETWORKS WITH LOGIC/image-20200729220600062.png" alt="image-20200729220600062" style="zoom:80%;" /></p>
<p>可能指的就是 <img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/DL2 TRAINING AND QUERYING NEURAL NETWORKS WITH LOGIC/image-20200729221406131.png" alt="image-20200729221406131" style="zoom:80%;" /></p>
</li>
</ol>
<p>同样的，have <strong>two definitions</strong> for <strong>the Lipschitz condition.</strong>  </p>
<ol>
<li><p><strong>training set constraint</strong> </p>
<p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/DL2 TRAINING AND QUERYING NEURAL NETWORKS WITH LOGIC/image-20200729221704696.png" alt="image-20200729221704696" style="zoom:80%;" /></p>
</li>
<li><p><strong>global constraint</strong> </p>
<p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/DL2 TRAINING AND QUERYING NEURAL NETWORKS WITH LOGIC/image-20200729221727188.png" alt="image-20200729221727188" style="zoom:80%;" /></p>
</li>
</ol>
<p><strong>Imposing domain knowledge</strong></p>
<ol>
<li><p><strong>training set constraint</strong> </p>
<p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/DL2 TRAINING AND QUERYING NEURAL NETWORKS WITH LOGIC/image-20200729221859620.png" alt="image-20200729221859620" style="zoom:80%;" /></p>
</li>
<li><p><strong>global constraint</strong> </p>
<p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/DL2 TRAINING AND QUERYING NEURAL NETWORKS WITH LOGIC/image-20200729221911682.png" alt="image-20200729221911682" style="zoom:80%;" /></p>
</li>
</ol>
<p>最后，我们考虑一个细分约束，它要求如果输入zi在位置λ上的两个输入x1和x2之间的直线上，则其输出概率在输出概率之间的直线上的位置λ上</p>
<p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/DL2 TRAINING AND QUERYING NEURAL NETWORKS WITH LOGIC/image-20200729222035065.png" alt="image-20200729222035065" style="zoom:80%;" /></p>
<p><strong>预测精度（P）和约束精度（C）</strong></p>
<p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/DL2 TRAINING AND QUERYING NEURAL NETWORKS WITH LOGIC/image-20200729222743867.png" alt="image-20200729222743867" style="zoom:80%;" /></p>
<p>(i) crossed-entropy only (CE) and (ii) CE and the constraint. </p>
<p>P 预测精度略微下降， C 约束精度很高</p>
<p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/DL2 TRAINING AND QUERYING NEURAL NETWORKS WITH LOGIC/image-20200729223542692.png" alt="image-20200729223542692" style="zoom:80%;" /></p>
<h4 id="Semi-supervised-learning"><a href="#Semi-supervised-learning" class="headerlink" title="Semi-supervised  learning"></a>Semi-supervised  learning</h4><p>我们将重点放在CIFAR-100数据集上，并将训练集按20/60/20的比例分为标记集，未标记集和验证集。</p>
<p>本着Xu等人的实验精神  Xu et al. (2018)，我们考虑约束条件 要求 类别组 <strong>groups  of  classes</strong> 的概率要么具有非常高的概率或非常低的概率。 A group consists of classes of a similar type( e.g., the classes <em>baby,boy,girl,man, and woman</em> are part of the people group), and <strong>the group’s probability</strong> <strong>is the sum of its classes’ probabilities</strong></p>
<p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/DL2 TRAINING AND QUERYING NEURAL NETWORKS WITH LOGIC/image-20200729223906576.png" alt="image-20200729223906576" style="zoom:80%;" /> for a small $\epsilon$</p>
<p>我们使用此约束条件来比较几种方法的性能,  we use the Wide Residual Network (Zagoruyko &amp; Komodakis (2016)) as the network architecture. </p>
<p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/DL2 TRAINING AND QUERYING NEURAL NETWORKS WITH LOGIC/image-20200729224145257.png" alt="image-20200729224145257" style="zoom:80%;" /></p>
<h4 id="Unsupervised-learning"><a href="#Unsupervised-learning" class="headerlink" title="Unsupervised learning"></a>Unsupervised learning</h4><p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/DL2 TRAINING AND QUERYING NEURAL NETWORKS WITH LOGIC/image-20200729225442306.png" alt="image-20200729225442306" style="zoom:80%;" /></p>
<p>另外，我们约束 $d(0)=0$。接下来，我们以无监督的方式训练模型，使用DL2。在每个实验中，我们生成具有15个顶点的随机图，并将图分为训练（300），验证（150）和测试集（150）。作为无监督的基线，我们考虑一个始终预测 d（v）= 1的模型。我们还训练了具有均方误差（MSE）损失的监督模型。值得注意的是，我们的方法无需使用任何标签即可获得非常接近监督模型的错误。这证实了由DL2产生的损失可用于指导网络满足具有许多嵌套连接和分离的甚至非常复杂的约束。</p>
<h4 id="6-2-QUERYING-WITH-DL2"><a href="#6-2-QUERYING-WITH-DL2" class="headerlink" title="6.2   QUERYING  WITH  DL2"></a>6.2   QUERYING  WITH  DL2</h4><p>我们评估了在TensorFlow中实现的具有约束的查询任务上的DL2。我们考虑了五个图像数据集，对于每个图像集，我们至少考虑了两个分类器。我们还考虑了生成器和鉴别器（使用GAN训练（Goodfellow等，2014a））。表3（附录E）提供了有关网络的统计信息。我们的基准测试包含18个模板查询 template queries（附录E），这些查询使用不同的网络，类和图像进行实例化。表1显示了结果（-表示不适用的查询）。 Queries ran with a timeout of2minutes.。结果表明我们的系统经常找到解决方案。尚未找到没有解决方案的查询是否具有解决方案是未知的。我们观察到查询的成功取决于数据集，例如，查询9-11对于除GTSBR之外的所有数据集都是成功的。这可能归因于GTSBR网络相对于这些查询旨在寻找的对抗示例的鲁棒性。利用区分词查找对抗示例的查询14仅对CIFAR数据集成功。可能的解释是，鉴别器是针对生成器创建的真实图像或图像进行训练的，因此，鉴别器在对仿生图像进行分类时表现不佳。利用生成器的查询15在所有经过测试的数据集中都成功，但是在每个数据集中只有很少的成功。至于整体解决时间，我们的结果表明，成功执行的过程会很快结束，并且我们的系统可以很好地扩展到大型网络（例如ImageNet）。</p>
<h3 id="7-CONCLUSION"><a href="#7-CONCLUSION" class="headerlink" title="7  CONCLUSION"></a>7  CONCLUSION</h3><p>AND APPENDIX</p>
<p><a href="https://www.sri.inf.ethz.ch/publications/fischer2019dl2">paper</a></p>
]]></content>
      <categories>
        <category>Neural Networks with Logic Rules</category>
      </categories>
      <tags>
        <tag>querying neural network</tag>
        <tag>differentiable loss</tag>
        <tag>convex set</tag>
      </tags>
  </entry>
  <entry>
    <title>Harnessing Deep Neural Networks with Logic Rules</title>
    <url>/blog/2020/07/22/Harnessing%20Deep%20Neural%20Networks%20with%20Logic%20Rules/</url>
    <content><![CDATA[<a id="more"></a>
<h3 id="『Harnessing-Deep-Neural-Networks-with-Logic-Rules』阅读笔记"><a href="#『Harnessing-Deep-Neural-Networks-with-Logic-Rules』阅读笔记" class="headerlink" title="『Harnessing Deep Neural Networks with Logic Rules』阅读笔记"></a>『Harnessing Deep Neural Networks with Logic Rules』阅读笔记</h3><p><a href="https://github.com/ZhitingHu/logicnn">code</a></p>
<p><a href="https://github.com/martiansideofthemoon/logic-rules-sentiment">Logic Rules for Sentiment Classification——code</a></p>
<ol>
<li>将 一阶逻辑 rules 表示的 知识通过 <strong><em>正则化(后验正则化</em>)</strong>的方式加入NN模型参数的更新中</li>
<li>相较于 知识蒸馏时 ，论文中teacher 和student network是同时训练的</li>
<li>teacher network 在每一次迭代中通过根据构造的损失函数的闭式解构造，所以实际只有要强化的student network 的参数要更新</li>
<li>认为结构知识，领域知识不能自然地以特征标签形式编码。</li>
<li><strong>仅使用少量（一个或两个）非常直观的规则</strong></li>
<li>测试时可以使用最后的student network p或者teacher network q，一般来讲q的表现会优于p。q更适用逻辑规则覆盖了大量样本的情况，而p更适用于规则评价复杂或者未知的情况。</li>
<li>teacher-student network 这种常常是 separate training 的方式，变成了 iterative 联合训练</li>
<li>teacher network 将 逻辑知识蒸馏 到student network，即可以增强各种类型的神经网络</li>
</ol>
<h3 id="专有名词"><a href="#专有名词" class="headerlink" title="专有名词"></a>专有名词</h3><ol>
<li><p><strong>knowledge distillation：</strong> <a href="https://zhuanlan.zhihu.com/p/51563760">知乎1</a>,  <a href="https://zhuanlan.zhihu.com/p/53864403">知乎2</a>,  <a href="https://github.com/lhyfst/knowledge-distillation-papers">paper reading list</a></p>
</li>
<li><p>后验正则化（posterior regularization）方法</p>
</li>
<li><p>K-way  classification,</p>
</li>
<li><p>K-dimensional  probability  simplex</p>
<p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/Harnessing Deep Neural Networks with Logic Rules/3987bf963ef4ab9a7920cbb1d57056c3" alt="img"></p>
</li>
<li><p>groundings of a rule： a grounding is the logic expression with all variables being instantiated 即 一阶逻辑表达式中所有 变量 都实例化为具体</p>
</li>
<li><p>max-over-time 池化层，NLP中的CNN:  <a href="https://blog.csdn.net/malefactor/article/details/51078135">参考1cnblog</a>  <a href="https://stackoverflow.com/questions/48549670/pooling-vs-pooling-over-time">Pooling vs Pooling-over-time</a></p>
</li>
<li><p><a href="http://www.gabormelli.com/RKB/Bidirectional_LSTM-CNN_(BLSTM-CNN">Bidirectional LSTM-CNN (BLSTM-CNN) Training System</a>_Training_System)</p>
</li>
</ol>
<h3 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h3><p>需要将<strong>深层神经网络与结构化逻辑规则</strong>结合起来，以充分利用灵活性并减少神经模型的不可解释性。我们提出了一个通用框架，该框架可以<strong>使用声明性一阶逻辑规则增强各种类型的神经网络</strong>（例如CNN和RNN）。具体来说，我们开发了一种<strong>迭代蒸馏方法</strong>，将逻辑规则的结构化信息转移到神经网络的权重中。我们将该框架部署在CNN上进行情感分析，并在RNN上进行命名实体识别。通过一些高度直观的规则，我们获得了实质性的改进</p>
<h3 id="1-Introduction"><a href="#1-Introduction" class="headerlink" title="1    Introduction"></a>1    Introduction</h3><p>深度神经网络为从海量数据中学习模式，在图像分类，语音识别，机器翻译。玩战略棋盘游戏等，尽管取得了令人瞩目的进步，但广泛使用的DNN方法仍然存在局限性。较高的预测准确性很大程度上取决于大量的标记数据。而且<strong>纯粹由数据驱动的学习会导致无法解释的结果，有时甚至导致反直觉的结果*</strong>(Anh Nguyen等人在CVPR2015上首次提出Fooling Examples的论文 <a href="https://link.zhihu.com/?target=https%3A//arxiv.org/abs/1412.1897">Deep Neural Networks are Easily Fooled: High Confidence Predictions for Unrecognizable Images</a>)<em>。在没有昂贵的直接监督或临时初始化的情况下，很难编码人类的意图以指导模型捕获所需的模式。另一方面，人类的认知过程表明人们不仅从具体的例子中学习（DNN确实如此），<strong>但也来自不同形式的一般知识和丰富经验</strong>。<em>*逻辑规则提供了灵活的声明性语言，用于传达高级认知和表达结构化知识</em></em>。因此，需要将逻辑规则集成到DNN中，以将人的意图和领域知识转移到神经模型中，并调节学习过程。</p>
<p>在本文中，我们提出了一个框架，该框架能够利用<strong>逻辑规则知识</strong>在各种任务上<strong><em>增强</em></strong>神经网络的通用类型，例如卷积网络（CNN）和递归网络（RNN）。在不同情况下，<strong>已经考虑过将符号表示 symbolic representations 与神经方法相结合</strong>。</p>
<p><a href="https://www.jiqizhixin.com/articles/101402">神经符号系统：让机器善解人意</a></p>
<p><strong><em>神经符号系统</em></strong>根据给定规则集构建网络以执行推理 execute reasoning。为了利用通用神经体系结构中的先验知识，<strong>最近的工作使用有用的特征扩充了每个原始数据实例( augments  each  raw  data  instance  with useful feature)</strong>，但是网络训练仍然仅限于实例标签监督，并且遭受与上述相同的问题。此外<strong>，各种各样的结构知识不能自然地以特征标签的形式编码。</strong></p>
<p>我们的框架使神经网络能够learn simultaneously from labeled instances as well as logic rules, through an <em>iterative rule knowledge distillation</em> (teacher-student network 知识蒸馏) procedure that transfers the structured information encoded in the logic rules into the network parameters。<strong>由于通用逻辑规则是对特定数据标签的补充</strong>，这种结合的一个自然“副产品”是对可以对半监督学习形成支持，因为使用未标记的数据可以更好地吸收逻辑知识( natural “side-product”of the integration is the support for semi-supervised learning where unlabeled data is used to better absorb the logical knowledge.)。从方法上讲，我们的方法可以看作是<strong>知识蒸馏</strong>和<strong>后验正则化（PR）方法</strong>的结合。特别是，在每次迭代中，我们都采用 <strong>posterior constraint principle from PR to construct a <em>rule-regularized teacher</em></strong>，<strong>并训练感兴趣的 <em>student network</em> 来模仿 <em>teacher network</em> 的预测</strong>。我们利用软逻辑 soft logic 来支持灵活的规则编码 flexible rule encoding 。</p>
<p>我们将框架同时应用于CNN和RNN，并分别部署在情感分析sentiment analysi（SA）和命名实体识别named entity recognition（NER）的任务上。<strong>仅使用少量（一个或两个）非常直观的规则</strong>，both  the  distilled  networks  and  the  joint  teacher networks  strongly  improve  over  their  basic  forms  (without  rules)。</p>
<h3 id="2-Related-Work"><a href="#2-Related-Work" class="headerlink" title="2    Related Work"></a>2    Related Work</h3><p><strong>逻辑规则和神经网络的结合</strong>已经在不同的背景下被考虑过，神经符号系统Neural-symbolic system，例如KBANN和CILP ++，从给定规则 构造网络架构 来进行推理和知识获取。诸如<em>马尔可夫逻辑网络</em>之类的相关研究从规则集中获得了<strong>概率图形模型</strong>（而不是神经网络）。</p>
<p>随着深度神经网络在众多应用领域中的最新成功，将结构化逻辑知识纳入一般类型的网络以充分利用灵活性并减少神经模型的不可解释性。最近的工作是<strong>在领域知识带来的额外特征上进行训练</strong>（虽然产生了改进的结果，<strong>但并没有超出 data-label paradigm </strong>。Kulkarni等使用专门的training  procedure，对训练实例进行仔细排序，以获得图像网络的可解释神经层。Karaletsos等通过数据标签和 similarity  knowledge  expressed  in  triplet  format  共同开发了一个生成模型，以学习改进的disentangled representations。</p>
<p>尽管确实存在允许对 <strong><em>潜在变量模型进行各种结构化约束编码的通用框架</em></strong>( allow encoding various structured constraints on latent variable model)（Ganchev等<a href="https://www.jmlr.org/papers/volume11/ganchev10a/ganchev10a.pdf">Posterior Regularization for Structured Latent Variable Models</a>），但它们要么不能直接应用于NN网络，要么可以根据我们的经验研究，产品的性能较差。<strong>梁等以流水线的方式将预训练的结构化模型的预测能力转移到非结构化模型</strong> ( Liang et al. (2008) transfers predictive power of pre-trained structured models to unstructured ones in a pipelined fashion.)。</p>
<p>我们提出的方法的不同之处在于，我们使用迭代规则提炼过程(use an iterative rule distillation process)将声明性一阶逻辑语言表示的丰富结构化知识有效地转移到参数中通用神经网络我们表明(effectively transfer rich structured knowledge, expressed in the declarative first-order logic language, into parameters of general neural networks)</p>
<h3 id="3-Method"><a href="#3-Method" class="headerlink" title="3    Method"></a>3    Method</h3><p>在本节中，我们介绍将逻辑结构化知识封装到神经网络中的框架。这是通过<strong>迫使网络 emulate the predictions of a rule-regularized teacher，并在整个培训过程中迭代地发展两个模型来实现的</strong> evolving both models iteratively throughout training（第3.2节）。该过程与网络体系结构无关，因此适用于一般类型的神经模型，包括CNN和RNN。我们通过  <strong>posterior regularization principle 后验正则化作为 logical constraint setting 构建 teacher network。提供了闭式解</strong></p>
<p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/Harnessing Deep Neural Networks with Logic Rules/image-20200727161311987.png" alt="image-20200727161311987"></p>
<p>左上是简略图表示 teacher network 的构建过程：obtained  by projecting  the  student  network  to  a  rule-regularized  subspace (red  dashed  arrow)</p>
<p>student  network 的 训练过程： balance  between  emulating  the  teacher’s  output (black solid arrows)知识蒸馏过程 和 predicting the true labels (blue solid arrows)</p>
<h4 id="3-1-Learning-Resources-Instances-and-Rules"><a href="#3-1-Learning-Resources-Instances-and-Rules" class="headerlink" title="3.1    Learning Resources:  Instances and Rules"></a>3.1    Learning Resources:  Instances and Rules</h4><p>我们的方法允许神经网络从特定的示例和一般规则中学习。在这里，我们给出了这些“learning resources”的设置</p>
<p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/Harnessing Deep Neural Networks with Logic Rules/image-20200727164435155.png" alt="image-20200727164435155"></p>
<p>输入变量 $x$， 目标变量 $y\in\{0,1\}^K$  是 class label 的 one-hot 编码，但是，我们的方法规范可以直接应用于其他情况，例如回归和序列学习（例如NER标签，它是分类决策的序列）。</p>
<p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/Harnessing Deep Neural Networks with Logic Rules/image-20200727165508535.png" alt="image-20200727165508535"></p>
<p> <strong>first-order  logic  (FOL)  rules</strong> $R_l$ 定义在输入目标空间 $(\mathcal{X,Y})$  规则集合的第 $l$ 条规则，with  <strong>confidences 权重</strong> $\lambda_l \in[0,\infty]$ ，当 $\lambda_l =\infty$ 表示这是一条 <strong>hard rule，则 all groundings are required to be true (=1).</strong></p>
<p>举例：</p>
<p>训练集 $\mathcal{D}=\{(x_n,y_n\}_{n=1}^N$   是 $(x,y)$ 的一组实例化集合</p>
<p>取一个minibatch $(X,Y)\subset(\mathcal{X,Y})$ ？为什么是样本空间的子集而不是 训练集 $\mathcal{D}$ </p>
<p>groundings 为 <img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/Harnessing Deep Neural Networks with Logic Rules/image-20200727171738815.png" alt="image-20200727171738815" style="zoom:80%;" /></p>
<p>实际情况下，a rule grounding 只能 cover a single or subset of examples，即使我们给出的公式是在整个集合上的最通用的形式</p>
<p>用 <strong>soft logic</strong> 进行编码，for flexible encoding and stable optimization</p>
<p>松弛后的逻辑运算规则，<strong>用 Lukasiewicz t-norm co-norm</strong> 分别作为 逻辑 AND 和 OR 的松弛形式</p>
<p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/Harnessing Deep Neural Networks with Logic Rules/image-20200727172352168.png" alt="image-20200727172352168"></p>
<p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/Harnessing Deep Neural Networks with Logic Rules/image-20200727172515257.png" alt="image-20200727172515257" style="zoom:80%;" /></p>
<h4 id="3-2-Rule-Knowledge-Distillation-逻辑规则的知识蒸馏"><a href="#3-2-Rule-Knowledge-Distillation-逻辑规则的知识蒸馏" class="headerlink" title="3.2    Rule Knowledge Distillation 逻辑规则的知识蒸馏"></a>3.2    Rule Knowledge Distillation 逻辑规则的知识蒸馏</h4><p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/Harnessing Deep Neural Networks with Logic Rules/image-20200727172737590.png" alt="image-20200727172737590" style="zoom:80%;" /></p>
<p>为了整合编码在 rules 中的 information，我们建议对网络进行训练，来模仿 the  outputs  of  a rule-regularized  projection of $p_{\theta}(y|x)$ ，表示为 $q(y|x)$ ，这个正则化的投影，明确包含了 rule constraints 为正则化项。<strong>每次迭代中，通过将 student network 输出 的条件概率  $p_\theta$ 投影到 受规则约束rule constraints 的子空间中来构造 $q$，因此具有has desirable properties。</strong></p>
<p><strong>$q$ 的预测行为 体现了正则化子空间 和 结构化规则 structured rules 的信息</strong>。因此student network模拟 q 的 输出用于传递 rules的知识到student network的输出分类 $p_\theta$</p>
<p>knowledge distillation其实就是 $p(y|x)$ ( student network) 模仿 $q(y|x)$ (Teacher network )的输出<br>(即soft predictions ) 的误差大小 和 预测真实 label 的误差之间的 权衡结果 去 update student network 的参数  $\Theta$</p>
<p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/Harnessing Deep Neural Networks with Logic Rules/image-20200728135028796.png" alt="image-20200728135028796"></p>
<p>t 是训练轮次，$\ell$ 是不同任务中的损失函数 loss（如在分类问题中，l 是交叉熵）$\sigma_\theta$是预测函数 ，$s_n^{(t)}$ 是teacher network 的预测结果 即作者说的 soft predictions $q$ on $x_n$ 。  $π$是校准两个目标相对重要性的模仿参数。 与传统的知识蒸馏不同的是，our teacherand student are learned simultaneously during training。</p>
<p>(尽管可以通过像以前一样仅使用数据标签实例对网络进行完全训练后将其投影到规则正则化子空间，或者通过直接优化投影网络来将神经网络与规则约束相结合) 这个方法性能更好</p>
<p>因为 这种方式将逻辑规则形式的结构化信息引入到神经网络的权重中，不需要依靠显示的规则表达，可以将 $p_\theta$ 用于在规则评估成本高昂甚至无法使用时在测试时预测新示例 (i.e., the privileged information setting (Lopez-Paz et al., 2016)) .</p>
<p>且上式中的第二项对 teacher network 的学习 除带有标记的示例外，还可以使用丰富的未标记数据进行扩充，这使半监督学习可以更好地吸收规则知识</p>
<h4 id="3-3-Teacher-Network-Construction"><a href="#3-3-Teacher-Network-Construction" class="headerlink" title="3.3    Teacher Network Construction"></a>3.3    Teacher Network Construction</h4><p>$q(y|x)$ 为  the  outputs  of  a rule-regularized  projection of $p_{\theta}(y|x)$ ，这个正则化的投影，明确包含了 rule constraints 为正则化项。</p>
<p>我们在构造 logic constraint setting 时 采用了 后验正则化 posterior regularization principle。</p>
<p>  $\mathcal{R}=\{(R_l,\lambda_l)\}_{l=1}^L $ FOL  rules 集合 包含L条 rules ，构造 $q$ 需要 1. fits the rules  2. staying close to student network 的输出 $p_\theta$</p>
<ol>
<li><strong>fits the rules:</strong>  对 rules $(R_l,\lambda_l)$ ( indexed by i)，和其所有在 这个 minibatch $(X,Y)$ 中的 groundsing ( indexed by g)， 有 约束： $\Bbb{E}_{q(Y|X)}[r_{lg}(X,Y)]=1$ 即正则化投影后得到的 $q(y|x)$ 输出分布，(x,y) pairs 能用  rules 全覆盖，则将输出的分布 constraint 到 rule-regularized space</li>
<li><strong>staying close to student network 的输出 $p_\theta$：</strong> 用 KL 散度 计算 student network 和 teacher network 输出分布的距离</li>
</ol>
<p>将两者结合起来，在对约束进行一定的松弛，得到下面的优化目标</p>
<p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/Harnessing Deep Neural Networks with Logic Rules/image-20200728095135232.png" alt="image-20200728095135232"></p>
<p>其中 $\xi_{l,gl}$ 是相应逻辑约束的松弛变量； C 是正则化常数。</p>
<p>该问题可以看作是将pθ投影到约束子空间中，该问题是凸的，可以通过其对偶式的闭式解有效地解决</p>
<p>q 的 共轭式 的 闭式解：<img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/Harnessing Deep Neural Networks with Logic Rules/image-20200728101323965.png" alt="image-20200728101323965" style="zoom:80%;" /></p>
<p>具有较大λ1的强规则将导致无法满足约束条件的预测概率较低</p>
<p>我们的框架与后验正则化（PR）方法有关（Ganchev et al。，2010），该方法在无监督的情况下对模型后验放置约束(places constraints over model posterior in unsupervised setting)。</p>
<p>在分类任务中，我们的优化程序类似于 对 PR的改进EM算法，通过使用式<img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/Harnessing Deep Neural Networks with Logic Rules/image-20200727221005098.png" alt="image-20200727221005098" style="zoom:80%;" />中的交叉熵损失并在 与 标记数据的样本集 $D$ 不同的未标记数据集上 评估第二个损失项，从而使等式<img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/Harnessing Deep Neural Networks with Logic Rules/image-20200728101323965.png" alt="image-20200728101323965" style="zoom:80%;" />对应于 E-estimation步骤 ，等式<img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/Harnessing Deep Neural Networks with Logic Rules/image-20200727221005098.png" alt="image-20200727221005098" style="zoom:80%;" />类似于M-maximizes步骤。这从另一个角度阐明了为什么我们的框架会起作用。但是，我们在实验（第5节）中发现，要产生强大的性能，在等式（2）的两个损失项中使用相同的标记数据 $x_n$ 至关重要，以便在模拟软预测与预测正确的硬标记之间形成<strong>直接的折衷</strong></p>
<h4 id="3-4-Implementations"><a href="#3-4-Implementations" class="headerlink" title="3.4    Implementations."></a>3.4    Implementations.</h4><p>Algorithm 1中总结了我们框架的迭代蒸馏优化过程。</p>
<p>训练过程中，在每次迭代都要计算 the  soft  predictions  of $q$，如果等式<img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/Harnessing Deep Neural Networks with Logic Rules/image-20200728101323965.png" alt="image-20200728101323965" style="zoom:80%;" />中的 rule constraint 以和 基本神经模型 pθ（例如，第4.1节中的情感分类中的 “but“ rule）相同的方式 分解factored ，则<strong>可以通过枚举直接进行计算</strong>。<strong>如果约束引入了额外的依赖关系，例如，二元语法依赖关系 作为NER任务中的转换规则</strong>（第4.2节），我们可以使用动态编程进行有效的计算。对于<strong>高阶约束</strong>（例如NER中的列表规则 listing rule），我们<strong>通过 Gibbs采样 进行近似</strong>，该采样针对每个位置 $i$ 反复从$q(y_i | y_{-i}，x)$进行采样。如果约束跨越多个实例，我们将相关实例组合成  minibatches 进行联合推理 joint inference（并在组太大时随机打破一些依赖关系）。请注意，计算软预测 soft predictions是高效的，因为只需要一个NN forward pass 就可以计算基本分布pθ（y | x）（如果需要，还可以计算一些基本规则的真值）。</p>
<p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/Harnessing Deep Neural Networks with Logic Rules/image-20200728110453886.png" alt="image-20200728110453886"></p>
<p>类似于 EM 算法，初始化模型参数 $\theta_0$ </p>
<h4 id="p-v-s-q-at-Test-Time"><a href="#p-v-s-q-at-Test-Time" class="headerlink" title="p  v.s. q  at Test Time"></a>p  v.s. q  at Test Time</h4><p>在测试时，我们可以 we can use either the distilled student network $p$ ,or  the  teacher  network $q$ after  a  final  projection。我们的经验结果表明，两种模型在仅使用数据标签实例进行训练的基础网络上均得到了显着改善。一般而言，q 的性能优于 p。特别地，当逻辑规则引入需要联合推理的附加依赖性（例如，跨越多个示例 spanning over multiple examples）时，q 更适合。相反，如上所述，p 更加 lightweight and efficient，并且在 rule evaluation is expensive or impossible at prediction time 时很有用。我们的实验广泛地比较了 p 和 q 的性能</p>
<h4 id="Imitation-Strength-pi"><a href="#Imitation-Strength-pi" class="headerlink" title="Imitation Strength  $\pi$"></a>Imitation Strength  $\pi$</h4><p>balances between emulating the teacher soft predictions and predicting the true hard labels.</p>
<p>由于教师网络是由 pθ 构建的，因此在训练开始时会产生低质量的预测，因此我们更倾向于在初始阶段预测真实标签。随着训练的进行，我们逐渐偏向于 模仿教师的预测以有效地提取结构化知识。具体而言，我们在迭代 t≥0 时定义 $\pi^{t}=\min\{\pi_0,1-\alpha^t\}$，其中 α≤1 指定衰减速度，而 π0&lt;1 是下限</p>
<h3 id="4-Applications"><a href="#4-Applications" class="headerlink" title="4    Applications"></a>4    Applications</h3><p>我们已经介绍了我们的框架，该框架足够通用，可以使用规则来改进各种类型的神经网络，并且易于使用，因为允许用户通过声明性的一阶逻辑来 注入其知识和意图。在本节中，我们通过将其应用于两种主力网络架构（即卷积网络和递归网络）以及两种代表性应用（即句子级情感分析sentence-level sentiment  analysis（这是一个分类问题）和名为实体识别 named  entity  recognition(序列学习问题)来说明我们方法的通用性。</p>
<p>实验用的网络 ， we largely use the same or similar networks to previous successful neural models。</p>
<p>We then design the linguistically-motivated rules to be integrated 在设计rules </p>
<h4 id="4-1-Sentiment-Classification"><a href="#4-1-Sentiment-Classification" class="headerlink" title="4.1    Sentiment Classification"></a>4.1    Sentiment Classification</h4><p>句子级别的情感分析是要识别单个句子背后的情感（例如，正面或负面）。这项任务对于许多观点挖掘 opinion mining 应用至关重要。该任务的挑战之一是捕捉句子中的对比感contrastive sense（例如，通过“ but”转折词 连词 等 conjunction）</p>
<h5 id="Base-Network"><a href="#Base-Network" class="headerlink" title="Base Network"></a>Base Network</h5><p>我们使用（Kim，2014）中提出的<strong>单通道卷积网络 single-channel convolutional network</strong>。该简单模型在各种情感分类基准上均具有令人信服的性能。该网络在给定句子的单词向量之上包含一个卷积层，然后是一个最大时间 max-over-time 池化层，然后是一个具有softmax输出激活的完全连接层。卷积运算是将 filter  应用于句子的一个窗口，使用具有不同窗口大小的多个 filter 来获得多个特征。图2左面板显示了网络体系结构。</p>
<p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/Harnessing Deep Neural Networks with Logic Rules/image-20200728115413313.png" alt="image-20200728115413313"></p>
<h5 id="Logic-Rules"><a href="#Logic-Rules" class="headerlink" title="Logic Rules"></a>Logic Rules</h5><p>普通神经网络的一个困难是识别对比意义 contrastive sense，以便准确地捕捉主导情绪 dominant sentiment 。连词“ but”是句子中这种情绪变化的有力指示之一，其中“ but”之后的从句情绪通常占主导地位。因此，如果我们认为句子 $S$  具有 $“ A-but-B” $ 结构，并期望整个句子的情感与从句B的情感一致。则一阶逻辑规应写为：</p>
<p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/Harnessing Deep Neural Networks with Logic Rules/image-20200728135229629.png" alt="image-20200728135229629"></p>
<p><strong>$r\equiv r_{body} \rarr r_{head} \equiv \tilde \neg  r_{body}\tilde\lor r_{head}$  (条件表达式性质)，</strong></p>
<p>class $+$ 代表 “positive” ，$\sigma_\theta(B)_+$ 是 soft prediction vector $\sigma_\theta(B)$ 中 class ‘+’ 所对应的 element。</p>
<p>请注意，这里我们假设 <strong>二分类（即正面和负面）</strong>，尽管为<strong>更细粒度的情感分类设计规则</strong>很简单</p>
<h4 id="4-2-Named-Entity-Recognition"><a href="#4-2-Named-Entity-Recognition" class="headerlink" title="4.2    Named Entity Recognition"></a>4.2    Named Entity Recognition</h4><p>识别出句子中命名实体的 边界与类别 的任务称为 NER   类别例如“persons”和“organization” </p>
<p>为每个单词分配一个 命名实体 tag ，标注格式：”X-Y“  其中 X is one of BIEOS (Beginning,  Inside,  End,  Outside,  and Singleton) and Y 是 实体类别 entity category。 有效的标签序列 valid  tag  sequence  必须通过标签方案 tagging  scheme 的定义并 遵循某些约束。此外，在句子内或句子之间具有结构（例如，lists）的文本通常会暴露出一些一致性模式 consistency patterns</p>
<h5 id="Base-Network-1"><a href="#Base-Network-1" class="headerlink" title="Base Network"></a>Base Network</h5><p>该基础网络与（Chiu and Nichols，2015）为NER提出的 bi-directional LSTM recurrent  network  (called  BLSTM-CNN)  具有相似的架构，其性能优于大多数先前的神经模型。 该模型使用CNN和预训练的单词向量分别捕获字符级和单词级信息。然后将这些功能输入带有LSTM单元的双向RNN中进行<strong>序列标记。(NER也可看成是 序列标记问题)</strong>与Chiu和Nichols，2015年相比，我们省略了字符类型和大写特征以及输出层中的加性转换矩阵additive transition matrix。图2右侧面板显示了网络架构</p>
<h5 id="Logic-Rules-1"><a href="#Logic-Rules-1" class="headerlink" title="Logic Rules"></a>Logic Rules</h5><p>base network 很大程度上在每个位置做出独立的标记决策，<strong>而忽略了有效标记序列对连续标记的约束</strong>（例如， <strong>I-ORG cannot follow B-PER 开头的人名后面不跟着机构名？</strong>）。与最近的工作（Lample等人，2016）不同，后者添加了条件随机字段（CRF）来捕获输出之间的二元语法依赖关系，相反，我们应用了不会引入额外参数来学习的逻辑规则。一个示例规则是：<img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/Harnessing Deep Neural Networks with Logic Rules/image-20200728144143916.png" alt="image-20200728144143916" style="zoom:80%;" />将confidence 系数设置为 $\infty$ ，防止任何的冲突。</p>
<p>进一步利用同一文档的句子内部和之间的 $list$ 结构，具体而言，列表中相应位置的命名实体可能位于同一类别中。例如：in “1.  Juventus, 2.  Biarcelona, 3.  …”  we know “Barcelona” must be  an  organization  rather  than  a  location, since  its  counterpart  entity  “Juventus”  is  an organization </p>
<p>识别 补充材料中的 list 结构 和 counterparts 对等类别，设计 rule：<img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/Harnessing Deep Neural Networks with Logic Rules/image-20200728145117742.png" alt="image-20200728145117742"  /></p>
<p>$e_y$ 是 one-hot encoding of $y$ (the class prediction of X)   $c(·)$ 将具有相同类别的标签上的probability mass 折叠为单个概率，从而得出长度等于类别数量的向量.  用 $\ell_2$ 距离 作为 衡量 prediction of $X$ 和 其 对等 counterpart $A$ 的 closeness，将 距离在[0,1]间取值 即 软真值</p>
<h3 id="5-Experiments"><a href="#5-Experiments" class="headerlink" title="5    Experiments"></a>5    Experiments</h3><p>我们发现能够进行显式联合推理的教师网络 q 比 蒸馏的学生网络 p性能好</p>
<p>我们通过在各种公共基准 public benchmarks 上评估 情感分类和命名实体识别 的应用来验证我们的框架。</p>
<p>实验参数：</p>
<p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/Harnessing Deep Neural Networks with Logic Rules/image-20200728150027718.png" alt="image-20200728150027718"></p>
<h4 id="5-1-Sentiment-Classification"><a href="#5-1-Sentiment-Classification" class="headerlink" title="5.1    Sentiment Classification"></a>5.1    Sentiment Classification</h4><p> <strong>commonly  used  benchmarks：</strong></p>
<ol>
<li><strong>SST2</strong>，斯坦福情感树库 Stanford Sentiment Treebank（Socher et al。，2013），在训练/开发/测试集中包含2个类别（负和正），分别包含6920/872/1821个句子。接下来（Kim，2014年），由于句子和短语上都提供了标签，因此我们在句子和短语上都训练了模型。</li>
<li><strong>MR</strong>（Pang and Lee，2005），一组10,662个单句电影评论，带有负面或正面情绪。</li>
<li><p><strong>CR</strong>（Hu和Liu，2004），各种产品的客户评论，包括2个类(负面或正面) 和3,775个实例。</p>
<p>For <strong>MR and CR</strong>, we use <strong>10-fold cross validationas</strong> in previous work. 在这三个数据集中，每个数据集中约有15％的句子包含“ but”一词。</p>
</li>
</ol>
<p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/Harnessing Deep Neural Networks with Logic Rules/image-20200728150836802.png" alt="image-20200728150836802"></p>
<p>对于基础神经网络，我们使用（Kim，2014年）中的“非静态”版本，且配置完全相同。使用word2vec初始化单词向量（Mikolov等，2013），并在整个训练过程中对其进行微调，并使用SGD，Adadelta优化器训练神经参数。</p>
<p>第5行）是唯一显示出比我们更好的结果的系统。他们的神经网络组合了各种不同的预训练词嵌入集diverse sets of pre-trained word embeddings（而我们仅使用word2vec），并且比我们的模型包含更多的神经层和参数。</p>
<p>为了进一步研究我们的框架在 <strong>集成结构化规则知识</strong>这一类方法中 的有效性，我们将其与其他各种可能的集成方法进行了比较。表2列出了这些方法及其在SST2任务上的性能。</p>
<p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/Harnessing Deep Neural Networks with Logic Rules/image-20200728151327600.png" alt="image-20200728151327600">与第6行中的流水线方法（类似于结构编译工作）（Liang等人，2008）相比，我们的迭代蒸馏（3.2节）提供了更好的性能。我们方法的另一个优点是我们只训练一组神经参数(因为 teacher network的输出 条件概率是通过闭式解得到的)，而不是两个单独的参数集。</p>
<p>与基础CNN相比，distilled 的 学生网络“ -Rule-p” 具有更高的准确性，而“ -project” 和 “ -opt-project” 则将CNN明确投影到规则约束的子空间 rule-constrained subspace 中。这验证了我们的蒸馏过程将结构化知识有效地转化为神经参数。“ -opt-project”的准确性较差的部分原因是其神经网络部分的性能较差，其仅达到85.1％的准确性，并导致对等式（5）中“ but”规则的评估不准确。</p>
<p><strong>在半监督学习中的应用</strong></p>
<p>接下来，我们将探索具有不同数量的标记实例 varying  numbers  of  labeled  instances  的框架的性能，以及<strong>利用未标记数据的效果</strong>。直观地讲，<strong>我们希望使用较少标记的示例来提高通用规则对性能的贡献，而未标记的数据应有助于更好地从规则中学习</strong>。这可能是一个有用的属性，尤其是在<strong>数据稀疏且标签价格昂贵的情况下</strong>。表3示出了结果。降采样subsampling  是在句子级别上进行的。也就是说，例如，在“ 5％”中，我们首先随机均匀地选择5％的训练句子，然后根据这些词句及其短语对模型进行训练。(That  is,  for  instance,  in  “5%”  we  firstselected 5% training sentences uniformly at random, then trained the models on these sen-tences  as  well  as  their  phrases.)结果证实了我们的期望。1）第1-3行给出仅使用数据标签子集进行训练的准确性。在每种情况下，我们的方法始终优于基本的CNN。2）“ Rule-q”在5％的数据（保证金为2.6％）上的改进要比较大的数据（例如，在10％的数据上为2.3％，在30％的数据上为2.0％）更高。数据上下文。3）通过在第5-6行中添加未标记的实例进行半监督学习，可以进一步提高准确性。4）第4行，“-semi-PR”是后验正则化（Ganchev等人，2010），它施加了规则约束在训练过程中仅通过未标记的数据。我们的蒸馏框架始终提供更好的结果。</p>
<p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/Harnessing Deep Neural Networks with Logic Rules/image-20200728152053215.png" alt="image-20200728152053215"></p>
<h4 id="5-2-Named-Entity-Recognition"><a href="#5-2-Named-Entity-Recognition" class="headerlink" title="5.2    Named Entity Recognition"></a>5.2    Named Entity Recognition</h4><p>NER 任务：</p>
<p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/Harnessing Deep Neural Networks with Logic Rules/image-20200728152213964.png" alt="image-20200728152213964"></p>
<p>我们 的 base BLSTM网络 使用的配置与Chiu和Nichols（2015）中的配置基本相同，不同之处在于，除了略微的体系结构差异（第4.2节）之外，我们还使用 Adadelta 进行参数更新。（Pennington et al。，2014）<strong>GloVe词向量</strong> 用于初始化<strong>词特征 word features</strong>。</p>
<h3 id="6-Discussion-and-Future-Work"><a href="#6-Discussion-and-Future-Work" class="headerlink" title="6    Discussion and Future Work"></a>6    Discussion and Future Work</h3>]]></content>
      <categories>
        <category>First Order Logic Rules</category>
        <category>Neural Networks with Logic Rules</category>
        <category>Knowledge Distillation</category>
        <category>Posterior Regularization</category>
      </categories>
      <tags>
        <tag>first order logic rules</tag>
        <tag>student-teacher network</tag>
        <tag>knowledge distillation</tag>
        <tag>posterior regularization</tag>
      </tags>
  </entry>
  <entry>
    <title>A Short Introduction to Probabilistic Soft Logic 阅读笔记</title>
    <url>/blog/2020/07/21/A%20Short%20Introduction%20to%20Probabilistic%20Soft%20Logic/</url>
    <content><![CDATA[<a id="more"></a>
<h3 id="『』阅读笔记"><a href="#『』阅读笔记" class="headerlink" title="『』阅读笔记"></a>『』阅读笔记</h3><h3 id="project-address"><a href="#project-address" class="headerlink" title="project address"></a><a href="https://psl.linqs.org/">project address</a></h3><p><a href="https://github.com/linqs/psl">code</a></p>
<p><a href="https://www.youtube.com/watch?v=EIe-JBE8kRg">介绍视频</a></p>
<p>统计关系学  statistical relational learning</p>
<h3 id="专有名词"><a href="#专有名词" class="headerlink" title="专有名词"></a>专有名词</h3><p>rule learning 规则学习</p>
<p><a href="https://leanprover.github.io/logic_and_proof/first_order_logic.html">first order logic rules </a>——<a href="[https://zh.wikipedia.org/wiki/%E4%B8%80%E9%98%B6%E9%80%BB%E8%BE%91](https://zh.wikipedia.org/wiki/一阶逻辑">一阶逻辑</a>)</p>
<p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/A Short Introduction to Probabilistic Soft Logic/image-20200726120840738.png" alt="image-20200726120840738"></p>
<p>Atom 原子公式：<a href="[https://zh.wikipedia.org/wiki/%E5%91%BD%E9%A2%98%E9%80%BB%E8%BE%91](https://zh.wikipedia.org/wiki/命题逻辑">命题逻辑</a>)</p>
<ol>
<li><a href="https://link.springer.com/referenceworkentry/10.1007%2F978-0-387-30164-8_140">collective classification</a></li>
<li><a href="https://en.wikipedia.org/wiki/Ontology_alignment">ontology alignment</a></li>
<li><a href="https://en.wikipedia.org/wiki/Personalized_medicine">personalized medicine</a></li>
<li><a href="https://link.springer.com/referenceworkentry/10.1007%2F978-1-4939-7131-2_379">opinion diffusion</a></li>
<li>trust in social networksolollllllllllllllllllll+</li>
<li><a href="https://www.jianshu.com/p/24fcf19b78da">graph summarization</a></li>
<li><a href="https://en.wikipedia.org/wiki/T-norm">t-norm</a>:    t-norm is a binary algebraic operation on the interval [0, 1], </li>
<li><a href="https://blog.csdn.net/jbb0523/article/details/79437497"> MPE inference</a></li>
<li>共识优化  <a href="https://www.cvxpy.org/examples/applications/consensus_opt.html">consensus optimization </a></li>
<li><strong>logic rules 逻辑规则，规则 rule：</strong></li>
<li><strong>一阶谓词逻辑：</strong></li>
<li><strong>原子命题：<a href="[https://zh.wikipedia.org/wiki/%E5%8E%9F%E5%AD%90%E5%85%AC%E5%BC%8F](https://zh.wikipedia.org/wiki/原子公式">原子公式</a>)</strong></li>
<li><strong>解释 interpretation：</strong></li>
<li><strong>rule 的 grounding 数：</strong></li>
<li>ground rule: 基本规则</li>
</ol>
<hr>
<p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/A Short Introduction to Probabilistic Soft Logic/image-20200725162947109.png" alt="image-20200817235935237" width = "50%" height = "50%" /></p>
<p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/A Short Introduction to Probabilistic Soft Logic/image-20200818094838660.png" alt="image-20200818094838660" width = "50%" height = "50%" /></p>
<p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/A Short Introduction to Probabilistic Soft Logic/image-20200818094909425.png" alt="image-20200818094909425" width = "50%" height = "50%" /></p>
<p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/A Short Introduction to Probabilistic Soft Logic/image-20200818095543339.png" alt="image-20200818095543339" width = "50%" height = "50%" /></p>
<p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/A Short Introduction to Probabilistic Soft Logic/image-20200818095145583.png" alt="image-20200818095145583" width = "50%" height = "50%" /></p>
<p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/A Short Introduction to Probabilistic Soft Logic/image-20200818095205647.png" alt="image-20200818095205647" width = "50%" height = "50%" /></p>
<p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/A Short Introduction to Probabilistic Soft Logic/image-20200818104152253.png" alt="image-20200818104152253" style="zoom:50%;" /></p>
<p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/A Short Introduction to Probabilistic Soft Logic/image-20200818152654995.png" alt="image-20200818152654995" width = "50%" height = "50%" /></p>
<p>定义：</p>
<p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/A Short Introduction to Probabilistic Soft Logic/image-20200818155834481.png" alt="image-20200818155834481" width = "50%" height = "50%" /></p>
<p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/A Short Introduction to Probabilistic Soft Logic/image-20200818154410912.png" alt="image-20200818154410912" width = "50%" height = "50%" /></p>
<p><strong>使得 Rules will behave like boolean logic</strong> (布尔逻辑用真值时，条件语句的真值表一致)</p>
<p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/A Short Introduction to Probabilistic Soft Logic/image-20200818153523164.png" alt="image-20200818153523164" width = "50%" height = "50%" /></p>
<p>satisfaction：左边ground atoms的值要大于等于 右边 atoms 的值</p>
<p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/A Short Introduction to Probabilistic Soft Logic/image-20200818153533540.png" alt="image-20200818153533540" width = "50%" height = "50%" /></p>
<p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/A Short Introduction to Probabilistic Soft Logic/image-20200818153629491.png" alt="image-20200818153629491" width = "50%" height = "50%" /></p>
<p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/A Short Introduction to Probabilistic Soft Logic/image-20200818160349166.png" alt="image-20200818160349166" width = "50%" height = "50%" /></p>
<p><strong>详细查看：</strong></p>
<p><a href="https://www.jmlr.org/papers/volume18/15-631/15-631.pdf">Hinge-Loss Markov Random Fields and Probabilistic Soft Logic</a></p>
<p><a href="https://www.slideshare.net/knowfrominfo/grand-psl-talkdec62010">slide1</a></p>
<p><a href="http://www.cs.umd.edu/~getoor/Talks/RuleML-PSL-July-13.pdf">slide2</a></p>
<p><a href="http://piazza.com/class_profile/get_resource/jcoztzkoa973d2/jhmnxr5zg223ad?">slide3</a></p>
<hr>
<ol>
<li><strong>可以为用户之间的不同类型的关系（例如友谊或家庭关系）建模，而且还可以对多种相似性概念</strong> </li>
<li>ground out all rules：将predicate中的变量都用实例填充</li>
<li>convert ground rules to hinge-loss functions</li>
<li>constructing a HL-MRF</li>
<li>making prediction</li>
</ol>
<h3 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h3><p>概率软逻辑(Probabilistic soft logic  PSL)是用于<strong>关系域 relational domains 中</strong>的 <strong>集体概率推理 collective, probabilistic reasoning 的框架</strong>。 PSL 将<strong>一阶逻辑规则 first order logic rules</strong>  用作<strong>图模型 graphical models 的模板语言 template language</strong>，该图模型<strong>针对区间为 [0, 1] 的具有软真值 soft truth values  的随机变量</strong>。在此设置下的<strong>推断是一项连续的优化任务 Inference in this setting is a continuous optimization task</strong> 。该文概述了 PSL 语言及其<strong>推理和权重学习技术</strong> techniques for inference and weight learning 。</p>
<h3 id="1-Introduction"><a href="#1-Introduction" class="headerlink" title="1  Introduction"></a>1  Introduction</h3><p>人工智能中的许多问题都需要 <strong>处理关系结构和不确定性 relational structure and uncertainty</strong> 。因此，对促进<strong>具有关系结构的复杂概率模型 probabilistic models with relational structure</strong> 的开发的工具的需求不断增长。这些工具应将高级建模语言与通用算法相结合，以在最终的概率模型或概率程序中进行 推断 inference 。最近开发的框架，基于图模型，关系逻辑或编程语言的思想 graphical models, relational logic, or programming languages</p>
<p>作者概述了有关概率软逻辑（PSL 的最新工作。PSL模型已在各个领域开发，包括<strong>集体分类 collective classification，本体对齐 ontology alignment，个性化医学 personalized medicine，意见扩散 opinion diffusion ，对社交网络的信任 trust in social networks和图摘要 graph summarization</strong>。PSL 的<strong>主要区别特征是它在间隔[0，1]中使用软真值</strong>。This allows one to directly <strong>incorporate similarity functions,both on the level of individuals and on the level of sets</strong>.  例如，在社交网络中对意见 opinions in social networks 进行建模时，<strong>PSL不仅可以为用户之间的不同类型的关系（例如友谊或家庭关系）建模，而且还可以对多种相似性概念 multiple notions of similarity（例如基于爱好，信念或对特定观点的意见）进行建模</strong>。从技术上讲<strong>，PSL将感兴趣的域表示为逻辑原子 logical atoms</strong>。它<strong>使用一阶逻辑规则 first order logic rules 捕获域的依赖结构，并以此为基础在所有原子logical atoms上构建联合概率模型</strong>。<strong>每条规则 rule 都有一个相关的非负权重</strong>，可以捕获该规则 rule 的相对重要性。由于<strong>使用了软真值，PSL中的推理是连续优化问题</strong>。</p>
<p>下面介绍 PSL建模语言 及其 用于最可能的解释和边际推断 most probable explanation and marginal inference 的 高效算法的概述。</p>
<h3 id="2-PSL-Semantics"><a href="#2-PSL-Semantics" class="headerlink" title="2  PSL Semantics"></a>2  PSL Semantics</h3><p>一个PSL程序由一组一阶逻辑规则组成，这些规则具有连接体 conjunctive bodies 和单个文字头 single literal heads 。<strong>每条规则 rule 都有一个相关的非负权重</strong>，可以捕获该规则 rule 的相对重要性。</p>
<p>以下示例程序对 基于社交网络的简单模型 进行编码，以预测选民的行为，该社交网络具有两种表示朋友 <em>friend</em> 和配偶关系 <em>spouse</em> 的链接：</p>
<p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/A Short Introduction to Probabilistic Soft Logic/image-20200725162947109.png" alt="image-20200725162947109" style="zoom:80%;" /></p>
<p>上面的两条 first order logic rules ：从权重分配 认为  <strong>spouses are more likely to vote for the same party than friends</strong></p>
<p>虽然PSL与一阶逻辑共享其 规则 的语法，但它使用来自位于 [0,1] 的 软真值，而不是仅使用0（false）和1（true）真值。<strong>Given a set of atoms $\ell=\{\ell_1,…,\ell_n\}$  我们将映射 $I: \ell \rightarrow[0,1]^n$ 从 atoms 到 软真值 称为 <em>解释 interpretation</em>。</strong>   <strong>PSL 定义了  <em>interpretation</em> 上的概率分布</strong>   使得更有可能满足 更基本的规则实例 satisfying more ground rule instances——即在 <em>interpretation</em> 空间根据概率分布选择有利的，在上面的示例中，我们倾向于  一个人的投票结果会与朋友一致的解释 interpretation ，即 satisfies many groundings of 规则(1)，但在朋友和配偶之间进行权衡的情况下，由于较高的规则(2)的权重，投票上首选与配偶达成一致——即 “与配偶达成一致” 的 解释 <em>interpretation</em>  更好的满足 。</p>
<p>为了确定 基本规则 的满足程度  the degree to which a ground rule is satisfied，<strong>用 Lukasiewicz t-norm co-norm</strong> 分别作为 逻辑 AND 和 OR 的松弛形式， 这样的松弛在两端的值是确定的 0和1，但在中间提供连续的映射。</p>
<p> Given an interpretation $I$ , the formulas for the relaxation of logical conjunction (∧), disjunction (∨), and negation (¬) are as follows：</p>
<p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/A Short Introduction to Probabilistic Soft Logic/image-20200725171242551.png" alt="image-20200725171242551" style="zoom:80%;" /></p>
<p>符号上的波浪线指的是从 布尔域 的松弛。</p>
<p>对于 <strong>基本的PSL规则  a ground PSL rule $r\equiv r_{body} \rightarrow r_{head} \equiv \tilde \neg  r_{body}\tilde\lor r_{head}$  (条件表达式性质)，</strong> 在 rule 中的 atoms上定义的 interpretation $I$ 将确定 r 是否满足要求，如果不满足，则说明其满足的距离 its distance to satisfaction。 </p>
<p><strong>Abusing notation，</strong> 我们将 $I$ 的使用范围扩大到  logical formulas。  logical formulas 公式的真值是通过从 $I$ 所指定的原子atom的真值开始  应用上述逻辑运算符的定义而获得的<strong>(命题逻辑？)</strong>(The truth value of a formula is obtained by applying the above definitions of the logical operators starting from the truth values of atoms as specified by $I$ 即上面通过应用 t-norm co-norm 得到的松弛后的逻辑运算符)</p>
<p>当给定一个 $I$， a rule $r$ is satisfied，也就是说 $I(r)=1$ (将 $I$ 的使用范围扩大到了  logical formulas上)当且仅当 $I(r_{body}) \le I(r_{head})$ ,也就是说 the head has at least the same truth value as the body. 同样，当真实值限制为0和1时，这与 rule satisfaction 的通常定义是一致的。  The rule’s <em>distance</em> to <em>satisfaction</em>  under interpretation $I$ then measures the degree to which this condition is violated  这条 rule 到 satisfaction 的距离衡量了 该条件违背 satisfaction 的程度</p>
<script type="math/tex; mode=display">d_r(I)=max\{0,I(r_{body})-I(r_{head})\}</script><p><strong>举例：</strong></p>
<p>考虑这个 Interpretation<br>$I=\{spouse(b,a) \mapsto 1, votesFor(a,p) \mapsto 0.9, votesFor(b,p) \mapsto 1\}$ </p>
<p> $r$ 表示 the  corresponding  ground  instance  of <img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/A Short Introduction to Probabilistic Soft Logic/image-20200726133404692.png" alt="image-20200726133404692" style="zoom:80%;" /></p>
<p>conjunction 松弛计算 $I(r_{body})=max\{0,1+0.9-1\}=0.9$ </p>
<p>条件假设 松弛计算$d_r(I)=max\{0,0.9-0.3\}=0.6$ </p>
<p>当 $I(r_{head})$ 的值大于或等于 0.9 则 距离为0</p>
<p>当给定 a set of ground atoms $\ell$  of interest，PSL 产生一个在可能的 interpretations $I$ 上的概率分布。</p>
<p>设 <strong>R</strong> be the set of all <strong>ground rules</strong> that are instances of a rule in the program。只在 $\ell$ 中有 atoms，$I$ 的概率密度函数 f 为</p>
<p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/A Short Introduction to Probabilistic Soft Logic/image-20200726175458909.png" alt="image-20200726175458909" style="zoom:80%;" /></p>
<p>其中 $\lambda_r$ 是 rule $r$ 的 权重，$Z$ 是 continuous version of the normalization constant used indiscrete Markov random fields, $p \in \{1,2\}$ 提供两种损失函数的选择</p>
<p><strong>补充 indiscrete Markov random fields：</strong></p>
<p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/A Short Introduction to Probabilistic Soft Logic/image-20200726180232206.png" alt="image-20200726180232206"></p>
<p><strong>线性损失函数（p = 1）倾向于 completely satisfy one rule 的 <em>interpretations</em>，但对于冲突规则而言，与 satisfaction 的距离要更远一些。而对于 平方损失函数 favors interpretations that satisfy all rules to some degree, which typically have truth values farther away from the extreme values</strong></p>
<p> individual atoms $\ell_i$ 的值 通过 线性等式和不等式约束可以进一步限制。当出现违背这些约束时，我们设置 $f(I)=0$ ，并且限制 Z 的积分限 constrain the domain of integration for the normalization constant $Z$ accordingly.</p>
<p>这使人们可以编码其他领域知识  domain knowledge ，例如 a predicate being functional. 举例：在上面选民的例子中，每个选民 $a$ 不能投票超过一个参与党派 $p_1,p_2,…,p_n$，这就给了函数 $votesFor(.,.)$ 添加了约束</p>
<h3 id="3-Inference-and-Learning-in-PSL"><a href="#3-Inference-and-Learning-in-PSL" class="headerlink" title="3  Inference and Learning in PSL"></a>3  Inference and Learning in PSL</h3><p>PSL 为以下两项关键任务提供了有效的推论 inference  方法</p>
<ol>
<li><strong>MPE inference:</strong> 根据证据变量的取值，输出未知变量各种取值的概率</li>
<li>计算边际分布  computing marginal distribution</li>
</ol>
<p><strong>PSL程序的形式以及软真值的使用  可确保  非零密度nonzero density的解释空间interpretations space  形成   凸多面体 convex polytope</strong>。两种设置的推理算法都利用  凸的性质  来实现效率。此外，<strong>PSL还提供了从标记数据中学习权重的方法</strong>。我们在这里总结了主要思想，并参考相应的技术文章以获取完整详细信息</p>
<h4 id="MPE-Inference"><a href="#MPE-Inference" class="headerlink" title="MPE Inference"></a>MPE Inference</h4><ol>
<li>PSL中的第一个常见推理任务是 find the most probable interpretation given evidence (MPE)，即，拓展给定部分解释 partial interpretation 下最有可能得到的解释 interpretation。这意味着最大化等式<img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/A Short Introduction to Probabilistic Soft Logic/image-20200726191002638.png" alt="image-20200726191002638" style="zoom:80%;" />中的密度函数 $f(I)$，这等效于最小化指数的求和，同时要满足  the evidence 以及 等式不等式约束。例如，在投票的例子中，给定社交网络和在民意测验中获得的少数人的真实投票行为，MPE推论得出所有其他人中最有可能的投票行为。</li>
<li>如 Broecheleret 等人[4]所示，可以将此约束优化问题转换为二阶锥规划 <a href="https://en.wikipedia.org/wiki/Second-order_cone_programming">second order cone program（SOCP）</a>。The SOCP can be solved in time $O(n^{3.5})$,  where <strong>n</strong> is the number of relevant rule groundings, that is, those with non-zero distance to satisfaction. 为了避免操纵 avoid manipulation 不相关 的规则，PSL 遵循一种迭代方法，在构造SOCP之前，根据 evidence atoms  的真值 和非证据原子的当前真值确定一组相关规则 the set of relevant rules 。最初，真值0用于非证据原子。在构造并求解了 SOCP 之后，根据当前的MPE interpretation 更新相关规则集。重复此过程，直到不再激活任何规则 no more rules get activated.</li>
<li>最近，Bachet等人证明了基于 共识优化  consensus optimization 的 MPE推理 可以实现线性可扩展性 linear scalability  ，同时其准确性仅比上述方法中使用的标准立方时间 SOCP solvers略低。共识优化 将优化问题 分解为 由其他约束联系在一起的独立的小问题。 在 PSL 中，separate subproblems  are  created  for  each  ground  rule。每个 此类子问题 都使用其自己的本地文字副本 own  local  copies  of literals，并引入了约束，这些约束将这些本地副本的真值与相应原始文字的真值等同 equate the truth values of these local copies with those of the corresponding original literal。例如，对于a given person $a$ and party $p$，all groundings of 规则（1）和（2）在原始优化问题中都依赖于 $votesFor(a,p)$，但是通过在共识优化中使用该原子的不同副本而独立。共识优化然后<strong>在</strong>（a）优化本地副本的真值作为在最小化它们对原始目标的贡献以及与原始原子的同意之间进行权衡(minimizing their contribution to the original objective and their agreement with the original atom)     <strong>和</strong> （b）将原始原子的真值更新为它们的本地副本的平均值，其中所有子问题均具有闭式解 之间 <strong>迭代</strong></li>
</ol>
<h4 id="Computing-Marginal-Distributions"><a href="#Computing-Marginal-Distributions" class="headerlink" title="Computing Marginal Distributions"></a>Computing Marginal Distributions</h4><p><strong>The second common inference task in PSL</strong> ：</p>
<p>计算 $P(l\le I(\ell_i)\le u)$ 即 一个 atom $\ell_i$ 从给出的区间 $[l,u]$ 取得一个真值的概率。</p>
<p>Broecheler和Getoor [3]引入了一种采样算法 sampling algorithm 来近似这种边际分布 marginal distributions ， 一般来说，这是一个 <strong>#P-hard problem</strong> in the number of ground atom。</p>
<p><strong>直观地来说，计算这个概率 corresponds to computing the volume of the corresponding slice of the convex polytope of non-zero density interpretations.</strong> 对应于计算非零密度解释的凸多面体的相应切片的体积。</p>
<p>在PSL中，边际分布 marginal distributions 是通过 hit-and-run Markov chain Monte Carlo scheme(命中并运行的马尔可夫链蒙特卡洛斯) 后 收集采样点的直方图来估算的。 从如上所述有效地获得的 <strong>MAP状态</strong> 开始，算法首先通过随机 均匀地采样 一个方向，然后在该多面体内的 线段line segment上 采样一个点来探索凸多面体。由于一般方案可能会卡在多面体的拐角处 get stuck in corners of the polytope，在拐角处大多数方向都不指向多面体内部，这些情况是可以检测到，应用松弛方法将 方向采样限制为仅在可行方向采样</p>
<h4 id="Weight-Learning"><a href="#Weight-Learning" class="headerlink" title="Weight Learning"></a>Weight Learning</h4><p>可以通过<strong>最大似然估计</strong>来学习规则的权重 the weights of rules </p>
<p>对数似然 对 weight $\lambda_i$ 的梯度是：</p>
<p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/A Short Introduction to Probabilistic Soft Logic/image-20200726204526494.png" alt="image-20200726204526494" style="zoom:80%;" /></p>
<p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/A Short Introduction to Probabilistic Soft Logic/image-20200726204549896.png" alt="image-20200726204549896" style="zoom:80%;" /></p>
<h3 id="4-Related-Work"><a href="#4-Related-Work" class="headerlink" title="4  Related Work"></a>4  Related Work</h3><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>细节上，PSL使用“软”逻辑作为其逻辑组成部分，以马尔可夫网络作为其统计模型。</p>
<p>概率软逻辑中的软逻辑指 逻辑结构真值不需要被严格的限制为0或1，可以是0-1之间的某个值</p>
<p>逻辑公式</p>
<p>$similarName(X,Y) \rightarrow sameEntity(X, Y)$</p>
<p>它表达的逻辑意义可以理解为，如果X和Y具有相似甚至相同的name，那么我们可以说X和Y可能是同一个人，而 $similarName(X, Y)$ 的结果是0-1之间的某个值，具体的逻辑符号通过以下形式定义：</p>
<p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/A Short Introduction to Probabilistic Soft Logic/image-20200725171242551.png" alt="image-20200725171242551" style="zoom:80%;" /></p>
<p>在PSL模型中，这些具体的逻辑公式将成为马尔科夫网络的特征，并且网络中的每个特征都会与一个权重相关联，决定它在特征之间相互作用的重要性。权重可以手动设置或是基于已有真实数据通过学习算法学习得到。PSL还提供了复杂的推理技术，同时利用软逻辑的特点将知识推理的复杂度优化到多项式时间，而不再是一个NP-HARD问题</p>
<h4 id="reference"><a href="#reference" class="headerlink" title="reference"></a><a href="https://www.jianshu.com/p/a7b57204c391">reference</a></h4>]]></content>
      <categories>
        <category>PSL</category>
        <category>First Order Logic Rules</category>
        <category>Neural Networks with Logic Rules</category>
      </categories>
      <tags>
        <tag>soft truth values</tag>
        <tag>first order logic rules</tag>
        <tag>relational domain</tag>
        <tag>constrained continuous Markov Random Field</tag>
        <tag>PSL</tag>
      </tags>
  </entry>
  <entry>
    <title>Neural Aspect and Opinion Term Extraction with Mined Rules as Weak Supervision</title>
    <url>/blog/2020/07/20/Neural%20Aspect%20and%20Opinion%20Term%20Extraction%20with%20Mined%20Rules%20as%20Weak%20Supervision/</url>
    <content><![CDATA[<a id="more"></a>
<h3 id="『Neural-Aspect-and-Opinion-Term-Extraction-with-Mined-Rules-as-Weak-Supervision』阅读笔记"><a href="#『Neural-Aspect-and-Opinion-Term-Extraction-with-Mined-Rules-as-Weak-Supervision』阅读笔记" class="headerlink" title="『Neural Aspect and Opinion Term Extraction with Mined Rules as Weak Supervision』阅读笔记"></a>『Neural Aspect and Opinion Term Extraction with Mined Rules as Weak Supervision』阅读笔记</h3><p>opinion term 和其描述的 aspect 以及 sentiment 高度相关。如果在抽取出 aspect 及预测出sentiment 同时，能给出表明该 sentiment 的 opinion term，将会使结果更加完整：aspect 给出了带有情感的评论目标，sentiment 给出了对目标的情感极性，opinion term 给出了情感的原因，这三者依次回答了What（对于什么），How（情感怎么样）以及 Why（为什么是这个情感）三个问题，对于评论目标构成更全面的分析</p>
<ol>
<li>提出了一种<strong>基于BiLSTM-CRF</strong>（双向LSTM条件随机场）的神经模型，<strong>用于aspect  and  opinion  term extraction</strong>，训练数据<strong>使用人类注释数据作为基本事实ground truth 监督和用mined规则注释的数据作为弱监督进行训练</strong>，类似半监督，但是这个方法在利用未标记的数据时引入了学习到的领域知识，所以和远程监督利用外部KB也有关。</li>
<li>自动挖掘的规则特点：<ul>
<li>作者说是不超过三个单词的规则，否则相关实例稀疏且对召回率的提高不大</li>
<li>其中一类基本类似关系挖掘得到的三元组，关系是 依存关系中的</li>
<li>另一类 是一对三元组，含义是 挖掘类似”联想”关系的一对，相同的 opinion term。</li>
</ul>
</li>
<li>在挖掘 aspect term时，需要事先准备 predefined opinion word vocabulary；文章认为 当提取 aspect term时，关注 动词和名词；当提取 opinion时 考虑adjectives, nouns and verbs，还要建立一个 opinion word vocabulary </li>
<li>具体实现中还采取不少提高效率的方法。</li>
</ol>
<h4 id="code"><a href="#code" class="headerlink" title="code"></a><a href="https://github.com/HKUST-KnowComp/RINANTE">code</a></h4><h3 id="专有名词"><a href="#专有名词" class="headerlink" title="专有名词"></a>专有名词</h3><h3 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h3><p>我们首先提出一种算法，该算法基于依存分析结果dependency parsing results从现有的训练示例<strong>中自动挖掘提取规则 mine extraction rules。然后将挖掘的规则应用于标记大量辅助数据。</strong>最后，我们研究既可以从规则自动标记的数据中学习，也可以从人为准确注释的少量数据中学习的模型的训练过程，以训练这样的神经模型。实验结果表明，尽管挖掘的规则由于灵活性有限而不能很好地发挥作用，但是人类注释数据和带有规则标记的辅助数据的组合可以改善神经模型。</p>
<h3 id="1-Introduction"><a href="#1-Introduction" class="headerlink" title="1  Introduction"></a>1  Introduction</h3><p>产品评论中有两种类型的字词或词组（或服务，餐厅等评论，为方便起见，我们在本文中使用“产品评论”）对于意见挖掘opinion  mining尤其重要：描述产品属性或属性的词或短语；以及与评论者对产品或产品方面有关的观点的看法。前者称为<strong>方面术语aspect terms</strong>，后者称为<strong>见解术语 opinion  terms</strong>。例如，在“笔记本电脑的速度speed令人难以置信incredible”这句话中，“speed”是一个方面的术语，“incredible”是一个见解的术语。方面和观点术语提取的任务是从产品评论中提取上述两种类型的术语。</p>
<p>基于规则的方法Rule  based  approaches  (Qiu  et  al.,  2011;  Liuet al., 2016) 和基于学习learning based 的方法 (Jakoband Gurevych, 2010; Wang et al., 2016)是完成此任务的两种主要方法。基于规则的方法通常使用基于dependency parsing结果的手动设计的规则来提取术语。这些方法的优点在于，可以始终提取在句子中使用某些<strong>特定模式</strong>的 aspect or opinion terms。</p>
<p><strong>基于学习的方法</strong>将aspect or opinion terms提取 建模 为<strong>序列标记问题sequence  labeling problem</strong>。尽管它们能够获得更好的性能，但它们还存在必须使用大量标记数据来训练此类模型以发挥其全部潜力的问题，尤其是在没有手动设计输入功能时。否则，它们甚至可能在非常简单的测试用例中失败（例如，请参阅第4.5节）</p>
<p>为了解决上述问题，我们<strong>首先使用基于规则的方法从辅助产品评论集中提取aspect  and  opinion  term ，这可以视为不正确的注释</strong> (use  a  <strong>rule  based  approach</strong>  to  <strong>extract  aspect and opinion terms from an auxiliary set of product reviews</strong>, which can be considered as inaccurate annotation)。这些<strong>规则</strong>是根据<strong>dependency parsing 结果</strong> <strong>从标记的数据</strong>中自动提取的。我们提出了一种<strong>基于BiLSTM-CRF</strong>（双向LSTM条件随机场）的神经模型，<strong>用于aspect  and  opinion  term extraction</strong>。神经模型<strong>使用人类注释数据作为基本事实ground truth 监督和用mined规则注释的数据作为弱监督进行训练</strong>。我们将方法命名为<em>RINANTE（Rule Incorporated Neural Aspect和Opinion Term Extraction）</em></p>
<p>我们对三个 <strong>SemEval 数据集 </strong>进行实验，这些数据集在现有aspect  and  opinion  term extraction研究中经常使用。</p>
<ul>
<li>对 基于BiLSTM-CRF的神经模型的训练 不仅包含人工标记的数据，还包含<strong>规则</strong>自动标记的数据</li>
<li>用于 aspect  and  opinion  term extraction 任务的数据标记规则 从based on dependency parsing and POS  tagging  results  自动找</li>
<li>充分的对比实验</li>
</ul>
<h3 id="2-Related-Work"><a href="#2-Related-Work" class="headerlink" title="2  Related Work"></a>2  Related Work</h3><p>方法主要有三种：基于规则的方法，基于主题建模的方法topic  modeling  based  approaches和基于学习的方法</p>
<h4 id="rule-based-approach"><a href="#rule-based-approach" class="headerlink" title="rule based approach:"></a><strong>rule based approach:</strong></h4><ol>
<li><strong>based  on  dependency  parsing  results</strong>  (Zhuang  et  al.,  2006;  Qiuet al., 2011)： <strong>这些方法中的规则通常只涉及一个句子中最多三个单词（邱等，2011），这限制了其灵活性(但在后后面又对点做出了解释，在我们的规则挖掘算法中，我们只挖掘不超过三个单词的规则)。</strong>手工设计规则也是一项劳动密集型的工作。刘等。（2015b）提出了一种从一组预先设计的规则中选择一些规则的算法，使得所选择的规则子集能够更准确地进行抽取。然而，与我们所使用的规则挖掘算法不同，它无法自动发现规则。</li>
<li><strong>Topic modeling approaches</strong> 主题 模型(Lin and He, 2009;Brody  and  Elhadad,  2010;  Mukherjee  and  Liu,2012) ：能得到 粗粒度的 aspects( <em>food,ambiance,service</em> for  restaurants,  and provide related words )(将主题作为隐变量，但不能具体extract 出exact aspect terms )</li>
<li><strong>Learning  based  approaches</strong> by labeling each word in a sentence <strong>with BIO (Begin, Inside, Outside) tagging scheme</strong>(Ratinov and Roth, 2009)—(<strong>序列标记问题sequence  labeling problem</strong>)：用 CNN 或 BiLSTM 提取句子中每个word的特征，再用CRF获得更好的序列标记结果。Word  embeddings  是常用的功能，也可以将手工制作的特征例如  POS tag  classes 和  chunk  information  组合起来以产生更好的性能（Liu等人，2015a; Yin等人，2016）。例如，Wang et al（2016）基于一个以Word  embeddings为输入的句子的依存解析树 dependency parsing tree of a sentence 构造了一个recursive neural network。然后将神经网络的输出输入到CRF。XU等（2018）使用CNN模型 提取aspect terms。他们发现<strong>同时使用general-purpose and domain-specific  word  embeddings 可以提高性能</strong></li>
</ol>
<p>我们的方法<strong>利用未标记的额外数据来改善模型的性能</strong>，这与半监督学习和迁移学习有关。一些方法允许在序列标记中使用未标记的数据 Jiaoet al. (2006) propose semi-supervised CRF, Zhanget al. (2017) propose neural CRF autoencoder。与我们的方法不同，<strong>这些方法在使用未标记的数据时不会整合有关任务的知识</strong>。杨等（2017）提出了三种不同的转移学习架构，它们允许神经序列标记模型 learn from both the target task and a different but related task。文章中的模型utilizing <strong>the output of a rule based approach for the same problem </strong>，与上面的工作区别。</p>
<p>我们的方法还与 weakly labeled data (Craven and Kumlien, 1999),  与信息抽取中使用的远程监管方法类似（Mintz等，2009）。</p>
<h3 id="3-RINANTE"><a href="#3-RINANTE" class="headerlink" title="3  RINANTE"></a>3  RINANTE</h3><p>在本节中，我们详细介绍我们的方法 RINANTE。假设我们有一个带有人类注释的数据集 $D_l$ 和 一个辅助数据集$D_a$   $D_l$ 包含一组产品评论，<strong>每个评论中都带有所有方面和观点术语</strong>;    $D_a$ 只包含一组<strong>未标记的产品评论</strong>。<strong>在$D_l$  and $D_a$ 中，所有评价都针对相同类型或几种相似类型的产品</strong>。通常， $D_a$ 未标记的大小比 $D_1$ 大得多。然后，RINANTE包括以下步骤</p>
<ol>
<li>在 $D_l$  用 a rule mining algorithm 挖掘  a set of <strong>aspect extraction rules </strong> $R_a$ 和 opinion extraction rules $R_o$ .</li>
<li>用 rules  $R_a$ 和 $R_o$  在 $D_a$ 的所有  reviews 中 提取 terms 作为 标签，则 $D_a$ 能被看成是 weakly labeled dataset <img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/Neural Aspect and Opinion Term Extraction with Mined Rules as Weak Supervision/image-20200801234518451.png" alt="image-20200801234518451" style="zoom:80%;" /></li>
<li>用<img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/Neural Aspect and Opinion Term Extraction with Mined Rules as Weak Supervision/image-20200801234542926.png" alt="image-20200801234542926" style="zoom:80%;" /> 训练神经网络</li>
</ol>
<h4 id="3-1-Rule-Mining-Algorithm"><a href="#3-1-Rule-Mining-Algorithm" class="headerlink" title="3.1  Rule Mining Algorithm"></a>3.1  Rule Mining Algorithm</h4><p>rules 主要基于dependency  relations between words 因为它们的有效性已经通过现有的基于规则的方法得到了验证(Zhuang et al., 2006; Qiu et al., 2011)</p>
<p>用三元组 $(rel, w_g,w_d)$ 表示依存关系，$w_g$ 是 governor支配词 $w_d$ 是 dependent从属词</p>
<p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/Neural Aspect and Opinion Term Extraction with Mined Rules as Weak Supervision/image-20200802092207665.png" alt="image-20200802092207665" style="zoom:80%;" /></p>
<p>上图例子中：<em>“system”  is an aspect term, and “horrible” is an opinion term</em></p>
<p><strong>常用的提取 aspect term 的规则：$(nsubj, O, noun^∗),$</strong> we use $O$ to represent a <strong>pattern</strong> that matches any word that belongs to a <strong>predefined opinion word vocabulary</strong>;   $noun^∗$ matches any <strong>noun word</strong> and the ∗ means that the matched word is <strong>output as the aspect word.</strong>  根据这个规则，如果 horrible 被 $O$ match到，则可以输出 aspect term “system”</p>
<p><strong>细节：</strong> <strong>在我们的规则挖掘算法中，我们只挖掘不超过三个单词的规则</strong>，因为涉及很多单词的规则可能对召回recall的影响很小，但是挖掘起来在计算上却很昂贵，并且这种模式不经常发生所以需要尽多的标记数据来cover这种情况</p>
<p>提取 aspect 和 提取 opinion 的算法相似</p>
<p>算法包含两部分</p>
<ol>
<li>Generating <strong>rule candidates</strong> based on a <strong>training set</strong></li>
<li><strong>Filtering</strong> the rule candidates based on their effectiveness on a <strong>validation set</strong></li>
</ol>
<div class="group-picture"><div class="group-picture-container"><div class="group-picture-row"><div class="group-picture-column" style="width: 50%;"><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/Neural Aspect and Opinion Term Extraction with Mined Rules as Weak Supervision/image-20200802093738286.png" alt="image-20200802093738286" style="zoom:80%;" /></div><div class="group-picture-column" style="width: 50%;"><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/Neural Aspect and Opinion Term Extraction with Mined Rules as Weak Supervision/image-20200802093813363.png" alt="image-20200802093813363" style="zoom:80%;" /></div></div></div></div>
<p><strong>函数 RelatedS1Deps：</strong>  returns a list of dependency relations.   每个dependency relations里的governor or the dependent必须是 $s_i.aspect_terms$中的一个元素</p>
<p><strong>PatternsFromS1Deps：</strong> 从上面返回的list中 得到 aspect term extraction patterns</p>
<p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/Neural Aspect and Opinion Term Extraction with Mined Rules as Weak Supervision/image-20200802100757705.png" alt="image-20200802100757705" style="zoom:80%;" /></p>
<p>通过 POS得到 词性标注 (JJ - Adjective 形容词)，通过 $ps()$ 函数从POS tag得到 the word type。只有当 $ps(w)$ 是 $noun$ or $verb$ 才自动生成上述的 pattern 或者 $w_g$ 在 predefined  aspect term中时，生成关于 Opinion 的pattern是相似的。</p>
<p><strong>RelatedS2Deps：</strong> 返回 a list that contains <strong>pairs of dependency relations</strong>  这个pair中的一个依存关系是RelatedS1Deps得到的，RelatedS2Deps的作用相当于为RelatedS1Deps生成的依存关系找到满足must have  one  word  in  common 的另一个依存关系。</p>
<p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/Neural Aspect and Opinion Term Extraction with Mined Rules as Weak Supervision/image-20200802102718668.png" alt="image-20200802102718668" style="zoom:80%;" /></p>
<p> <strong>FrequentPatterns:</strong> obtains  the  rule  candidates。 用阈值$ T$ (T is a predefined parameter that can be determined based on the total number of sentences in S.) 划分出出现次数多的pattern</p>
<p>RC1和RC2分别包含基于单个依赖关系和依赖关系对的候选抽取模式。将它们合并以获得最终规则候选者列表</p>
<p>通过在验证集上extract  aspect terms 实验，用这个结果对 mined 到的 rule 的precision进行估计，<strong>用阈值</strong> $p$ 去掉准确率低的 rules。</p>
<p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/Neural Aspect and Opinion Term Extraction with Mined Rules as Weak Supervision/image-20200802105043740.png" alt="image-20200802105043740" style="zoom:80%;" /></p>
<p>显示了从包含一个依赖关系的规则模式 $r$ 来 从句子$s$中 extracting aspect terms from a sentence的算法。</p>
<p><strong>函数 TermFrom: </strong> tries to obtain the <strong>whole term</strong> based on this <strong>matched seed word</strong> 具体来说，当它是动词时，它仅返回单词 $w_s$。但是当$w_s$ 是名词时，它会返回由包含$w_s$的名词word的连续序列形成的名词短语。</p>
<p>$V_{fil}$ includes the terms extracted with the candidate rules from the training set that are always incorrect经验法则。</p>
<p><em>在实践中，我们还构建了一个词典，该词典包括在训练集中常用的aspect  terms  。该字典用于通过直接匹配提取方面的术语。(泛化能力？过于拟合在训练集上？)</em></p>
<p><em>文章认为 当提取 aspect term时，关注 动词和名词；当提取 opinion时 考虑adjectives, nouns and verbs，还要建立一个 opinion word vocabulary</em> </p>
<h5 id="Time-Complexity"><a href="#Time-Complexity" class="headerlink" title="Time Complexity"></a>Time Complexity</h5><h4 id="3-2-Neural-Model"><a href="#3-2-Neural-Model" class="headerlink" title="3.2  Neural Model"></a>3.2  Neural Model</h4><p>在 $D_l$ 中 mine 出 rule后，在 weakly labeled dataset <img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/Neural Aspect and Opinion Term Extraction with Mined Rules as Weak Supervision/image-20200801234518451.png" alt="image-20200801234518451" style="zoom:80%; display:inline" align="middle" />中 obtain the aspect and opinion terms in each sentence。得到 terms 后，标注为  BIO tag sequences(命名实体复用序列标注)</p>
<p>由于挖掘的规则不准确，因此结果中可能存在<strong>冲突</strong>，即，可能会提取单词同时作为aspect term and an opinion term，所以对$D_a$ 中所有的 review，都保留aspect terms 和 opinion terms 两条 tag sequences。</p>
<p>目标是网络模型应该能够从上述两个标签序列和一组手动标记的数据中同时学习，则表示为$t_a t_o t_m$ 分别是<strong>predicting the terms</strong> extracted by the aspect term extraction rules ……</p>
<p>手动准确标记的数据中的 reviews 只需一个 tag sequence。然后我们可以训练一个既有ground truth supervision又有weak supervision的神经网络模型。我们提出了两个基于BiLSTM-CRF（Huang et al。，2015）的模型，可以基于这三个任务对其进行训练。其结构如图2所示。</p>
<div class="group-picture"><div class="group-picture-container"><div class="group-picture-row"><div class="group-picture-column" style="width: 50%;"><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/Neural Aspect and Opinion Term Extraction with Mined Rules as Weak Supervision/image-20200802115202026.png" alt="image-20200802115202026" style="zoom:80%;" /></div><div class="group-picture-column" style="width: 50%;"><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/Neural Aspect and Opinion Term Extraction with Mined Rules as Weak Supervision/image-20200802115211130.png" alt="image-20200802115211130" style="zoom:80%;" /></div></div></div></div>
<p>use pre-trained embeddings of the words in a sentence as input, then a BiLSTM-CRF structure is used to predict the labels  of  each  word.</p>
<p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/Neural Aspect and Opinion Term Extraction with Mined Rules as Weak Supervision/image-20200802120129926.png" alt="image-20200802120129926" style="zoom:80%;" /></p>
<p><strong>训练过程：</strong></p>
<ol>
<li>交替训练三个任务 $t_a t_o t_m$ </li>
<li>预先训练 $t_a$ and $t_o$ ，然后再训练 $t_m$ 。</li>
</ol>
<p>在第一种方法中，在每次迭代中，三个任务中的每一个都用于更新一次模型参数。</p>
<p>在第二种方法中，首先模型对任务 $t_a t_o$ 进行预训练，这两个任务交替训练结束后。然后将训练好保留参数的模型用来训练 $t_m$</p>
<p>引入早停正则化方法，对第一种方法或使用第二种方法训练  $t_m$ 时，根据验证集的性能（ aspect  term  extraction and opinion term extraction的F1分数之和）执行。  对第二种方法 与训练时，早停是根据 the sum of theF1scores of $t_a$ and $t_o$.</p>
<p>在  BiLSTM layers and the word embedding layers 后 加入  dropout layers</p>
<h3 id="4-Experiments"><a href="#4-Experiments" class="headerlink" title="4  Experiments"></a>4  Experiments</h3><h4 id="4-1-Datasets"><a href="#4-1-Datasets" class="headerlink" title="4.1  Datasets"></a>4.1  Datasets</h4><p>用三个数据集：<strong>SemEval-2014 Restaurants,  SemEval-2014  Laptops,  and  SemEval-2015  Restaurants</strong></p>
<p>由于 SemEval 中使用的原始数据集在每个句子中都没有 annotation of the opinion terms，因此我们使用(Wang et al., 2016) and (Wang et al., 2017) 提供的 opinion term annotations。作为 $D_l$</p>
<p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/Neural Aspect and Opinion Term Extraction with Mined Rules as Weak Supervision/image-20200802140038838.png" alt="image-20200802140038838" style="zoom:80%;" /></p>
<p>除了上述数据集，我们还使用了 Yelp dataset and  an  Amazon  Electronics  dataset  (Heand McAuley, 2016) as auxiliary data to be annotated with the mined rules.    作为 $D_a$，它们还用于训练 word embeddings。</p>
<p><strong>Yelp dataset</strong> 作为 SE14-R and SE15-R. 的 auxiliary data——includes  4,153,150  reviews  that  are  for  144,072different  businesses.</p>
<p><strong>Amazon  Electronics  dataset</strong> 作为  laptop  dataset  SE14-L 的 auxiliary data——1,689,188 reviews for 63,001 products such as lap-tops, TV, cell phones, etc.</p>
<h4 id="4-2-Experimental-Setting"><a href="#4-2-Experimental-Setting" class="headerlink" title="4.2  Experimental Setting"></a>4.2  Experimental Setting</h4><p>对于每个SemEval数据集，我们拆分训练集，并使用20％作为验证集。</p>
<p>对于SE14-L，我们将挖掘的规则应用于Amazon数据集的所有笔记本电脑评论，以获得自动注释的辅助数据，其中包括156,014条评论句子。</p>
<p>对于SE14-R和SE15-R，我们从Yelp数据集中随机抽取4％的 restaurant review 句子以应用挖掘的规则，其中包括913,443个sentences。</p>
<p>对于这两个自动注释的数据集，使用2,000个评论语句形成一个验证集，其余的用来形成训练集。它们在训练RINANTE的神经模型时使用。</p>
<p>我们使用 Stanford CoreNLP (Manninget al., 2014) 执行 dependency parsing and POS tagging。对于所有三个数据集，规则挖掘算法的规则候选生成部分中的频率阈值整数 <strong>T</strong> 均设置为10；精度阈值  <strong>p</strong> 设置为0.6。</p>
<p>我们将opinion  word  vocabulary  used  in  (Hu  andLiu,  2004)  用于aspect  term  extraction  rules。</p>
<p>在Yelp数据集和Amazon数据集的所有  reviews 上分别使用  word2vec（Mikolov等人，2013）训练两组100维word embeddings。BiLSTMs 的隐藏层大小  are all set to <strong>100.</strong>   <strong>Dropout rate</strong> is set to  0.5 for the neural models.</p>
<h4 id="4-3-Performance-Comparison"><a href="#4-3-Performance-Comparison" class="headerlink" title="4.3  Performance Comparison"></a>4.3  Performance Comparison</h4><div class="group-picture"><div class="group-picture-container"><div class="group-picture-row"><div class="group-picture-column" style="width: 100%;"><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/Neural Aspect and Opinion Term Extraction with Mined Rules as Weak Supervision/image-20200802141601709.png" alt="image-20200802141601709" style="zoom:80%;" /></div></div><div class="group-picture-row"><div class="group-picture-column" style="width: 50%;"><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/Neural Aspect and Opinion Term Extraction with Mined Rules as Weak Supervision/image-20200802141608237.png" alt="image-20200802141608237" style="zoom:80%;" /></div><div class="group-picture-column" style="width: 50%;"><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/Neural Aspect and Opinion Term Extraction with Mined Rules as Weak Supervision/image-20200802141627550.png" alt="image-20200802141627550" style="zoom:80%;" /></div></div><div class="group-picture-row"><div class="group-picture-column" style="width: 50%;"><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/Neural Aspect and Opinion Term Extraction with Mined Rules as Weak Supervision/image-20200802141638261.png" alt="image-20200802141638261" style="zoom:80%;" /></div><div class="group-picture-column" style="width: 50%;"><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/Neural Aspect and Opinion Term Extraction with Mined Rules as Weak Supervision/image-20200802141648624.png" alt="image-20200802141648624" style="zoom:80%;" /></div></div></div></div>
<ul>
<li><p><strong>NCRF-AE(Zhang et al., 2017)：</strong>  it is a neural <strong>autoencoder</strong> model that uses <strong>CRF</strong>. It is able to  perform  <strong>semi-supervised</strong>  learning  for  <strong>sequence labeling.</strong> The Amazon laptop reviews and the Yelp restaurant reviews are also used as unlabeled data for this approach。</p>
</li>
<li><p><strong>HAST  (Li  et  al.,  2018):</strong>  It  proposes  to  use <strong>Truncated  History-Attention</strong>  and  <strong>Selective Transformation  Network</strong>  to  improve  aspect extraction</p>
</li>
<li><strong>DE-CNN   (Xu   et   al.,   2018):</strong>  DE-CNN feeds both general-purpose embeddings and domain-specific  embeddings  to  a  Convolutional Neural Network model.</li>
</ul>
<p>我们还比较了RINANTE的两个简化版本：直接使用挖掘的规则提取术语；仅使用人类注释数据来训练相应的神经模型。具体来说，第二个简化版本使用BiLSTM-CRF结构模型，将每个单词在句子中的 embeddings  作为输入。 This structure is also studied in (Liu et al., 2015a). We name this approach RINANTE (no rule) 即这个用于序列标注的结构是研究过的，用 weekly labeled data来增强了数据，在如何weekly label 上引入了自动 mine rule。</p>
<p>从结果可以看出，只使用挖掘规则表现不佳。但是，通过从这些规则自动标记的数据中学习，RINANTE的所有四个版本都比RINANTE（无规则）具有更好的性能。这证明我们确实可以使用这些规则的结果来改善神经模型的性能。而且，对RINANTE（无规则）的改进在SE14-L 和 SE15-R上更加明显。我们认为这是因为SE14-L相对是困难得多的数据，而SE15-R的 人工标签数据要少得多。</p>
<p>在四个版本的RINANTE中，RINANTE-Double-Pre在SE14-L和SE15-R上表现最佳，而RINANTE-Shared-Alt在SE14-R上则稍好。因此，我们认为，为了利用 Mined rules 的结果，与共享的 单独一层 BiLSTM 相比，使用两个分离的 BiLSTM 层作为 aspect terms and opinion terms 更为稳定。同样，对于这两个模型，我们介绍的两种训练方法都可能获得良好的性能。一般而言，RINANTE-Double-Pre的性能更稳定。</p>
<p>与Double Propagation的 eight manually designed rules 相比 我们的算法能够挖掘数百个有效规则。</p>
<p><strong>由性能没超过的方法</strong></p>
<p>与其他方法相比，RI-NANTE（不包括RINANTE-Double-Pre†）仅在SE14-L和SE15-R的方面术语提取部分上无法提供最佳性能。在SE14-L，DE-CNN表现更好。但是，我们的方法同时提取了 aspect terms and opinion term，而DE-CNN和HAST仅关注 aspect terms。在SE15-R上，方面术语提取的最佳性能系统是Elixa，它依赖于手工制作的功能</p>
<h4 id="4-4-Mined-Rule-Results"><a href="#4-4-Mined-Rule-Results" class="headerlink" title="4.4  Mined Rule Results"></a>4.4  Mined Rule Results</h4><p>我们的规则挖掘算法提取的规则数量以及它们在测试集上提取的aspect and opinion terms。使用Intel i7-7700HQ在计算机上的每个数据集上挖掘这些规则所需的时间不到10秒2.8GHz CPU。在SE15-R上挖掘最少的规则，因为此数据集包含最少的训练样本。这还会导致挖掘的规则在此数据集上的性能较差。我们还显示了从SE14-L中提取的一些example aspect extraction rule，以及它们可以匹配并从中提取术语的例句。只需看一下模式，就很容易猜出第一，第二和第三条规则的“意图”。实际上，第一条规则和第二条规则通常用于基于规则的方面术语提取方法中（Zhuang等，2006； Qiu等，2011）。但是，我们仔细检查了所有的碎屑规则，发现它们实际上就像表4中的第四条规则，很难通过检查数据来手动设计。这也显示了人类设计此类规则的局限性。</p>
<p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/Neural Aspect and Opinion Term Extraction with Mined Rules as Weak Supervision/image-20200802144240086.png" alt="image-20200802144240086" style="zoom:80%;" /></p>
<h4 id="4-5-Case-Study"><a href="#4-5-Case-Study" class="headerlink" title="4.5  Case Study"></a>4.5  Case Study</h4><p>为了帮助您了解我们的方法是如何工作的，并获得了一些关于如何进一步改进它的见解，我们在表5中显示了SE14-L的一些示例语句，并附带了RINANTE（无规则）提取的方面条款，约束规则，RINANTE（RINANTE-Double-Pre）和DE-CNN。在第一行中，可以通过基于规则的方法轻松提取方面术语“ SuperDrive”。但是，如果没有足够的培训数据，那么RINANTE（无规则）仍然无法识别它。在第二行中，我们看到这些规则还可以帮助避免提取错误的术语。第三行也很有趣：虽然挖掘的规则仅提取“microphones”，但RI-NANTE仍然能够获得正确的短语“external microphones“，而不是盲目地遵循挖掘的规则。最后一行中的句子还具有一个方面术语，可以很容易地用规则将其提取出来。RINANTE的结果也是正确的。但是RINANTE（无规则）和DE-CNN都无法提取它。</p>
<p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/Neural Aspect and Opinion Term Extraction with Mined Rules as Weak Supervision/image-20200802144518345.png" alt="image-20200802144518345"></p>
<h3 id="5-Conclusion-and-Future-Work"><a href="#5-Conclusion-and-Future-Work" class="headerlink" title="5  Conclusion and Future Work"></a>5  Conclusion and Future Work</h3>]]></content>
      <categories>
        <category>Neural Networks with Logic Rules</category>
        <category>Distant Supervision</category>
        <category>Sentiment Analysis</category>
      </categories>
      <tags>
        <tag>sentiment analysis</tag>
        <tag>aspect and opinion terms extraction</tag>
        <tag>BiLSTM-CRF</tag>
        <tag>rule mining</tag>
        <tag>semi-supervision</tag>
      </tags>
  </entry>
  <entry>
    <title>Biomedical Event Extraction Based on Knowledge-driven Tree-LSTM</title>
    <url>/blog/2020/07/19/Biomedical%20Event%20Extraction%20Based%20on%20Knowledge-driven%20Tree-LSTM/</url>
    <content><![CDATA[<a id="more"></a>
<h3 id="『Biomedical-Event-Extraction-Based-on-Knowledge-driven-Tree-LSTM』阅读笔记"><a href="#『Biomedical-Event-Extraction-Based-on-Knowledge-driven-Tree-LSTM』阅读笔记" class="headerlink" title="『Biomedical Event Extraction Based on Knowledge-driven Tree-LSTM』阅读笔记"></a>『Biomedical Event Extraction Based on Knowledge-driven Tree-LSTM』阅读笔记</h3><ol>
<li>生物医学事件提取难点1：复杂上下文，对句子序列不做修改则 <em>trigger</em>和<em>argument</em>之间可能间隔10个words以上—对策：<strong>链式的LSTM来说很难捕捉到这种长距离的依赖关系，而在依存树结构中，它们的距离显著缩短</strong></li>
<li>生物医学事件提取难点2：领域知识—对策：远程监督，使用<strong>外部知识库 external knowledge bases</strong></li>
<li>做出两个修改</li>
<li>将句子的依存关系树输入TREE-LSTM</li>
<li>LSTM结构加入一个门控，控制远程监督信息输入到lstm unit的hidden state</li>
<li>​    对医学生物 KB的利用，主要包括</li>
<li>entity type—用在PubMed and PMC texts上预训练的word embedding生成词嵌入</li>
<li>gene ontology function—用state of-the-art sentence embedding approach生成一个向量</li>
<li>将修改过的 hidden state和外部知识embedding都输入LSTM的gate中</li>
<li>argument role 分类，用最短路径算法找到依存树的一条最短路，把最短路输入tree-lstm，将root的hidden state和trigger、argument 的hidden state串联输入到softma算在role上分布</li>
</ol>
<h3 id="专有名词"><a href="#专有名词" class="headerlink" title="专有名词"></a>专有名词</h3><ol>
<li><strong>Tree-Structured LSTM模型</strong>：<a href="https://zhuanlan.zhihu.com/p/76671510">参考1</a>、<a href="https://zhuanlan.zhihu.com/p/46651378">参考2</a>、<a href="https://zhuanlan.zhihu.com/p/26261371">参考3</a></li>
<li>recursive matching criterion ——Overview of genia event taskin bionlp shared task 2011. Jin-Dong Kim</li>
</ol>
<h3 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h3><p><strong>生物医学领域</strong>的<strong>事件提取 Event  extraction</strong> 比一般新闻领域的事件提取更具挑战性，因为它需要<strong>更广泛的领域特定知识 domain-specific  knowledge  的获取和对复杂上下文的更深入的理解</strong>。为了更好地<strong>编码上下文信息和外部背景知识</strong>，我们提出了一种<strong>新颖的知识库（KB）-驱动的树结构长短期记忆网络（Tree-LSTM）框架</strong> novel  <strong>knowledge  base</strong>  (KB)-<strong>driven</strong>  tree-structured  long  short-term  memory  networks(<strong>Tree-LSTM</strong>)  framework,  ，整合了两种新类型的功能：</p>
<ol>
<li>依赖结构 dependency structures 以捕获广泛的上下文  wide contexts ；</li>
<li>通过实体链接 entity linking 从外部本体获得实体属性（类型和类别描述 types  and  category  descriptions ）。(远程监督)</li>
</ol>
<p>我们在  BioNLP shared task 和 Genia数据集 上评估了与我们的方法，并获得了最新的结果。此外，定量和定性 quantitative and qualitative 研究都证明了 Tree-LSTM 的发展以及生物医学事件提取的外部知识表示。</p>
<h3 id="1-Introduction"><a href="#1-Introduction" class="headerlink" title="1  Introduction"></a>1  Introduction</h3><p><strong>生物医学事件通常是指状态变化 change of status</strong>，尤其是蛋白质或基因状态变化。事件提取的目的是从生物医学文本中识别 triggers 及其 arguments，然后将事件类型分配给每个trigger，并将角色分配给每个参数。</p>
<p>图1所示的句子</p>
<p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/Biomedical Event Extraction Based on Knowledge-driven Tree-LSTM/image-20200723111259746.png" alt="image-20200723111259746" style="zoom:80%;" /></p>
<p>(这句生物方面的句子 trigger有两个type： gene expression和positive regulation，<strong><em>Tax</em></strong> 是 <strong>gene expression</strong>类型trigger 的 <strong>Theme</strong> argument，而在生物领域 gene expression既可以是trigger type也可以是positive regulation trigger type 的argument)</p>
<p>它包含了一个<strong>基因表达 gene expression</strong> 和一个 正向调节<strong>positive regulation</strong> 事件提及，两者都由 <strong><em>transduced</em></strong> 触发。<strong><em>Tax</em></strong> 是 <strong>gene expression</strong> 的 <strong>Theme</strong> argument。一个事件也可以作为另一个事件的 argument ， 导致嵌套结构——举例：the <strong>gene expression</strong> event <strong>triggered</strong> by <strong><em>transduced</em></strong> is also a <strong>Theme argument</strong> of the <strong>positive regulation</strong> event。</p>
<p>一个事件也可以用作另一个事件的参数，从而导致嵌套结构。例如，由转导触发的基因表达事件也是正调控事件的表象，如图1所示。</p>
<p>早期的事件提取研究依赖于<strong>核方法</strong>，例如支持向量机（SVM），这些方法使用手工特征。最近<strong>基于分布表示 distributional   representation   based</strong> 的方法（Rao等人，2017;Bj̈orne和Salakoski，2018）探索了仅需要分布式语义特征distributed  semantic  features 的深度神经网络。但是，与<strong>一般新闻领域中的事件提取不同，生物医学事件提取需要广泛获取领域特定的知识和对复杂上下文的深刻理解</strong>——$\color{red}{[}$  <em>例如，在 BioNLP shared task 2011的 Genia 事件提取中（Kim等，2011），大约80％的实体提及是基因，蛋白质和疾病的缩写 abbreviations of genes, proteins and diseases，而<strong>超过36％的事件 triggers 和 参数 arguments 之间有10个以上的单词，距离很长。</strong></em> $\color{red}{]}$</p>
<p>为了有效地从<strong>广泛的上下文中</strong>获取<strong>指示性信息indicative information</strong>，我们首先采用基于 <strong>Tree-LSTM 网络</strong>。<strong>依存句法树 Dependency tree structure</strong> 可以<strong>连接语义相关的概念semantically related concepts</strong>，从而显着<strong>缩短trigger 与its arguments之间的距离</strong>。例如，在下面的句子“ …，<em>which</em> <strong>binds</strong> <em>to the enhancer A located in the promoter of the mouse MHC class I gene</em> <strong>H-2Kb</strong>,，……”中，在确定 <strong>binds</strong> 的触发类型时，我们需要仔细选择其 <strong>上下文词contextual words</strong>，例如  <strong>H-2Kb</strong> ，表示 是 <strong>binds</strong>  的对象。但是，<strong>binds</strong> 和 <strong>H-2Kb</strong> 中间隔了16个words，<strong>这对链式的LSTM来说很难捕捉到这种长距离的依赖关系</strong>，而在<strong>依存树结构中，它们的距离显着缩短到7</strong>。  </p>
<p>此外，为了更好地捕获 特定领域的知识 domain-specific knowledge，我们还建议<strong>利用 leverage 外部知识库 external knowledge bases（KBs）</strong>来<strong>获取所有生物医学实体biomedical entities的属性 properties</strong>。KB的属性对于我们的模型更明确地学习<strong>模式</strong>非常有益。以图1中的 <strong><em>Tax</em></strong> 实体为例，它是一种通常参与<strong>基因转录正调控positive regulation of transcription</strong>的生物学过程的<strong>蛋白质</strong>，<strong>根据 基因本体论referred to Gene Ontology</strong>（Ashburner等，2000）——<strong>外部知识</strong>。此功能描述为确定<strong><em>transduced</em></strong> as <strong><em>positive regulation</em></strong>提供了关键线索。  (转导和转录)</p>
<p>因此，为了从外部知识库中获取此类知识，</p>
<ol>
<li>对于每个实体 entity，我们首先从其属性中学习 在 KB 层面上的 嵌入a KB concept embedding</li>
<li>然后通过 <strong>a gate function</strong> 自动将 <strong>embedding</strong>  <strong>并入</strong> 其 <strong>Tree-LSTM</strong> 的 <strong>hidden state</strong> </li>
</ol>
<h3 id="2-KB-driven-Tree-LSTM-for-Event-Extraction"><a href="#2-KB-driven-Tree-LSTM-for-Event-Extraction" class="headerlink" title="2  KB-driven Tree-LSTM for Event Extraction"></a>2  KB-driven Tree-LSTM for Event Extraction</h3><h4 id="2-2-Constructing-KB-Concept-Embedding"><a href="#2-2-Constructing-KB-Concept-Embedding" class="headerlink" title="2.2  Constructing KB Concept Embedding"></a>2.2  Constructing KB Concept Embedding</h4><p>对于<strong>生物医学事件提取</strong>，我们主要将 <strong><em>Gene Ontology</em></strong> 作为外部 <strong><em>KB</em></strong>，它提供了<strong>所有物种中每个基因和基因产物属性的详细描述</strong>。它包含两种类型的信息：</p>
<p>（1）<strong>the gene ontology（GO）</strong>定义了：</p>
<ol>
<li>所有基因功能 the gene functions，</li>
<li>这些基因功能之间的关系，relations  between  these  gene  functions</li>
<li>用于描述基因功能的概念 aspects used  to  describe  the  gene  function，包括分子功能 molecular  function, ，细胞成分 cellular  component  和生物过程 biological process.。</li>
</ol>
<p>（2）<strong>基因产物注释(GO  Anno)</strong>   提供所有与实体相关的属性 entity  related  attributes，比如：实体全名   full entity name； 实体类型  entity type ； 与之相关的基因功能  相关gene functions </p>
<p> <strong><em>Gene Ontology</em></strong> 能提供的信息示例：</p>
<p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/Biomedical Event Extraction Based on Knowledge-driven Tree-LSTM/image-20200723202324522.png" alt="image-20200723202324522"    /></p>
<p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/Biomedical Event Extraction Based on Knowledge-driven Tree-LSTM/image-20200723202245300.png" alt="image-20200723202245300" style="zoom:80%;"   /></p>
<p><strong>为了利用 <em>Gene Ontology</em>  的信息</strong>：</p>
<ol>
<li>apply  <strong>QuickGO  API</strong> ：将<strong>每个 entity mention</strong> 链接到 <strong>Gene Ontology</strong> link each entity mention to the Gene Ontology 并检索所有知识库 KB 注释。对于每个实体，我们仔细选择 <strong>两种</strong> 类型的<strong>对事件提取任务有利</strong>的<strong>属性</strong>： the <strong>entity type</strong> (e.g.,<strong>protein</strong> for <strong>tax</strong>) ；<strong>the gene ontology function</strong> it is related to (e.g.,<strong><em>positive regulation of transcription</em></strong> for <strong>tax</strong>)。 <strong>实体类型 entity type 可以促进显式模式学习 argument role 的 labeling任务</strong>，例如基因表达事件模式。<strong>基因本体功能 gene ontology function</strong> 可以提供<strong>隐含的线索</strong>来确定 <strong>trigger 类型</strong></li>
<li><strong>KB Concept Embedding： </strong>我们分配了一个<strong>词嵌入词 word  embedding</strong>，它在 <strong>PubMed 和 PMCtexts</strong> 上进行了<strong>预训练</strong>（Moen和Ananiadou，2013），以<strong>表示每种实体类型 entity  type</strong>。对于通常是一个<strong>长短语 long phrase,的每个 gene  ontology  function</strong>，我们使用 <strong>state-of-the-art 的 sentence embedding approach</strong>（Conneauet等人，2017）自动学习向量表示。然后，我们将这两种类型的 KB 属性表示形式连接起来，作为最终的 KB Concept Embedding。</li>
</ol>
<h4 id="2-3-Event-Trigger-Extraction"><a href="#2-3-Event-Trigger-Extraction" class="headerlink" title="2.3  Event Trigger Extraction"></a>2.3  Event Trigger Extraction</h4><p>KB concept embeddings 作为  domain-specific knowledge 放入  Tree-LSTM</p>
<p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/Biomedical Event Extraction Based on Knowledge-driven Tree-LSTM/image-20200724102218772.png" alt="image-20200724102218772" style="zoom:80%;" /></p>
<p>A 中展示了 Tree-LSTM 的一个 unit， 为了得到 input token $x_j$ 的 隐状态 hidden state $h_j$ ，这个 unit  通过深度优先遍历 计算包含了它的所有孩子节点的 hidden state $h_{i-1}, h_{i-2}$。</p>
<p>给了上图中的句子：</p>
<ol>
<li><p>perform  the  <strong>dependency  parsing</strong>  with  the  <strong>Stanford  dependency parser</strong> ，obtain  a  dependency tree structure</p>
</li>
<li><p>对于树结构中的 节点 j ，$C(j)$ 是节点 j 的所有 子节点集合， $\mu_k$ 是节点 k 的KB concept embedding，$h_k$ 是 节点k 的 hidden state。 当 节点 k not a biomedical entity 设置 $\mu_k$ 为0，$\color{red}{\tilde\mu_j  = \sum_{k\in C(j)}\mu_k          \tilde h_j  = \sum_{k\in C(j)}h_k}$   (和向量的感觉)</p>
</li>
<li><p>我们将 <strong>KB concept embedding 嵌入到 Tree-LSTM 的输入，遗忘和输出门</strong>中  to select useful KB information implicitly,：</p>
<p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/Biomedical Event Extraction Based on Knowledge-driven Tree-LSTM/image-20200724115046407.png" alt="image-20200724115046407" style="zoom:80%;" /></p>
<p><em>这里嵌入，相当于是原sentense中和 node j 有依赖关系的一个子node的 embedding代表的是node j在外部资料库中的资料，相当于原文句子中加上了一个括号，括号中对这个word做了解释</em></p>
</li>
<li><p>此外，<strong>引入knowledge specific output gate $g_j$ 显示地将 KB concept embedding 加到每个node  的 hidden state中</strong>，与Maet al(2018)不同，他仅考虑每个节点本身的knowledge concept embedding，我们<strong>使用整个子树(推测是自身加子节点？)的knowledge concept embedding的总和来代替</strong>：</p>
</li>
</ol>
<p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/Biomedical Event Extraction Based on Knowledge-driven Tree-LSTM/image-20200724141846765.png" alt="image-20200724141846765" style="zoom:80%;" /></p>
<ol>
<li>前面算了在隐式添加KB知识后的各种门的参数，现在得到 Cell 的 state 的值 以及 添加显式 KB 知识的 输出 $h_j$</li>
</ol>
<p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/Biomedical Event Extraction Based on Knowledge-driven Tree-LSTM/image-20200724142105412.png" alt="image-20200724142105412" style="zoom:80%;" /></p>
<p>以上所有 $W$ 参数都是需要学习的:</p>
<p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/Biomedical Event Extraction Based on Knowledge-driven Tree-LSTM/image-20200724142934532.png" alt="image-20200724142934532" style="zoom:80%;" /></p>
<h4 id="2-4-Event-Argument-Role-Labeling"><a href="#2-4-Event-Argument-Role-Labeling" class="headerlink" title="2.4  Event Argument Role Labeling"></a>2.4  Event Argument Role Labeling</h4><p>在检测到所有 candidate triggers 之后，我们<strong>进一步为每个 triggers 提取 arguments</strong> 。 <strong>Genia event extraction shared task 提供了所有实体提及 entity mentions 的注释</strong>。因此，对于每个trigger，我们<strong>使用在同一句子中出现的所有<em>实体提及作为 trigger 的候选参数</em></strong>，然后<strong>分配一个  argument role or None</strong> 。与trigger提取 trigger  extraction, 不同，我们<strong>在依赖关系树结构中使用最短依赖路径shortest  dependency path（SDP）代替表面上下文 surface contexts</strong> ，以更好地捕获 trigger 和每个参数 arguments 之间的依赖关系。</p>
<p>以下图的句子为例，给定一个 trigger : <strong><em>transcription</em></strong>和一个候选参数 argument:  <strong><em>OBF-1</em></strong></p>
<p>我们首先执行 <strong>dependency parsing: </strong> ，<strong>用 Dijkstra 算法</strong> 得到 transcription 和 OBF-1 间的的<strong>最短依赖路径</strong>，<strong>transcription → of → gene → OBF-1</strong>。我们使用与第2.3节中介绍的相同的  <strong><em>KB-driven Tree-LSTM</em></strong> 将<strong>每个节点编码为 hidden state 表示</strong>。我们使用根节点的隐藏状态 h0 作为整个依赖路径的整体矢量表示。最后，我们<strong>将 h0 和 hidden state of the trigger and argument 的串联结果 输入 另一个 softmax 中，predict the argument role</strong>。我们也通过 最小化负对数似然损失来优化模型。</p>
<p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/Biomedical Event Extraction Based on Knowledge-driven Tree-LSTM/image-20200724104152082.png" alt="image-20200724104152082"></p>
<h3 id="3-Experiment"><a href="#3-Experiment" class="headerlink" title="3  Experiment"></a>3  Experiment</h3><h4 id="3-1-Task-Description"><a href="#3-1-Task-Description" class="headerlink" title="3.1  Task Description"></a>3.1  Task Description</h4><p><strong>The Genia Event Extraction task</strong>  是 <strong>BioNLP  Shared  Task  series</strong> 中一个主任务</p>
<p>任务介绍：</p>
<div class="group-picture"><div class="group-picture-container"><div class="group-picture-row"><div class="group-picture-column" style="width: 100%;"><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/Biomedical Event Extraction Based on Knowledge-driven Tree-LSTM/image-20200724145319796.png" alt="image-20200724145319796" style="zoom:80%;" /></div></div><div class="group-picture-row"><div class="group-picture-column" style="width: 50%;"><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/Biomedical Event Extraction Based on Knowledge-driven Tree-LSTM/image-20200724145328270.png" alt="image-20200724145319796" style="zoom:80%;" /></div><div class="group-picture-column" style="width: 50%;"><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/Biomedical Event Extraction Based on Knowledge-driven Tree-LSTM/image-20200724145338765.png" alt="image-20200724145319796" style="zoom:80%;" /></div></div></div></div>
<h4 id="3-2-Experimental-Setup"><a href="#3-2-Experimental-Setup" class="headerlink" title="3.2  Experimental Setup"></a>3.2  Experimental Setup</h4><p>我们在Genia 2011数据集上应用了 KB-driven  Tree-LSTM  模型。Genia数据集中的实体是手动注释的，并作为输入的一部分给出。</p>
<p>我们使用Genia任务组织者提供的官方在线工具 在测试集上评估结果。 根据先前的研究（Bj̈orneandSalakoski，2011; Venugopal等人，2014; Raoet等人，2017; Bj̈orne和Salakoski，2018），<strong>we report scores obtained by the approximate span</strong>（允许触发跨度 trigger spans  与黄金跨度 gold spans 有一个word 的 不同）。由于我们只关注于匹配的核心参数 arguments ，因此我们使用递归匹配标准  recursive matching criterion 评估，不需要为其他事件引用的事件匹配其他参数（Kim等，2011 Overview of genia event taskin bionlp shared task 2011.）。</p>
<p><strong>word  embedding  pretrained  on PubMed  and  PMC  texts</strong></p>
<h4 id="3-3-Results-and-Error-Analysis"><a href="#3-3-Results-and-Error-Analysis" class="headerlink" title="3.3  Results and Error Analysis"></a>3.3  Results and Error Analysis</h4><ul>
<li><p>事先对比 <strong>comparison：</strong>  only using Tree-LSTM 和 a standard BiLSTM model 对比</p>
<p>结果： Tree-LSTM  outperforms  the  BiLSTM  baseline  which indicates the power of <strong>Tree-LSTM in dealing with long-distance dependency structure</strong> <strong>in biomedical literature</strong>.  </p>
</li>
<li><p><strong>incorporating external KB information: </strong> 2.12% F-score gain  comparing  to  Tree-LSTM</p>
</li>
<li><p><strong>event  extraction</strong>  results  from  the  <strong>BioNLP  shared  task  using the  same  corpus</strong>.</p>
<p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/Biomedical Event Extraction Based on Knowledge-driven Tree-LSTM/image-20200724151252001.png" alt="image-20200724151252001" style="zoom:80%;" /></p>
</li>
</ul>
<p>我们注意到我们的方法在 <strong>Simple</strong> event  types 上获得了高分，但在 <strong>Binding event</strong> 和 <strong>Regulation event types</strong>上获得了相对低的分。我们分析结果后发现<strong>Binding event</strong> 有 <strong>multiple arguments</strong></p>
<p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/Biomedical Event Extraction Based on Knowledge-driven Tree-LSTM/image-20200724151508868.png" alt="image-20200724151508868"></p>
<p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/Biomedical Event Extraction Based on Knowledge-driven Tree-LSTM/image-20200724151742589.png" alt="image-20200724151742589" style="zoom:80%;" /></p>
<div class="group-picture"><div class="group-picture-container"><div class="group-picture-row"><div class="group-picture-column" style="width: 50%;"><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/Biomedical Event Extraction Based on Knowledge-driven Tree-LSTM/image-20200724151753726.png" alt="image-20200724151753726" style="zoom:80%;" /></div><div class="group-picture-column" style="width: 50%;"><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/Biomedical Event Extraction Based on Knowledge-driven Tree-LSTM/image-20200724151815746.png" alt="image-20200724151815746" style="zoom:80%;" /></div></div></div></div>
<h4 id="3-4-Effect-of-KB-concepts"><a href="#3-4-Effect-of-KB-concepts" class="headerlink" title="3.4  Effect of KB concepts"></a>3.4  Effect of KB concepts</h4><p>·</p>
<h3 id="4-Related-Work"><a href="#4-Related-Work" class="headerlink" title="4  Related Work"></a>4  Related Work</h3><h3 id="5-Conclusions-and-Future-Work"><a href="#5-Conclusions-and-Future-Work" class="headerlink" title="5  Conclusions and Future Work"></a>5  Conclusions and Future Work</h3>]]></content>
      <categories>
        <category>Event Extraction</category>
        <category>Distant Supervision</category>
        <category>Biomedical</category>
      </categories>
      <tags>
        <tag>Tree-LSTM</tag>
        <tag>Biomedical</tag>
        <tag>Event Extraction</tag>
        <tag>distant supervision</tag>
        <tag>dependency parsing</tag>
        <tag>knowledge bases</tag>
      </tags>
  </entry>
  <entry>
    <title>Learning Named Entity Tagger using Domain-Specific Dictionary——AutoNER</title>
    <url>/blog/2020/07/18/Learning%20Named%20Entity%20Tagger%20using%20Domain-Specific%20Dictionary/</url>
    <content><![CDATA[<a id="more"></a>
<h3 id="『Learning-Named-Entity-Tagger-using-Domain-Specific-Dictionary——AutoNER』阅读笔记"><a href="#『Learning-Named-Entity-Tagger-using-Domain-Specific-Dictionary——AutoNER』阅读笔记" class="headerlink" title="『Learning Named Entity Tagger using Domain-Specific Dictionary——AutoNER』阅读笔记"></a>『Learning Named Entity Tagger using Domain-Specific Dictionary——AutoNER』阅读笔记</h3><p><a href="https://shangjingbo1226.github.io/AutoNER/">Project地址</a></p>
<ol>
<li><p>为解决标注数据不足问题，通常可以找相似领域的有标记数据做领域迁移、用领域词典做远程监督生成标记数据——本文讨论如何使用领域词表来生成标注数据。用词表直接匹配的问题是：</p>
<ul>
<li>词典无法覆盖所有实体</li>
<li>相同实体对应多个类别的情况(缺少上下文)，或是遇到词表中不存在的类别</li>
</ul>
<p>(在 entity span中做，包含共指消解吗)</p>
</li>
<li><p>先提出了解决传统 CRF 无法做多标签分类，现有模型无法解决entity 多label问题的Fuzzy-LSTM-CRF with Modified IOBES：</p>
</li>
</ol>
<p>   <img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/Learning Named Entity Tagger using Domain-Specific Dictionary/image-20200817090907042.png" alt="image-20200817090907042" style="zoom:80%;" /></p>
<p>   <img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/Learning Named Entity Tagger using Domain-Specific Dictionary/image-20200817093213501.png" alt="image-20200817093213501" style="zoom:80%;" /></p>
<ol>
<li><p>提出了一种 Tie or Break 的标注方案</p>
<ul>
<li>若当前词与上一个词在同一个实体内 Tie (O)</li>
<li>若其中一个词属于一个未知类型的实体短语，则该词的前后都是 Unknown (U)</li>
<li>其它情况都默认 Break (I)</li>
<li>某个实体类型未知 None (N)</li>
</ul>
</li>
<li><p>实体边界的远程监督信息和实体类别的远程监督信息是分开来计算的。这是为了能充分利用非领域词典——高质量短语词表中的词的边界信息。</p>
</li>
<li><p>模型使用的是一个用 Highway network 优化的 BiLSTM 来做 span prediction</p>
</li>
</ol>
<h3 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h3><p>深度神经模型的最新进展允许我们构建没有手工特征的可靠命名实体识别 reliable  named  entity  recognition（NER）系统。但是，此类方法需要大量的手动标记训练数据。已经有用远程监督（与外部词典一起）替换人类注释的方法，但是生成的嘈杂标签对学习有效的神经模型提出了重大挑战。在此，我们提出两种神经模型来适应字典中的嘈杂远程监督。首先，在traditional  sequence  labeling  framework下，我们提出了一种修正的模糊CRF层来处理tokens  with  multiple  possible  labels。在确定了远程监管中的嘈杂标签的性质之后，我们提出了神经模型AutoNER，具有新的$\text{Tie or Break}$ 方案。此外，我们还讨论了如何优化远程监管为更好的NER性能。在三个基准数据集上进行的大量实验表明，<strong>仅使用字典dictionary就可以实现AutoNER的最佳性能，而无需付出额外的人力</strong>，并且使用最新的监督基准可以提供具有竞争力的结果</p>
<h3 id="1-Introduction"><a href="#1-Introduction" class="headerlink" title="1    Introduction"></a>1    Introduction</h3><p>最近，在构建没有手工特征的可靠命名实体识别（NER）模型方面已进行了广泛的努力。然而，大多数现有方法需要大量的人工注释语句来训练监督模型（例如神经序列模型）（Liu等人，2018; Ma和Hovy，2016; Lample等人，2016; Finkel等人，2005）。这在特定的域下尤其具有挑战性，<strong>因为domain-expert annotation is expensive and/or slow to obtain</strong>。</p>
<p>为了减轻人类的努力，<strong>已应用了远程监管来自动生成标记数据</strong>，并已在各种自然语言处理任务中获得成功，包括短语挖掘（Shang等人，2018），实体识别entity recognition（Renet等人，2015; Fries等人）（2017； He，2017），方面项提取aspect term extraction（Giannakopoulos等，2017）和关系提取relation  extraction（Mintz等，2009）。同时，<strong>开放式知识库（或词典</strong>）正变得越来越流行，例如通用领域的 WikiData 和YAGO，以及生物医学领域的MeSH和CTD<strong>。这样的词典的存在使得有可能大规模生成 NER 的训练数据而无需额外的人工。</strong></p>
<p><strong>现有的远程监督的 NER 模型通常通过启发式匹配规则来解决实体文段检测entity  span  detection 问题</strong>，例如基于POS标签的正则表达式regular expression（Ren等，2015; Fries等，2017）和精确的字符串匹配exact  string  matching（Giannakopoulos等，2017; He，2017）。在这些模型中，每个不匹配的token 都将被标记为非实体non-entity。但是，<strong>由于大多数现有词典对实体的覆盖范围有限</strong>，<strong>因此简单地忽略不匹配的标记可能会引入假阴性的labels</strong>（例如，图1中的“前列腺素合成”）。因此，我们建<strong>议从语料库中提取高质量的out-of-dictionary phrases</strong>，并将其标记为具有特殊“未知”类型的潜在实体 potential  entities  with  a  special  “unknown”  type。<strong>而且，由于两个不同类型的实体可以在字典中共享相同的表面名称。，因此可以用多种类型标记每个实体范围every  entity  span  in  a sentence can be tagged with multiple types,</strong> 。为了解决这些挑战，我们用两个带有自定义标记方案 customized tagging schemes来对两个网络模型结构进行比较。</p>
<p>我们从在<strong>传统序列标签框架下调整模型 traditional sequence labeling framework</strong>开始。<strong>NER模型</strong>通常基于<strong>条件随机场(CRF)</strong>用$\text{IOB}$ 或者<strong>$\text{IOBES}$</strong> tagging scheme，但是，<strong>这种设计不能处理 multi-label  tokens.</strong> ($\color{red}{传统CRF不能解决多标签标注问题}$) 因此，我们将<strong>LSTM-CRF中的常规CRF层</strong>（Lample等，2016）<strong>自定义为Fuzzy CRF层</strong>，该层允许每个tokentoken 具有多个标签而不会牺牲计算效率。</p>
<p>为了<strong>适应远程监督生成的不完善标签imperfect labels</strong>，提出了一种<strong>新的预测模型</strong>prediction model。具体而言，我们建议预测两个相邻token是否在相同的实体提及中绑定 tied in thesame entity mention or not（即broken），而不是预测每个单个token的标签。 T<strong>he key motivation is that, even the boundaries of an entity  mention  are  mismatched  by  distant  supervision,  most  of  its  inner  ties  are  not  affected,  and thus more robust to noise</strong>。因此，我们设计了一种新的$\text{Tie or Break}$ 方案，以更好地利用嘈杂的远程监督。因此，我们设计neural architecture <strong>首先通过forms  all  possible  entity  spans  by  detecting such ties,</strong>，然后<strong>识别每个span的实体类型</strong>。$\text{Tie or Break}$ 方案和neural  architecture form我们的新模型<strong>AutoNER</strong>，在我们的实验中，它被证明比Fuzzy CRF模型更好地工作。</p>
<h4 id="贡献"><a href="#贡献" class="headerlink" title="贡献"></a>贡献</h4><ol>
<li><strong>AutoNER</strong>：$\text{Tie or Break}$ 方案和neural  architecture ，<strong>for the distantly supervised NER task</strong></li>
<li><strong>Fuzzy-LSTM-CRF  model：</strong> strong distantly supervised baseline</li>
<li><strong>refine distant supervision</strong> for better  NER  performance：incorporating high-quality phrases to reduce false-negative labels，进行了消融实验</li>
</ol>
<h3 id="2-Overview"><a href="#2-Overview" class="headerlink" title="2   Overview"></a>2   Overview</h3><p>我们的<strong>目标是使用且仅使用字典来学习命名实体</strong>。<em>每个字典条目均包含以下内容：1）实体的表面名称surface name，包括其<strong>规范名称</strong>和<strong>同义词的列表</strong>；2）实体类型。</em>考虑到词典的覆盖范围有限，我们<strong>通过<em>添加高质量的短语high-quality phrases作为类型未知的潜在实体</em>来扩展现有的词典</strong></p>
<p>给定一个原始的语料库raw  corpus 和字典，我们<strong>首先通过精确的字符串匹配 string  matching生成实体标签 entity   labels </strong>（包括未知的labels），其中冲突匹配通过最大化匹配标记的总数来解决 conflicted matches  are  resolved  by  maximizing  the  total number  of  matched  tokens（Etzioni等，2005； Hanisch等，2005；Lin et al。，2012; He，2017）</p>
<p>根据字典匹配dictionary matching的结果，每个tokentoken都属于以下三类categories之一：1）它属于具有一种或多种已知类型types的实体提及 entity mention；2）属于未知类型的实体提及；3）标记为非实体。</p>
<h3 id="3-Neural-Models"><a href="#3-Neural-Models" class="headerlink" title="3    Neural Models"></a>3    Neural Models</h3><h4 id="3-1-Fuzzy-LSTM-CRF-with-Modified-IOBES"><a href="#3-1-Fuzzy-LSTM-CRF-with-Modified-IOBES" class="headerlink" title="3.1    Fuzzy-LSTM-CRF with Modified IOBES"></a>3.1    Fuzzy-LSTM-CRF with Modified IOBES</h4><p><strong>under  the  traditional  sequence  labeling  framework</strong></p>
<p><strong>State-of-the-art  named  entity  taggers</strong>使用$\text{IOB}$ 或者<strong>$\text{IOBES}$</strong> 标注集，为sequence  labeling  framework（Ratinov和Roth，2009年），因此需要<strong>CRF层</strong>来捕获 输出标签 之间的依赖性<strong>dependency between labels</strong>。但是，原始方案和常规CRF层都不能处理多类型或未知类型的tokentokens。因此，我们相应地提出了<strong>改进的IOBES方案</strong>和<strong>Fuzzy CRF层</strong></p>
<h5 id="Modified-IOBES"><a href="#Modified-IOBES" class="headerlink" title="Modified  IOBES"></a>Modified  IOBES</h5><p>为了减少标注成本，文中采用Distant-supervision方法进行标注，即预先收集需要识别的实体词典库，采用词匹配的方法，在待处理文本中将词典中匹配到的实体标记出来。标注方法如下:</p>
<p>我们根据三个token类别定义标签:</p>
<ol>
<li>如果一个token标记为一种或多种类型，则这个token用所有这些types和$\{\text{I,B,E,S}\}$中的一种，according to its positions in the matched entity mention</li>
<li>类型未知的token，即词典中未出现的词，但属于词典中的高质量短语 high quality phrase。$\{\text{I,O,B,E,S}\}$所有五个都有可能，同时，分配了所有可用的类型。例如，如果只有两个可用types Chemical和Disease，则总共有2*4+1=9中labels ，但要注意 $\{\text{I,O,B,E,S}\}$的标注顺序，比如B的后面不能再跟一个B</li>
<li>对于标记为非实体的token，其标记$\{\text{O}\}$</li>
</ol>
<p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/Learning Named Entity Tagger using Domain-Specific Dictionary/image-20200722154950277.png" alt="image-20200722154950277" style="zoom:80%;" /></p>
<p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/Learning Named Entity Tagger using Domain-Specific Dictionary/image-20200722154937486.png" alt="image-20200722154937486" style="zoom:80%;" /></p>
<h5 id="Fuzzy-LSTM-CRF"><a href="#Fuzzy-LSTM-CRF" class="headerlink" title="Fuzzy-LSTM-CRF"></a>Fuzzy-LSTM-CRF</h5><p><strong>我们将LSTM-CRF模型（Lample等，2016）修改为Fuzzy-LSTM-CRF模型，以支持修改后的IOBES标签。</strong></p>
<p><strong>输入：</strong>一个word   sequence $X_1,X_2,…,X_n$</p>
<p>它首先通过单词级 word-level <strong>BiL-STM</strong>(forward and backward LSTMs)</p>
<p>在串联了两个方向输出的 representations后，该模型为每个输出标签做出独立的标记决策——输出分数$P_{i,y_j}$——the word $X_i$ being the label $y_j$</p>
<p>我们遵循先前的工作（Liu等人，2018; Maand Hovy，2016; Lample等人，2016）来定义预测序列的得分，预测序列 $y_1,y_2,…,y_n$ 的得分。其中，$\phi_{y_i,y_{i+1}}$ 是从label $y_i$ 到 label $y_{i+1}$ 的转移概率，$\phi$ 是$(k+2) \times (k+2)$ 大小的矩阵，Two additional labels <strong>start</strong> and <strong>end</strong> are used (only used in the CRF layer) to represent the beginning and end of a sequence, respectively</p>
<p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/Learning Named Entity Tagger using Domain-Specific Dictionary/image-20200722155717967.png" alt="image-20200722155717967" style="zoom:80%;" /></p>
<p>传统的CRF层将唯一有效标签序列 only valid label sequence的可能性最大化，只需要最大化一条标注路径的概率即可，但<strong>在修改的IOBES方案中，一个句子可能具有多个有效的标签序列</strong>，由于存在多条路径，那么我们就需要同时最大化所有路径的概率，因此，我们<strong>将常规CRF层扩展为模糊CRF模型fuzzy CRF model</strong>。</p>
<p>它枚举IOBES标签和所有匹配的实体类型，Objective是最大化所有可能的标签序列的总概率。优化目标：</p>
<p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/Learning Named Entity Tagger using Domain-Specific Dictionary/image-20200722160807135.png" alt="image-20200722160807135" style="zoom:80%;" /></p>
<p>在训练过程中，we maximize the log-likelihood function of上式</p>
<p>S:路径得分，计算方法与传统的CRF相同</p>
<p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/Learning Named Entity Tagger using Domain-Specific Dictionary/image-20200817090907042.png" alt="image-20200817090907042" style="zoom:80%;" /></p>
<p><strong>the  state-of-the-art  distantly  supervised phrase mining method ：AutoPhrase (Shanget  al.,  2018)</strong></p>
<p>预标注中提到的高质量短语（high quality phrases），我们通过AutoPhrase的方法从文本中挖掘（论文：<a href="https://link.zhihu.com/?target=https%3A//arxiv.org/pdf/1702.04457.pdf">Automated phrase mining from massive text corpora</a>，代码：<a href="https://link.zhihu.com/?target=https%3A//github.com/shangjingbo1226/AutoPhrase">AutoPhrase</a>）通过ulabeled语料和短语词典，设置适当的阈值，我们可以挖掘出高质量的短语。对于挖掘出来的短语，如果没在词典中出现过，我们就把它加入单独的一个“unknown”词典。</p>
<h4 id="3-2-AutoNER-with-“Tie-or-Break”"><a href="#3-2-AutoNER-with-“Tie-or-Break”" class="headerlink" title="3.2  AutoNER with “Tie or Break”"></a>3.2  AutoNER with “Tie or Break”</h4><p><strong>着眼于相邻tokens之间的联系ties</strong>，即它们 are <strong>tied in the same entity mentions</strong> or <strong>broken into two parts</strong>。因此，我们为此方案设计了一种新颖的神经模型</p>
<h5 id="“Tie-or-Break”-Tagging-Scheme"><a href="#“Tie-or-Break”-Tagging-Scheme" class="headerlink" title="“Tie  or  Break”  Tagging  Scheme"></a>“Tie  or  Break”  Tagging  Scheme</h5><p>具体来说，对于每两个相邻的tokens，它们之间的连接标记为</p>
<ul>
<li><strong>Tie：</strong>  当两个token与同一实体匹配时，属于同一个实体mention即前后两个token构成一个实体mention</li>
<li><strong>Unknown: </strong> if  at  least  one  of  the  tokens  belongs to  an  unknown-typed  high-quality  phrase;</li>
<li>否则为 <strong>Break</strong></li>
</ul>
<p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/Learning Named Entity Tagger using Domain-Specific Dictionary/image-20200722162125232.png" alt="image-20200722162125232" style="zoom:80%;" /></p>
<p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/Learning Named Entity Tagger using Domain-Specific Dictionary/image-20200722162152857.png" alt="image-20200722162152857" style="zoom:80%;" /></p>
<p><a href="https://zhuanlan.zhihu.com/p/63109138">reference</a></p>
<p>distant-supervision指出“ceramic unibody”匹配到了AspectTerm词典，8GB RAM是一个unknown高质量短语。因此ceramic unibody之间就被标记为Tie，短语8GB RAM的前后和中间就标记为Unknown。两个连续的Break标记之间的tokens就形成了一个span，每一个span都将被打上标签集中的所有匹配上的标签（词典匹配）。如果没有匹配到实体类型，我们就将其标记为None</p>
<h5 id="AutoNER"><a href="#AutoNER" class="headerlink" title="AutoNER"></a>AutoNER</h5><p>在<strong>“Tie  or  Break”  Tagging  Scheme</strong>中，entity  spans  and  entity  types  are  encoded  <strong>into  two folds</strong>.  Therefore, we <strong>separate the entity span detection and entity type prediction into two steps.</strong></p>
<p>实体span和type分两步编码，将实体span检测和实体类型预测分为两步执行。</p>
<ul>
<li><strong>entity span detection：</strong>在预测span序列时，只预测是tie还是break，在计算损失时，忽略真实为Unknown的token。而在计算type损失的时候，包括了序列中所有的token。构建一个二元分类器，输出类别为Break和Tie；如果预标注是Unknown类型则直接跳过。在第i个token和它的前一个token间，将BiLSTM 的输出串联得到一个新的<strong>特征向量 $u_i$ ，</strong>被输入一个 sigmoid 层，<strong>估计这里是一个 Break 的概率</strong></li>
</ul>
<p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/Learning Named Entity Tagger using Domain-Specific Dictionary/image-20200722163940010.png" alt="image-20200722163940010" style="zoom:80%;" /></p>
<ul>
<li><strong>entity types：</strong>  BiLSTM的输出将 re-aligned  以形成一个新的特征向量 $v_i$ , for $i th$ span candidate。 $v_i$ 会被输入softmax layer，输出 $v_i$ 在每个实体类别上的概率，估计entity type分布为    </li>
</ul>
<p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/Learning Named Entity Tagger using Domain-Specific Dictionary/image-20200722164540590.png" alt="image-20200722164540590" style="zoom:80%;" /></p>
<p>​    由于 one span 可以被标记为多种类型，我们将 possible set of types for $i th$ entity span candidate 的可能类型标记为 $L_i$，第i个span 的 候选实体类型集</p>
<p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/Learning Named Entity Tagger using Domain-Specific Dictionary/image-20200722170417291.png" alt="image-20200722170417291" style="zoom:80%;" /></p>
<p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/Learning Named Entity Tagger using Domain-Specific Dictionary/image-20200722170432069.png" alt="image-20200722170432069" style="zoom:80%;" /></p>
<p><strong><em>因为无明确的监督信息，因此采用，可能type集合内的概率分布作为监督信息，使得概率主要分配在可能的type集合上而不是整个type集中</em></strong></p>
<p>  AutoNER 没有 CRF 层和 Viterbi 解码，则在 inference 时更加高效</p>
<h4 id="3-3-Remarks-on-“Unknown”-Entities"><a href="#3-3-Remarks-on-“Unknown”-Entities" class="headerlink" title="3.3    Remarks on “Unknown” Entities"></a>3.3    Remarks on “Unknown” Entities</h4><p><strong>“Unknown”实体提及</strong> 不是其他类型的实体，而是<strong>我们对它们的边界不太确定和/或无法根据远程监管来识别其类型的tokenless confident about their boundaries and/or cannot identify their types based on the distant supervision。</strong>例如，在图1中，“prostaglandin synthesis”是“Unknown”的  token  span。 distant  supervision无法确定它是 Chemical 还是 Disease，是其他类型的实体，是两个单独的single-token  entities还是（部分）不是实体？因此，在<strong>FuzzyCRF模型</strong>中，我们为这些标记分配了所有可能的标签。</p>
<p>在我们的AutoNER模型中，这些<strong>“Unknown” positions</strong>具有undefined boundary and type losses，原因是：（1）它们使边界标签不清楚make the boundary labels unclear；以及（2）没有类型标签 type labels。由于边界的标签和实体类型都是unknown，在训练时它们被跳过。</p>
<h3 id="4-Distant-Supervision-Refinement"><a href="#4-Distant-Supervision-Refinement" class="headerlink" title="4    Distant Supervision Refinement"></a>4    Distant Supervision Refinement</h3><p>完善远程监管的两种技术，以更好地命名实体标签——都是说字典匹配</p>
<h4 id="4-1-Corpus-Aware-Dictionary-Tailoring词典裁剪"><a href="#4-1-Corpus-Aware-Dictionary-Tailoring词典裁剪" class="headerlink" title="4.1    Corpus-Aware Dictionary Tailoring词典裁剪"></a>4.1    Corpus-Aware Dictionary Tailoring词典裁剪</h4><p>在字典匹配中，盲目使用<strong>完整词典</strong>可能会<strong>引入假阳性标签</strong>，因为存在许多<strong>超出给定语料库范围的实体</strong>，但它们的<strong>别名可以匹配</strong>。</p>
<p>例如，当字典中具有不相关的字符名称“ Wednesday Addams” 及其别名“ Wednesday”时， many  Wednesday’s  will  be wrongly marked as persons<strong>。在理想情况下，词典应覆盖并且仅覆盖给定语料库中出现的实体</strong>，以确保在保持合理覆盖率的同时确保较高的精度。</p>
<p>作为近似，我们通过<strong>排除规范名称从未出现在给定语料库中的实体</strong>，将原始词典调整为<strong>与语料库相关的原始词典子集</strong>。背后的<strong>直觉intuition</strong>是，<strong>为了避免歧义</strong>，人们可能会<strong>至少提及一次实体的规范名称</strong>。(当说到某个实体对象时，人们至少会提起一次其正式的名称。因此，我们删除词典中那些正式名称从来没有出现过的实体（包括其别名），将能有效降低误召回。)例如，在生物医学领域，分别对BC5CDR和NCBI数据集中提到的实体的88.12％，95.07％成立，即<strong>至少提及一次canonical name</strong>。我们期望与在原始字典上训练的 NER model 相比，在这种调整后的字典的subset上训练的 NER model 具有更高的精度和合理的召回率</p>
<h4 id="4-2-Unknown-Typed-High-Quality-Phrases"><a href="#4-2-Unknown-Typed-High-Quality-Phrases" class="headerlink" title="4.2    Unknown-Typed High-Quality Phrases"></a>4.2    Unknown-Typed High-Quality Phrases</h4><p>远程监管的另一个问题是关于假阴性标签false-negative labels。当token span无法与词典中的任何entity surface names匹配时，由于词典的覆盖范围有限，仍然很难确定其为非实体（即否定标签）。具体来说，一些字典范围之外的高质量短语 high-quality phrases 也可能是潜在的实体。</p>
<p>We  utilize  the  state-of-the-art  <strong>distantly  supervised phrase mining method</strong>, <strong>AutoPhrase (Shanget  al.,  2018)。</strong> 以给定域中的<strong>语料库和字典</strong>作为输入，AutoPhrase<strong>仅需要未标记的文本和高质量短语的词典</strong>。我们通过设置<strong>阈值</strong>来获<strong>得高质量的多词和单词短语</strong> (e.g., 0.5and  0.9  respectively).   实际上，人们可以从<strong>同一域</strong>中<strong>查找更多未标记的文本</strong>（例如，PubMed论文和Amazon笔记本电脑评论），并使用<strong>相同的特定于域的词典</strong> 执行 NER 任务。在我们的实验中，对于生物医学领域，我们使用从整个 PubTator 数据库中 均匀采样的686,568篇PubMed论文（约4％）的标题和摘要作为训练语料库。对于笔记本电脑评论领域，我们使用Amazon笔记本电脑评论数据集3，该数据集旨在用于aspect-based的情感分析（Wang等人，2011年）</p>
<p>我们<strong>将 out-of-dictionary  phrases 视为具有“unknown”类型的潜在实体</strong>，并将其<strong>合并为新的字典条目</strong> incorporate them as new dictionary entries。此后，仅在此扩展词典中无法匹配的 token span 将被标记为   non-entity 。<strong>Being aware of these high-quality phrases,</strong> we expect the trained NER tagger should be more accurate。(通过这种方法，我们只需要准备大量的目标领域无标签语料和一个高质量的种子词典即可，通过调节posing threshods，我们很容易获取大量高质量的短语数据。我们对些短语数据进行筛选，除去那些在其它词典中出现过的短语，剩下的短语集构成“unknown”词典。在进行远程监督时，只有同时未被实体类型词典和unknown词典匹配的部分才被标记为non-entity。)</p>
<h3 id="5-Experiments"><a href="#5-Experiments" class="headerlink" title="5    Experiments"></a>5    Experiments</h3><h4 id="5-1-Experimental-Settings"><a href="#5-1-Experimental-Settings" class="headerlink" title="5.1    Experimental Settings"></a>5.1    Experimental Settings</h4><h4 id="Datasets——corpus"><a href="#Datasets——corpus" class="headerlink" title="Datasets——corpus"></a>Datasets——corpus</h4><p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/Learning Named Entity Tagger using Domain-Specific Dictionary/image-20200722232107701.png" alt="image-20200722232107701" style="zoom:80%;" /><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/Learning Named Entity Tagger using Domain-Specific Dictionary/image-20200722232117169.png" alt="image-20200722232117169" style="zoom:100%;" /></p>
<p>前两个数据集已经划分为三个子集：训练集，开发集和测试集。对于 LaptopReview 数据集，我们遵循（Gian-nakopoulos等人，2017），并从训练集中随机选择20％作为开发集。 Only raw texts are provided as the input of distantly supervised models，而gold training set 用于监督模型.</p>
<h4 id="Domain-Specific-Dictionary"><a href="#Domain-Specific-Dictionary" class="headerlink" title="Domain-Specific  Dictionary"></a>Domain-Specific  Dictionary</h4><p>对于生物医学数据集，该词典是 <strong>MeSH 数据库</strong><a href="https://www.nlm.nih.gov/mesh/download_mesh.html">MeSH</a>和 <strong>CTD Chemical and  Disease<a href="http://ctdbase.org/downloads/">CTD</a> 词汇集</strong>的组合。该词典包含322,882个 Chemical and Disease entity surfaces。</p>
<p>For the <strong>laptop review dataset</strong><a href="https://www.computerhope.com/jargon.htm">laptop review</a>,  the dictionary has 13,457 computer terms crawled from a public website</p>
<h4 id="Metric"><a href="#Metric" class="headerlink" title="Metric"></a>Metric</h4><p><strong>micro-averaged F1 score</strong></p>
<h4 id="Parameters-and-Model-Training"><a href="#Parameters-and-Model-Training" class="headerlink" title="Parameters and Model Training"></a>Parameters and Model Training</h4><p>基于开发集中的分析，我们进行了带有动量的随机梯度下降的优化stochastic gradient descent  with  momentum。我们将批量大小和动量设置为10和0.9。最初将学习率设置为0.05，如果最近5轮中没有更好的发展F1，则学习率将降低40％。在模型中应用了ratio 为 0.5 的 Dropout 。为了获得更好的稳定性，我们使用 5.0 的梯度剪切 gradient clipping 。此外，我们在开发集中采用了early stopping </p>
<h4 id="Pre-trained-Word-Embeddings"><a href="#Pre-trained-Word-Embeddings" class="headerlink" title="Pre-trained   Word   Embeddings"></a>Pre-trained   Word   Embeddings</h4><p>对于生物医学数据集，我们使用来自（Pyysalo等人，2013）的预训练的200维单词向量<a href="http://bio.nlplab.org/">biomedical datasets</a>，这些向量在整个 PubMed abstracts，PubMed Central（PMC）的所有全文文章和英语 Wikipedia 上进行了训练。</p>
<p>对于笔记本电脑评论数据集，我们使用 GloVe 100维度的预训练词向量<a href="https://nlp.stanford.edu/projects/glove/">laptop  review  datase</a>，这些向量在 Wikipedi  和 GigaWord 上进行了训练</p>
<h4 id="5-2-Compared-Methods"><a href="#5-2-Compared-Methods" class="headerlink" title="5.2    Compared Methods"></a>5.2    Compared Methods</h4><ul>
<li><strong>Dictionary Match:</strong> 我们将其直接应用于测试集，以获得与字典中的表面名称完全相同的实体提及，通过多数投票分配类型，通过与之比较，我们可以检查神经模型相对于远程监督本身的改进</li>
<li><strong>SwellShark：</strong> 在生物医学领域，可以说是最佳的远程监督模型，尤其是在 BC5CDR 和 NCBI-Disease 数据集上（Fries等人，2017）。它不需要人工注释的数据，但是，它需要额外的 expert effort 来进行 entity span detection，包括构建POS标签，设计有效的正则表达式以及针对特殊情况进行手动调整</li>
<li><strong>Distant-LSTM-CRF:</strong> 在没有注释的训练数据的情况下，使用远程监督 LSTM-CRF model ，在 LaptopReview 数据集上获得了最佳性能</li>
<li><strong>Supervised   benchmarks: </strong> </li>
</ul>
<p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/Learning Named Entity Tagger using Domain-Specific Dictionary/image-20200723000830820.png" alt="image-20200723000830820" style="zoom:70%;" /></p>
<h4 id="5-4-Distant-Supervision-Explorations"><a href="#5-4-Distant-Supervision-Explorations" class="headerlink" title="5.4    Distant Supervision Explorations"></a>5.4    Distant Supervision Explorations</h4><p><strong>消融实验</strong></p>
<p>我们研究了我们在本节中提出的两种技术的有效性。通过消融实验。如表4所示，<strong>使用定制词典总是比使用原始词典获得更好的F1分数。</strong>通过使用量身定制的词典，AutoNER模型的精度将更高，而召回率将保持不变。例如，在NCBI-Disease数据集上，它可以将召回损失从63.54％从53.14％大幅提高到77.30％％to58.54％。此外，<strong>在字典中合并未知类型的高质量短语会显着提高AutoNER模型的每个分数</strong>，尤其是召回率。这些结果完全符合我们的预期</p>
<p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/Learning Named Entity Tagger using Domain-Specific Dictionary/image-20200723001042233.png" alt="image-20200723001042233" style="zoom:80%;" /></p>
<h4 id="5-5-TestF1Scores-vs-Size-of-Raw-Corpus"><a href="#5-5-TestF1Scores-vs-Size-of-Raw-Corpus" class="headerlink" title="5.5    TestF1Scores vs. Size of Raw Corpus"></a>5.5    TestF1Scores vs. Size of Raw Corpus</h4><p>此外，当我们<strong>有不同大小的远程监督文本时</strong>，我们探索了 <strong>test F1 scores 的变化</strong>。我们从给定的原始语料中均匀地抽取句子样本，然后评估在所选句子上训练的 AutoNER 模型。</p>
<p>我们还研究了提供黄金训练集时将发生的情况。曲线可在图3中找到。<strong>X轴是distantly  supervised  training  sentences 的数量</strong>，<strong>Y轴是测试集上的F1分数</strong>。</p>
<p>仅使用远程监督时，一开始就可以观察到testF1分数的显着增长趋势，但是后来，随着越来越多的原始文本，增长率降低了。</p>
<p>当 gold training set is available,，远程监督仍然对AutoNER有所帮助。从一开始，AutoNER的性能就不如监督基准测试。后来，在有足够 distantly supervised  sentences，AutoNER 的表现优于监督基准。我们认为有两个可能的原因：<strong>（1）对那些可匹配的实体提及，远程监管更重视。（2）黄金注释可能会错过一些不错但可匹配的实体提及</strong>。这些可以指导AutoNER训练到更通用的模型，并因此具有更高的testF1分数。</p>
<h3 id="6-Related-Work"><a href="#6-Related-Work" class="headerlink" title="6    Related Work"></a>6    Related Work</h3><h3 id="7-Conclusion-and-Future-Work"><a href="#7-Conclusion-and-Future-Work" class="headerlink" title="7    Conclusion and Future Work"></a>7    Conclusion and Future Work</h3><p><a href="https://zhuanlan.zhihu.com/p/135453456">reference1—命名实体识别 NER 论文综述</a></p>
<p><a href="https://zhuanlan.zhihu.com/p/63109138">reference2——Named Entity Recognition</a></p>
]]></content>
      <categories>
        <category>Training Data Generation</category>
      </categories>
      <tags>
        <tag>AutoNER</tag>
        <tag>pos schema</tag>
        <tag>entity span</tag>
        <tag>domain-specific dictionary</tag>
      </tags>
  </entry>
  <entry>
    <title>Learning the Structure of Generative Models without Labeled Data</title>
    <url>/blog/2020/07/17/Learning%20the%20Structure%20of%20Generative%20Models%20without%20Labeled%20Data/</url>
    <content><![CDATA[<a id="more"></a>
<h3 id="『Learning-the-Structure-of-Generative-Models-without-Labeled-Data』阅读笔记"><a href="#『Learning-the-Structure-of-Generative-Models-without-Labeled-Data』阅读笔记" class="headerlink" title="『Learning the Structure of Generative Models without Labeled Data』阅读笔记"></a>『Learning the Structure of Generative Models without Labeled Data』阅读笔记</h3><p><strong>优化一个不同的目标函数</strong>，可以扩大对许多潜在不相关依赖项的学习：</p>
<p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/Learning the Structure of Generative Models without Labeled Data/image-20200815233733051.png" alt="image-20200815233733051" style="zoom:80%;" /></p>
<p><a href="https://blog.csdn.net/m0_37477175/article/details/89205840">Inferring Generative Model Structure with Static Analysis-2017【论文理解】</a></p>
<p>真实的标签true label在生成模型中是一个<strong>隐变量</strong>。</p>
<p>对于一个数据点 $x_i$，它的真实标签为 $y_i\in-1,1$，有 n 个标记函数LFs，然后对 $x_i$  就可以得到n个预测结果组成的标注向量 $\Lambda_i=\Lambda_{i1},…\Lambda_{in}$ 从n个结果中我们可以通过生成模型得到一个最终的结果 $\Lambda_i\in-1,0,1$ 三个值分别对应false，不确定，true。</p>
<p>目标是估计一个概率模型,生成labeling-function输出标注矩阵 $\Lambda \in {-1,0,1}^{m\times n}$。</p>
<p>假设<em>n</em>个结果 $\Lambda_i=\Lambda_{i1},…\Lambda_{in}$ 都条件独立于 $y_i$  ，$\Lambda_i$ 与 $y_i$ 之间就存在n个准确性依赖关系，那么估计每个结果相对于真实标签的一个准确率<img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/Learning the Structure of Generative Models without Labeled Data/image-20200815152622124.png" alt="image-20200815152622124" style="zoom:80%;" />，acc因子函数建模每个标签函数 $\lambda_j$ 的准确性。</p>
<p>将此结构称为条件独立模型，并将其指定为：(类似于用内积表示相似度，所以设计成{-1,0,1})</p>
<p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/Learning the Structure of Generative Models without Labeled Data/20190413211132756.png" alt="img" style="zoom: 40%;" /></p>
<p>通过最小化的边际负对数似然估计参数，参数表示每个标记函数对数据 $y_i$ 的标注的权重(信心)，</p>
<h3 id="专有名词"><a href="#专有名词" class="headerlink" title="专有名词"></a>专有名词</h3><ol>
<li>监督的准确性</li>
<li>marginal pseudolikelihood</li>
<li>sub-linearly </li>
<li>EM算法</li>
<li>log marginal pseudolikelihood </li>
<li>在线截断梯度法online truncated gradient method——<a href="https://zr9558.com/2016/01/12/truncated-gradient/">https://zr9558.com/2016/01/12/truncated-gradient/</a></li>
<li><a href="https://zh.wikipedia.org/wiki/易辛模型">易辛模型</a></li>
</ol>
<h3 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h3><p><strong>生成模型的依赖关系结构 generative model’s dependency structure直接影响估计标签的质量</strong>，但是自动选择一个结构在没有标签数据情况下是一个明显的挑战。</p>
<p>我们提出了一种结构估计方法，可以最大程度地提高观测数据的L1正则的边际伪似然概率。</p>
<p>我们的分析表明， for a broad class of models，识别真实结构true structure所需的未标记数据量随着可能的依赖dependencies的数量按次线性缩放 scales        sub-linearly 。</p>
<h3 id="1-Introduction"><a href="#1-Introduction" class="headerlink" title="1. Introduction"></a>1. Introduction</h3><p>人们越来越有兴趣使用生成模型从弱监督源中综合训练数据，such as heuristics, knowledge bases, and weak classifiers trained directly on noisy sources。这种方法不是将训练标签视为金标准输入，而是将训练集的创建建模为一个过程，以便大规模生成训练标签。数据点的真实类标签被建模为隐变量，该变量生成可观察到的有噪声的标签。将生成模型的参数拟合到未标记的数据后，得到该隐变量的分布，从分布中推断出真实标签。</p>
<p>此类生成模型的<strong>此类生成模型的结构直接影响推断的真实标签</strong>，先前的工作假设该结构是用户指定的（Alfonseca等，2012； Takamatsu等，2012； Roth＆Klakow，2013b； Ratner等，2016）</p>
<p>一种想法是假设在给定 latent class label，supervision sources是条件独立的。但是，<strong>统计上的依赖关系在实践中很常见</strong>，不考虑它们会导致对监督准确性 <strong>accuracy of the supervision的误判。</strong>我们一般不能依靠用户来指定生成模型的结构，因为<strong>对某些数据集进行监督的启发式方法和分类器可能是独立的，而对其他数据集则不是</strong>。因此，我<strong>们寻求一种仅从弱监督源自动学习生成模型的结构的有效方法</strong></p>
<p>在有监督的环境中对结构学习进行了很好的研究 (e.g.,Meinshausen &amp; B ̈uhlmann,2006;Zhao &amp; Yu,2006;Ravikumar et al.,2010, see also Section6), 因为<strong>真正的类别标签是潜在的</strong>，所以要获得用于弱监督的生成模型的结构具有挑战性<strong>。尽管我们可以使用随机梯度下降和吉布斯采样来学习给定结构的生成模型参数，但是对所有可能的依赖关系建模并不能作为模型选择的替代方法(对所有可能的依赖关系建模成为性能瓶颈)</strong>。例如，为一个规模最大的100个弱监督源的问题估计所有可能的相关性需要40分钟。（为进行比较，我们提出的方法在15秒内解决了相同的问题。）随着用户发展其监督启发式方法，重新运行参数学习以识别依赖项成为一个瓶颈。</p>
<p>我们提出<strong>一种估计器estimator，以在不使用任何标记训练数据的情况下学习生成模型的依赖结构</strong> learn the dependency structureof a generative model。我们的方法独立地 maximizes 每个监管源的输出的“ <strong>L1-正则化边际伪似然</strong>”，<strong>选择了那些非零权重的依赖</strong>。估算器类似于逻辑回归的最大似然法——<strong>对数最大似然</strong>，除了我们将潜在类标签的不确定性边缘化了。由于伪似然概率是一个自由变量的函数，并且对另一个变量进行了边际化，因此我们可以精确计算边际伪似然的梯度，<strong>从而避免了像最大似然估计那样使用Gibbs采样逼近梯度的需要</strong>。</p>
<p>我们的分析表明，对于一类广泛的模型，识别真实结构所需的数据量以亚线性方式按比例缩小。从直觉上讲，这是基于这样的事实，即当有足够多的优于随机性的监督资源可用时，就可以学习生成模型的参数。与随机猜测相比，有了足够的信号来更好地估计潜在类别标签 latent class labels ，可以对那些估计进行完善，直到确定模型为止</p>
<h3 id="2-Background"><a href="#2-Background" class="headerlink" title="2. Background"></a>2. Background</h3><p>在数据编程中，弱监督源被编码为labeling functions，即标记数据点（或弃权）的启发式方法。生成概率模型适合于估计标记函数的准确性以及任何用户的输出间用户指定的统计依赖性的强度。在此模型中，数据点的真实类标签是一个潜在变量，它会生成标签函数输出。拟合生成模型的参数后，可以估计潜在的真实标签上的分布，并通过将与该分布有关的预期损失最小化来用于训练判别模型。</p>
<p>我们首先通过为每个指定的数据点 $x_i$ a latent random variable $y_i\in\{-1,1\}$ 作为它的true label。例如，在<strong>信息提取</strong>任务中， $x_i$ 可能是一段文字，那么 $ y_i$ 可以代表是否提及某家公司（实体标签）。或者，$x_i$ 可能是一个更复杂的结构，例如文档中的规范标识符的元组 a tuple of canonical identifiers 和相关提及，然后 $ y_i$ 可以表示文档中是否表达了对该元组的感兴趣关系（<strong>关系提取</strong></p>
<p>我们没法直接获得 $ y_i$ （即使在训练时），但是我们有用户提供的n个标注函数$\lambda_1,\lambda_2,…\lambda_n$，可以将其应用于 $x_i$ 以产生输出$\Lambda_1,\Lambda_2,…\Lambda_n$。例如，对于上面提到的company-tagging task ，标注函数可以将常规表达式 <strong>.+\sInc </strong> 应用于文本范围，并返回是否匹配。每个$ \Lambda_{i,j}\in\{-1,0,1\}$，分别对应于false，abstain和true。扩展到多类情况很简单。</p>
<p>Our <strong>goal</strong> is to <strong>estimate a probabilistic model that generates the labeling-function outputs</strong> $\Lambda_{i,j}\in\{-1,0,1\}^{m\times n}$ 。一个常见的假设是：在给定真实标签下，输出是条件独立的，并且$\Lambda$和 $y$ 之间的关系由n个accuracy dependencies来控制</p>
<script type="math/tex; mode=display">\phi_j^{Acc}(\Lambda_i,y_i):=y_i\Lambda_{ij}</script><p>使用一个参数<script type="math/tex">\phi_j^{Acc}</script>建模每个标注函数 $\lambda_i$ 的准确性，我们将此结构称为<strong>条件独立模型</strong>，并将其指定为：</p>
<script type="math/tex; mode=display">p_{\theta}(\Lambda,Y)\propto exp (\sum_{i=1}^m\sum_{j=1}^n\theta_j^{Acc}\phi_j^{Acc}(\Lambda_i,y_i))</script><script type="math/tex; mode=display">Y:=y_1,...,y_m</script><p>我们估计参数 $\theta$ by minimizing <strong>the negative log marginal likelihood</strong> $p_{\theta}(\bar\Lambda)$, $\bar\Lambda$是观察到的标记函数输出矩阵。</p>
<script type="math/tex; mode=display">\underset{\theta} {\operatorname{arg\ min}} \ \ \ -log\sum_Yp_{\theta}(\bar\Lambda,Y)</script><p><strong>使用随机梯度下降法可以直接优化，上式对$\theta_j^{Acc}$ 的梯度</strong>是联合分布 $p_{\theta}$ 的相应充分统计量和在观察矩阵$\bar\Lambda$的条件下的同个分布即$p_{\theta|\bar\Lambda}$ </p>
<p>$\sum_{i=1}^m(E_{\Lambda,Y \text{~}\theta}[\phi_j^{Acc}(\Lambda_i,y_i)]- E_{Y\text{~}\bar\Lambda|\theta}[\phi_j^{Acc}(\bar\Lambda_i,y_i)])$</p>
<p>在实践中，我们可以交错采样interleave samples以非常紧密地估计梯度和梯度步长，在对每个变量$\Lambda_{ij}$或者$y_i$进行一次采样后，走一个梯度步长，similarly to contrastive divergence (Hinton,2002).(可以不用蒙特卡洛采样，吉布斯采样——<a href="https://mlnote.com/2014/05/11/Training-Products-of-Experts-by-Minimizing-Contrastive-Divergence/"></a>)</p>
<p>条件独立模型是一种常见的假设，当前使用更复杂的生成模型需要用户指定其结构。在本文的其余部分，我们将解决从观察$\bar\Lambda$自动识别依赖结构dependency structure的问题，而无需观察$Y$</p>
<h3 id="3-Structure-Learning-without-Labels"><a href="#3-Structure-Learning-without-Labels" class="headerlink" title="3. Structure Learning without Labels"></a>3. Structure Learning without Labels</h3><p>统计依赖性在弱的监督源中自然而然地出现。在数据编程中，用户通常会编写带有直接相关输出的labeling functions ，甚至是故意设计的，narrow的，更精确的启发式方法来增强其它的labeling functions。为了解决这个问题，我们将<strong>条件独立模型</strong>泛化到为具有附加依赖性的因子图factor graph ，包括将<strong>每个数据点$x_i$和 label $y_i$的多个标记函数输出multiple labeling function outputs连接起来的高阶因子</strong>。我们将通用模型指定为</p>
<script type="math/tex; mode=display">p_{\theta}(\Lambda,Y)\propto exp (\sum_{i=1}^m\sum_{t\in T}\sum_{t\in S_t}\theta_s^{t}\phi_s^{t}(\Lambda_i,y_i))</script><p>这里$T$是感兴趣的依赖项类型的集合，$S_t$ 是index tuples的集合，指出参与每个类型依赖项dependency of type $t\in T$的 labeling function。</p>
<p>标准的依赖类型 <strong><em>correlation</em></strong> 定义为：</p>
<script type="math/tex; mode=display">\phi_{jk}^{Cor}(\Lambda_i,y_i):=1\{\Lambda_{ij}=\Lambda_{ik}\}</script><p>我们将这种依赖关系称为标记函数之间的成对依赖关系，因为它们仅依赖于两个标记函数输出。我们还可以考虑涉及更多变量的高阶相依性，例如依赖类型 <strong><em>conjunction</em></strong>:</p>
<script type="math/tex; mode=display">\phi_{jk}^{And}(\Lambda_i,y_i):=1\{\Lambda_{ij}=y_i\and\Lambda_{ik}=y_i\}</script><p>估计the structure of the distribution $p_{\theta}(\Lambda,Y)$具有挑战性，因为$Y$是latent; we never observe its value,even during training。因此，我们必须和边际概率marginal likelihood $p_{\theta}(\Lambda)$。jointly学习生成模型的参数需要Gibbs采样来估计梯度。由于可能的dependencies的数量增加至少是标注函数数量的平方次，this heavyweight approach to learning does not scale （请参见第5.2节）</p>
<h4 id="3-1-Learning-Objective"><a href="#3-1-Learning-Objective" class="headerlink" title="3.1. Learning Objective"></a>3.1. Learning Objective</h4><p>我们可以扩大对许多潜在不相关依赖项的学习，通过优化另一个目标：<strong>the log marginal pseudolikelihood of the outputs of a single labeling function $\lambda_i$, 以其他的 labeling function输出作为条件 conditioned on $\lambda_{\setminus i}$, 用L1正则引入稀疏性，引入了特征选择</strong></p>
<p>(边际概率，EM算法)</p>
<p><strong><em>Objective:</em></strong></p>
<script type="math/tex; mode=display">\begin{equation}\underset{\theta} {\operatorname{arg\ min}}\quad-\log p_{\theta}(\bar\Lambda_j\mid\bar\Lambda_{\setminus j})+\varepsilon\lVert\theta\rVert_1\\=\underset{\theta} {\operatorname{arg\min}}\quad\sum_{i=1}^m\log\sum_{y_i}p_{\theta}(\bar\Lambda_{ij},y_i\mid\bar\Lambda_{i\setminus j})+\varepsilon\lVert\theta\rVert_1\end{equation}</script><p>$\varepsilon &gt;0$ 是超参</p>
<p>通过取这个条件概率 $\log\sum_{y_i}p_{\theta}(\bar\Lambda_{ij},y_i\mid\bar\Lambda_{i\setminus j})$ ,我们确保可以在多项式时间内根据标记函数，数据点和possible dependencies;的的数量来计算梯度；无需任何sampling or variational approximations。</p>
<p>对数边际伪似然的梯度是两个期望之间的差：以所有标记函数(除了$\lambda_j$)为条件的充分统计量和以所有标记函数为条件的充分统计量：</p>
<p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/Learning the Structure of Generative Models without Labeled Data/image-20200721115548159.png" alt="image-20200721115548159" style="zoom:80%;" /></p>
<h4 id="3-2-Implementation"><a href="#3-2-Implementation" class="headerlink" title="3.2. Implementation"></a>3.2. Implementation</h4><p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/Learning the Structure of Generative Models without Labeled Data/image-20200721115735284.png" alt="image-20200721115735284" style="zoom:80%;" /></p>
<p>这是一种随机梯度下降（SGD）例程。在每次下降中，为单个数据点估计梯度，可以通过封闭式算出。使用SGD有两个优点：首先，它仅需要一阶梯度信息，诸如内点法interior-point（Koh et al。，2007）之类的用于1-正则回归的其他方法通常需要计算二阶信息。其次，观察结果$\bar\Lambda$可以逐步进行处理，由于数据编程对未标记的数据（通常是大量的）进行操作，因此 scalability 泛化能力至关重要。为了实现SGD中的1正则化，我们使用了在线截断梯度法online truncated gradient method（Langford等，2009)</p>
<p>在实践中，我们发现唯一需要调整的参数是$\varepsilon$，它控制the threshold and regularization strength. 较高的值会在所选结构中引起更大的稀疏性。对于其他参数，我们在所有实验中都使用相同的值：步长$\eta$=$m^{-1}$，epoch count T = 10，truncation frequency 窗口大小K = 10。</p>
<h3 id="4-Analysis"><a href="#4-Analysis" class="headerlink" title="4. Analysis"></a>4. Analysis</h3><p>我们保证Algorithm1成功恢复确切的依赖结构的可能性。我们<strong>首先为所有可能的依赖关系（包括成对依赖关系和高阶依赖关系）提供一般恢复保证</strong>。但是，在许多情况下，不必对标注函数的行为进行较高的依赖性的建模higher-order dependencies are not necessary to model the behavior of the labeling functions。实际上，正如我们在第5.3节中所演示的那样，在许多有用的模型中，只有准确性相关性和成对相关性accuracy dependencies and pairwise correlation。在这种情况下，作为一般结果的推论，我们证明所需样本的数量在可能的依存关系数量上是次线性的，更具体地说是$O(nlogn)$</p>
<p>前面针对监督案例的分析不能直接迁移到非监督情况，因为不再是凸问题。例如，analysis of an analogous method相同方法 for supervised Ising models（Ravikumar等，2010）依赖于拉格朗日对偶性和紧密对偶性缺口tight duality gap，这对于我们的估计问题不成立。取而代之的是，我们推断出参数空间的一个区域，在该区域中，我们可以估计出足够好，从而最终可以得到the true model。</p>
<p>现在我们陈述the conditions necessary for our guarantees。首先是两个必需的standard conditions 来保证可以用任意数量的样本恢复依赖结构：</p>
<p>一，我们必须有一些可行的参数集合$\Theta\subset R^M$。</p>
<p>二，真正的model在 $\Theta$ 里</p>
<p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/Learning the Structure of Generative Models without Labeled Data/image-20200721143206261.png" alt="image-20200721143206261" style="zoom:80%;" /></p>
<p>这意味着对于每个标记函数，使用它将比不使用时更好地估计依赖项。它类似于对数据编程中的参数学习进行分析的假设</p>
<div class="group-picture"><div class="group-picture-container"><div class="group-picture-row"><div class="group-picture-column" style="width: 50%;"><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/Learning the Structure of Generative Models without Labeled Data/image-20200721145711522.png" alt="image-20200721145711522" style="zoom:80%;" /></div><div class="group-picture-column" style="width: 50%;"><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/Learning the Structure of Generative Models without Labeled Data/image-20200721145828757.png" alt="image-20200721145828757" style="zoom:80%;" /></div></div></div></div>
<h3 id="5-Experiments"><a href="#5-Experiments" class="headerlink" title="5. Experiments"></a>5. Experiments</h3><p>我们将我们的方法作为开源框架Snorkel1的一部分进行实施，并通过三种方式对其进行评估。首先，我们使用合成数据来测量返回精确相关结构的概率如何受到问题参数的影响，从而确认我们的分析表明其样本复杂度在可能的依赖项数量上是次线性的。事实上，我们发现在实践中，样本的复杂度低于理论上的保证率，与在完全监督的结构学习中所看到的率相匹配。其次，我们将我们的方法与通过参数学习估计结构的所有可能依赖项进行了比较。我们的方法更快，更准确，平均选择了1/4倍的外部相关性。第三，我们将我们的方法应用于使用数据编程构建的实际应用程序中，例如从PubMed期刊摘要和硬件规格表中提取信息。在这些应用程序中，用户未指定标注函数之间的任何依赖关系，但这些依赖性自然产生，例如由于显式组成，放松或加强了标签功能启发式算法 explicit composing, relaxing, or tightening of labeling function heuristics；相关的远程监管资源；或多个并发的开发人员编写标注函数。我们表明，学习这种结构比条件独立模型可以提高性能，平均提高1.5 F1点。</p>
<h4 id="5-1-Sample-Complexity"><a href="#5-1-Sample-Complexity" class="headerlink" title="5.1. Sample Complexity"></a>5.1. Sample Complexity</h4><p>我们测试了Algorithm1返回正确的相关结构的概率如何取决于真实分布。我们在第4节中的分析保证，样本复杂性最差在n个标注函数的O（nlogn）阶上增长。在实践中，我们发现结构学习的效果要比保证率好，线性地取决于真实相关性的数量，对数取决于可能的相关性的数量。这与Ising models 的完全监督结构学习中观察到的行为相匹配（Ravikumar等人，2010），这也比最著名的理论保证更严格。</p>
<p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/Learning the Structure of Generative Models without Labeled Data/image-20200721151900896.png" alt="image-20200721151900896" style="zoom:80%;" /></p>
<p>我们首先测试标注函数数量变化的影响。 For $n\in\{25,50,75,100\}$</p>
<p>设置两对标注函数be correlated with$\theta_{jk}^{Cor}=0.25$， 设置$\theta_{j}^{Acc}=1.0$ 对所有 j</p>
<p>然后，我们为100多个试验的每个设置生成m个样本。</p>
<div class="group-picture"><div class="group-picture-container"><div class="group-picture-row"><div class="group-picture-column" style="width: 33.333333333333336%;"><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/Learning the Structure of Generative Models without Labeled Data/image-20200721152358951.png" alt="image-20200721152358951" style="zoom:80%;" /></div><div class="group-picture-column" style="width: 33.333333333333336%;"><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/Learning the Structure of Generative Models without Labeled Data/image-20200721152415862.png" alt="image-20200721152415862" style="zoom:80%;" /></div><div class="group-picture-column" style="width: 33.333333333333336%;"><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/Learning the Structure of Generative Models without Labeled Data/image-20200721152611247.png" alt="image-20200721152611247" style="zoom:80%;" /></div></div><div class="group-picture-row"><div class="group-picture-column" style="width: 100%;"><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/Learning the Structure of Generative Models without Labeled Data/image-20200721152625536.png" alt="image-20200721152625536" style="zoom:80%;" /></div></div></div></div>
<h4 id="5-2-Comparison-with-Maximum-Likelihood"><a href="#5-2-Comparison-with-Maximum-Likelihood" class="headerlink" title="5.2. Comparison with Maximum Likelihood"></a>5.2. Comparison with Maximum Likelihood</h4><h4 id="5-3-Real-World-Applications"><a href="#5-3-Real-World-Applications" class="headerlink" title="5.3. Real-World Applications"></a>5.3. Real-World Applications</h4><p>考虑了三个任务：从科学文献中提取特定疾病的提及mentions of specific diseases（疾病标记）；从科学文献中摘录有关化学物质诱发疾病的记载mentions of chemicals inducing diseases(Chemical-Disease)；并从PDF零件表中提取关于电子设备极性的说明（设备极性）。在前两个应用中，我们考虑一个训练集包含500个来自PubMed的未标记摘要，在第三情况下，我们考虑了由混合文本和表格数据组成的100个PDF parts sheets 。我们使用手工标记的测试集来评估 on the candidate-mention-level performance，即分类器在给定 a set of candidate mention的情况下识别特定实体或关系的正确提及的准确性。例如，在化学疾病中，我们将通过 标准预处理工具 确定的所有 共生化学疾病提及对 co-occurring chemical-disease mention pairs  视为候选。</p>
<p>我们看到，对标记函数之间的相关性进行建模可以提高性能，这似乎与源总数相关correlated with the total number of source。不同的源使用不同的匹配启发式方法检查 参考疾病本体的特定子树的成员for membership in specific subtrees of a reference disease ontology，标注函数在检查本体的相同子树使会发生重叠</p>
<p>检查化学疾病任务后，<strong>我们发现我们的方法可以识别明显是真实的相关性和更微妙的相关性</strong>，例如，我们的方法将学习labeling functions 之间的依赖性，这些labeling functions 是彼此的组成部分，例如一个标签函数检查模式$\text{[CHEM] induc.* [DIS]}$ 而另一种标注函数，在已知化学-疾病关系的外部知识库中检查此模式以及成员身份。</p>
<p>我们的方法还学习了更细微的相关性：例如，它选择了一种标记函数，该标记函数在 包含候选物 的 chemical and disease mentions 之间检查一个chemical mention是否存在，而一个标记函数则检查$\text{.*-induced}$出现在两者之间。</p>
<h3 id="7-Conclusion-and-Future-Directions"><a href="#7-Conclusion-and-Future-Directions" class="headerlink" title="7. Conclusion and Future Directions"></a>7. Conclusion and Future Directions</h3><p>我们表明，学习生成模型的结构可以实现更高质量的数据编程结果。我们的结构学习方法也比最大似然方法快100倍。如果要通过数据编程和其他形式的弱监督来简化机器学习工具的开发，则必须以最少的用户干预为生成模型选择准确的结构。有趣的问题仍然存在。可以提高定理1的担保以获得更高阶的依赖性以匹配推论2的成对情况吗？初步实验表明它们在实践中以相似的速率收敛</p>
]]></content>
      <categories>
        <category>Training Data Generation</category>
        <category>Generative Models</category>
      </categories>
      <tags>
        <tag>generative models</tag>
        <tag>truncated normal distribution</tag>
      </tags>
  </entry>
  <entry>
    <title>Data Programming:Creating Large Training Sets, Quickly</title>
    <url>/blog/2020/07/16/Data%20ProgrammingCreating%20Large%20Training%20Sets,%20Quickly/</url>
    <content><![CDATA[<a id="more"></a>
<h3 id="『Data-Programming-Creating-Large-Training-Sets-Quickly』阅读笔记"><a href="#『Data-Programming-Creating-Large-Training-Sets-Quickly』阅读笔记" class="headerlink" title="『Data Programming:Creating Large Training Sets, Quickly』阅读笔记"></a>『Data Programming:Creating Large Training Sets, Quickly』阅读笔记</h3><p><a href="https://github.com/HazyResearch/metal/blob/master/tutorials/Basics.ipynb">Basics Tutorial for Snorkel MeTaL</a></p>
<p><a href="https://arxiv.org/pdf/1812.00417.pdf"> Snorkel Drybell：在行业规模部署弱监督的案例研究</a></p>
<p><a href="https://medium.com/sculpt/a-technique-for-building-nlp-classifiers-efficiently-with-transfer-learning-and-weak-supervision-a8e2f21ca9c8">Snorkel应用实例：Building NLP Classifiers Cheaply With Transfer Learning and Weak Supervision</a></p>
<p><a href="https://zhuanlan.zhihu.com/p/55138499">reference—snorkel解读</a></p>
<ol>
<li><p>整个流程大体可以分为3部分：</p>
<ul>
<li><p>弱监督或无监督数据源采集，包括采集无标签数据、构建领域词表等；</p>
</li>
<li><p>编写LF函数，生成对样本集的标注向量； 训练生成式模型对样本长生概率标注；</p>
</li>
<li><p>利用第二步生成的带标注的数据训练复杂的判别型模型，比标注函数LF有更好的泛化能力(比如CNN、RNN等)</p>
</li>
</ul>
</li>
<li><p>把整个模型看成是集成学习(ensemble learning)，每个LF都可以看成是一个弱分类器</p>
</li>
<li><p>生成模型基于概率图模型，用factor来建模变量间的依赖关系。单变量因子用来建模图中变量的先验分布；多变量因子建模多个变量之间的关系，联合分布。</p>
</li>
<li><p>样本的真实标签 Y 看作是模型的隐变量。要建模所有LF对样本生成的标注向量和真实标签的联合概率，要通过优化得到的模型参数是每个LF给出pseudo labels的权重，在并不知道真实标签分布即先验分布时，用最大对数似c然估计参数，因此计算中用到将真实标注marginalized的marginal 概率(论文中优化的模型参数是一个LF对一个样本进行标注的概率和标注正确的概率，对这两个随机变量设置了取值范围，感觉和集成学习中应用Hoeffding来算上下界有关)</p>
</li>
<li><p>对上面的优化目标求梯度，根据蒙特卡洛积分，最终只需要把每次采样到的两个分布的样本点带入到对应的因子函数中求出对应的值，再计算两者只差即可。为了获得指定分布的样本点，对于高维的联合分布通常使用Gibbs采样算法</p>
</li>
</ol>
<h3 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h3><p>我们表明，通过将训练集标记过程明确表示为一个<strong>生成模型</strong>，我们可以对生成的训练集进行<strong>“去噪”</strong>，并在理论上确定我们可以在少数几个设置中恢复这些生成模型的参数。然后，我们展示如何修改<strong>判别损失函数</strong> discriminative loss function以使其是<strong>噪声敏感noise-aware</strong>的。并且在包括Logistic回归和LSTM在内的一系列判别模型中证明了该方法。此外，当训练数据有限或不可用时，数据编程可能是非专家更容易创建机器学习模型的方式。</p>
<h3 id="专有名词"><a href="#专有名词" class="headerlink" title="专有名词"></a>专有名词</h3><ol>
<li><p>data programming</p>
</li>
<li><p>weak supervision strategies</p>
</li>
<li><p>domain heuristics ——labeling functions：程序标记了数据的子集，但是标记的label are noisy and may conflict。</p>
</li>
<li><p>labeling functions——用户无需手动标记每个示例，而是通过提供一组启发式规则来描述可以标记这些示例的过程</p>
</li>
<li><p>TAC-KBP Slot Filling challenge,</p>
</li>
<li><p>asymptotic scaling ——渐近缩放，流行学习？</p>
</li>
<li><p>relation extraction tasks——关系提取任务</p>
</li>
<li><p>urrounding textual patterns——周围文本模式</p>
</li>
<li><p>discriminative feature-based mode</p>
</li>
<li><p>hierarchical topic models——分层主题模型</p>
</li>
<li><p>Co-training——<strong>views of the data</strong></p>
</li>
<li><p>factor graph</p>
<p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/Data ProgrammingCreating Large Training Sets, Quickly/image-20200717115255648.png" alt="image-20200717115255648" style="zoom:67%;" /></p>
</li>
<li><p>Gibbs sampling </p>
</li>
<li><p>snorkel <a href="https://zhuanlan.zhihu.com/p/55138499">Sonrkel—从0开始构建机器学习项目</a></p>
<p>近似集成学习 ensemble learning <a href="[http://www.huaxiaozhuan.com/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0/chapters/6_ensemble_learning.html](http://www.huaxiaozhuan.com/统计学习/chapters/6_ensemble_learning.html">集成学习</a>)</p>
</li>
</ol>
<h3 id="1-简介"><a href="#1-简介" class="headerlink" title="1    简介"></a>1    简介</h3><p>过去十年中许多重要的机器学习突破都受到新标签训练数据集的发布的推动。使用此类数据集的监督学习方法Supervised learning approaches 已越来越成为整个科学和工业应用的关键构建块。自动化特征生成方法automated feature generation approaches的最新成功经验也推动了这一趋势，特别是深度学习方法，例如长期短期记忆（LSTM）网络，在具有足够大标签的训练集的情况下，该方法减轻了特征工程的负担。但是，对于许多实际应用程序，不存在大型的手工标记训练集，并且由于要求标记者必须是应用程序领域的专家，因此训练集的创建成本过高。此外，应用程序的需求经常变化，因此需要新的或修改的训练集。</p>
<p>为了帮助减少训练集创建的成本，我们提出了<strong>data programming</strong>，它是训练数据集的编程创建和建模的范例。数据编程为<strong>weak supervision</strong>提供了一个简单，统一的框架，在该框架中，训练标签有噪声，并且可能来自多个可能重叠的来源。在数据编程中，用户以<strong>labeling functions</strong>的形式对这种弱监督进行编码，标签函数是用户定义的程序，每个程序都为数据的某些子集提供标签，并共同生成大量但可能重叠的训练标签集。</p>
<p>许多不同的弱监督方法可以表示为标记功能，例如利用现有知识库的策略existing knowledge bases (就像在<strong>DS</strong>中一样)为许多个人注释者的标签建模（如在众包中）或利用特定于领域的模式和词典patterns and dictionaries的组合——所以，labeling functions 的错误率可能变化很大，并且在某些数据点上可能会发生冲突。————所以我们将labeling functions建模成generative process，通过学习标记函数的准确性及其相关结构，自动对所得的训练集进行降噪处理。反过来，我们使用该训练集模型来优化我们希望训练的判别模型的损失函数的随机形式。我们表明，在labeling functions,具有特定条件的情况下，我们的方法实现了与监督学习方法相同的渐近缩放，但是我们的缩放取决于未标记数据unlabeleddata的数量，并且仅使用固定数量的标记函数 labeling functions</p>
<p>Data programming，例如，考虑以下场景：当两个质量和范围不同的 labeling functions重叠并且在某些训练示例上可能发生冲突时;在先前的方法中，用户将不得不决定使用哪个信号，或者如何以某种方式将两者的信号集成在一起。在数据编程中，我们通过学习包含两个 labeling functions的训练集模型来自动完成此任务。另外，用户经常知道或能够推断出其 labeling functions之间的dependencies依赖性。在数据编程中，用户可以提供一个依赖图dependency graph，以表明例如两个标记功能相似，或者一个“固定”fixes”或“加强”“reinforces”另一个。我们描述了一些案例，在这些案例中我们可以学习这些依赖性的强度the strength of these dependencies,，并且对于它们的泛化generalization也渐近地与监管方法相同。    (集成学习)</p>
<p>我们的方法的另一个动机是由于观察到用户经常为模型的选择特征selecting features而苦恼，这是给定固定大小的训练集的传统开发瓶颈。但是，来自用户的初步反馈表明，在数据编程框架中<strong>编写标签功能writing labeling functions可能更容易</strong>。虽然一个特征的最终性能的影响取决于训练集和模型的统计特性，但a labeling function具有简单直观的最佳性标准：可以正确标记数据。以此为动力，我们探索了是否可以颠覆传统的机器学习开发流程，让用户专注于生成足够大的训练集以支持自动生成的特征。</p>
<h4 id="Summary-of-Contributions-and-Outline"><a href="#Summary-of-Contributions-and-Outline" class="headerlink" title="Summary of Contributions and Outline"></a>Summary of Contributions and Outline</h4><p>我们的第一个贡献是数据编程框架，在该框架中，用户可以比以前的方法更灵活，更通用的方式隐式描述训练集的丰富生成模型。在第3节中，我们首先探讨一个简单的模型，其中标记函数是有条件独立的。我们在这里表明，在某些条件下，样本复杂度几乎与标记的情况相同。在第4节中，我们将结果扩展到更复杂的数据编程模型，在众包中泛化得到相关的结果[17]。在第5节中，我们通过实验验证了我们在基因组学，药物基因组学和新闻领域中的大型现实文本关系提取任务上所采用的方法，该方法在基线<strong>DS</strong>方法上显示出平均2.34分的F1得分提高-包括获得新的竞争得分在2014年TAC-KBP插槽填充竞赛中。使用LSTM生成的功能，我们将在竞争中排名第二，比最新的LSTM基线获得5.98分的F1分数增长[32]。此外，我们描述了一组生物信息学用户从可用性研究中获得的有希望的反馈</p>
<h3 id="2-Related-Work"><a href="#2-Related-Work" class="headerlink" title="2    Related Work"></a>2    Related Work</h3><ol>
<li><strong><em>Distant supervision</em></strong> 是通过编程方式创建训练集的一种方法，典型的例子是从文本中提取关系relation extraction，其中将已知关系的知识库启发式heuristically 映射到输入语料库 [8,22]。<strong>基本extension</strong>是通过围绕文本模式将示例分组，将问题变成multiple instance learning  [15, 25].；<strong>其他extension</strong>使用基于判别性基于特征的模型discriminative feature-based mode [26]或生成式模型对这些周围文本模式的准确性进行建模[1, 27, 31].。像我们的方法一样，这些后来的方法为训练集创建的生成过程generative process建模，但它们不是基于用户的输入as in our approach。还有很多示例，其中以与我们的方法类似的方式，从未标记的数据[7]或直接从用户[21、29]收集用于标记训练数据的其他启发式模式heuristic patterns ，但没有任何框架可以处理以下事实： labels are explicitly noisy</li>
<li><strong><em>Crowdsourcing</em></strong>  被广泛用于各种机器学习任务 [13, 18]. 与我们的问题设置特别相关的是一个理论问题，即如何在没有可用的<strong>ground truth</strong>的情况下对各种专门领域数据的准确性进行建模，这是在Crowdsourcing背景下提出的[10]。 [4,9, 16, 17, 24, 33]中provide formal guarantees even in the absence of labeled data。<strong>我们的模型可以捕获the basic model of the crowdsourcing setting，并且在独立情况下可以视为等效模型（第3节）。</strong>除了超越仅从人类注释者中得到输入之外，我们还对用户提供的“labelers“之间的依赖关系进行建模，这在Crowdsourcing的语境中是不自然的。此外，<strong>尽管众包结果侧重于大量标记者，每个标记者都对数据的一小部分进行标记，但我们考虑了一小部分标记函数，每个标记函数都对数据集的大部分进行了标记</strong></li>
<li><strong><em>Co-training</em></strong>协同训练是通过选择两个条件独立的<strong>数据视图views of the data</strong>来有效利用少量标记数据和大量未标记数据的经典过程[5]。除了不需要一组标记数据，并允许两个以上的视图（在我们的情况下为标记函数）之外，我们的方法还允许对视图之间的依赖关系进行显式建模，例如，允许对观察到的与视图 views之间的依赖关系进行显式建模[19]</li>
<li><strong><em>Boosting</em></strong> 用于组合许多“弱”分类器的输出以在supervised setting中创建强分类器[28]。最近，已经提出boosting-like 的方法，该方法除了利用标记数据之外还利用了未标记数据，该方法还用于对所集成 ensembled的各个分类器的准确性设置约束[3]。这在本质上与我们的方法类似，除了在我们的方法中标记数据不是明确必需的，并且支持“启发式”分类器（标记函数）之间更丰富的依赖关系richer dependency structures结构。</li>
<li>在经典[20]和最近的情况下[23]都讨论了带有噪声标签的学习的一般情况。还已经在标签噪声鲁棒logistic回归in the context of label-noise robust logistic regression的背景下进行了专门研究[6]。我们<strong>考虑更普遍的情况，其中多个嘈杂的标签功能可能会发生冲突并具有依赖性。</strong></li>
</ol>
<h3 id="3-The-Data-Programming-Paradigm"><a href="#3-The-Data-Programming-Paradigm" class="headerlink" title="3   The Data Programming Paradigm"></a>3   The Data Programming Paradigm</h3><ol>
<li><p><strong>动机：</strong>在许多应用程序中，我们想使用机器学习，但是我们面临以下挑战：（i）手工标注的训练数据不可用，并且要获得足够数量的数据过于昂贵，因为它需要昂贵的领域专家标记;（ii）相关的外部知识库不可用或不够具体，从而排除了传统的远程监管或共同培训方法；（iii）应用规范不断变化，从而改变了我们最终希望学习的模型。——是训练集以编程方式创建的范例，它使领域专家可以更快地训练机器学习系统，具有这种类型的预期损失缩放的潜力has the potential for this type of scaling of expected loss。</p>
</li>
<li><p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/Data ProgrammingCreating Large Training Sets, Quickly/image-20200716212956853.png" alt="image-20200716212956853" style="zoom:67%;" /></p>
<p>这一段指什么？</p>
</li>
<li><p>在本文的其余部分中，我们将重点放在 binary classification 任务中，其中我们具有分布$\pi$ over object，有 class pairs$(x,y)\in \chi \times\{-1,1\}$，我们关心在给定一些特征的线性模型linear model下使logistic损失最小</p>
<p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/Data ProgrammingCreating Large Training Sets, Quickly/image-20200717092515094.png" alt="image-20200717092515094" style="zoom: 67%;" /></p>
<p>不失一般性地，我们假设$||f(x)||\leq1$.</p>
<p>labeling function$\lambda_i:\chi\mapsto\{-1,0,1\}$ 用户定义的函数，对某些 domain heuristic编码,为对象的某些子集提供（非零）标签。用户提供m个labeling function，我们将其向量化为$\lambda:\chi\mapsto\{-1,0,1\}^m$ </p>
</li>
<li><p>举例一个简单的文本关系提取text relation extraction来得到直观印象：给定句子“Gene A causes disease B”，则对象x=(A,B) 有真实分类y=1. w为了构建训练集，写了三个labeling functions：</p>
<p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/Data ProgrammingCreating Large Training Sets, Quickly/image-20200717094342779.png" alt="image-20200717094342779"></p>
<p>$\lambda_1$ : 外部结构化知识库用于标记一些对象的准确性相对较高，相当于传统的远程监管用于关系抽取</p>
<p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/Data ProgrammingCreating Large Training Sets, Quickly/image-20200717094626324.png" alt="image-20200717094626324"></p>
<p>$\lambda_2$ : 使用纯粹的启发式方法以较低的准确度标记大量示例</p>
<p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/Data ProgrammingCreating Large Training Sets, Quickly/image-20200717094710960.png" alt="image-20200717094710960"></p>
<p>$\lambda_3$ : 是一种“混合”标签功能，它利用了知识库和启发式方法</p>
</li>
<li><p>labeling function 不必具有完美的准确性或召回率；相反，它表示用户希望赋予impart to其模型的模式pattern ，并且比起一组手工标记的示例用labeling function更容易。labeling functions 可以基于外部知识库，库或本体 ontologies，可以表达启发式模式或这些类型的某种混合形式；我们在实验中看到存在这种多样性(个体学习器间要有一定的多样性)的证据————labeling functions 可能会重叠，冲突甚至具有依赖性，用户可以将其作为数据编程规范的一部分提供——为输入这些labeling functions提供了框架</p>
</li>
</ol>
<h4 id="Independent-Labeling-Functions"><a href="#Independent-Labeling-Functions" class="headerlink" title="Independent Labeling Functions"></a>Independent Labeling Functions</h4><ol>
<li><p>我们首先描述一个模型——<strong>一个生成模型</strong>，labeling functions 单独打标签，其中给定 true label class——labeling functions $\lambda_i$有$\beta_i$ 的可能性为一个object 打标签(覆盖率)，有$\alpha_i$ 的可能性正确标记对象(准确性)，为简单起见，我们在此还假设每个类别的概率为0.5(each class has probability 0.5)</p>
<p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/Data ProgrammingCreating Large Training Sets, Quickly/image-20200717103541509.png" alt="image-20200717103541509" style="zoom:67%;" /></p>
<p>$\Lambda\in\{-1,0,1\}^m$  包含 labeling functions 输出的标签， $Y\in\{-1,0,1\}$ 是预测的类class</p>
</li>
<li><p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/Data ProgrammingCreating Large Training Sets, Quickly/image-20200717104248010.png" alt="image-20200717104248010"></p>
<p>我们注意到，尽管可以更改这些任意约束，但它们与我们的应用经验大致相符，在该经验中，用户倾向于编写高精度和高覆盖率的标签功能。 </p>
</li>
<li><p>我们的首要目标是使用最大似然估计来了解在我们的未标记训练集，哪一组参数（α，β）与我们的观察最一致。——为此，对于特定的训练集$S\subset\chi$，我们将解决问题：</p>
<p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/Data ProgrammingCreating Large Training Sets, Quickly/image-20200717104635622.png" alt="image-20200717104635622" style="zoom: 67%;" /></p>
<p>换句话说，我们正在最大化在训练示例中产生的观察到的标签出现在生成模型下的概率maximizing the probability that the observed labels produced on our trainingexamples occur under the generative model in<img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/Data ProgrammingCreating Large Training Sets, Quickly/image-20200717103541509.png" alt="image-20200717103541509" style="zoom:67%;" /></p>
<p>在我们的实验中，我们使用随机梯度下降法解决了这个问题。由于这是一种标准技术，因此我们将其分析推迟到附录中进行</p>
</li>
</ol>
<h4 id="Noise-Aware-Empirical-Loss"><a href="#Noise-Aware-Empirical-Loss" class="headerlink" title="Noise-Aware Empirical Loss"></a>Noise-Aware Empirical Loss</h4><p>鉴于我们的参数学习阶段已成功找到一些可以准确描述训练集的$\hat\alpha$和$\hat\beta$，现在，我们可以继续估计参数w(feature mapping的参数矩阵)，在给定$\hat\alpha$和$\hat\beta$的情况下，minimizes the expected risk of a linear model over our feature mapping  $f$。定义了感知噪声的经验风险noise-aware empirical risk $L_{\hat\alpha,\hat\beta}$, with regularization parameter $\rho$</p>
<p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/Data ProgrammingCreating Large Training Sets, Quickly/image-20200717110431141.png" alt="image-20200717110431141" style="zoom:67%;" /></p>
<p>这是一个逻辑回归问题，因此也可以使用随机梯度下降法解决</p>
<p>实际上，我们可以证明在我们现在描述的条件下，在（2）和（3）上运行的<strong>随机梯度下降可以保证产生准确的估计</strong>：</p>
<h5 id="条件1："><a href="#条件1：" class="headerlink" title="条件1："></a>条件1：</h5><p>the problem distribution $\pi$ needs to be accurately modeled by some distribution $\mu$ in the family that we are trying to learn, for $\alpha^<em>,\beta^</em>$</p>
<p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/Data ProgrammingCreating Large Training Sets, Quickly/image-20200717112531997.png" alt="image-20200717112531997" style="zoom:67%;" /></p>
<h5 id="条件2："><a href="#条件2：" class="headerlink" title="条件2："></a>条件2：</h5><p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/Data ProgrammingCreating Large Training Sets, Quickly/image-20200717112625988.png" alt="image-20200717112625988" style="zoom:67%;" /></p>
<p>上述条件2约束 labeling functions 可以任意依赖于特征may be arbitrarily dependenton the features，提供足够的信息以准确识别类别 class</p>
<h5 id="条件3："><a href="#条件3：" class="headerlink" title="条件3："></a>条件3：</h5><p>我们认为用于求解（3）的算法具有有界的generalization risk，$\chi$</p>
<p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/Data ProgrammingCreating Large Training Sets, Quickly/image-20200717113316450.png" alt="image-20200717113316450" style="zoom:67%;" /></p>
<h4 id="在上述条件下，我们对估计的准确性做出以下陈述"><a href="#在上述条件下，我们对估计的准确性做出以下陈述" class="headerlink" title="在上述条件下，我们对估计的准确性做出以下陈述"></a><strong>在上述条件下，我们对估计的准确性做出以下陈述</strong></h4><p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/Data ProgrammingCreating Large Training Sets, Quickly/image-20200717113448896.png" alt="image-20200717113448896" style="zoom:67%;" /></p>
<h3 id="4-Handling-Dependencies"><a href="#4-Handling-Dependencies" class="headerlink" title="4  Handling Dependencies"></a>4  Handling Dependencies</h3><p>随着系统的开发增加了更多的labeling functions ，在标签功能中自然会产生隐式的依赖结构：在某些情况下，对这些依赖进行建模可以提高准确性。我们描述了一种方法，用户可以通过该方法将这种依赖关系知识指定为依赖关系图dependency graph，并说明系统如何使用它来产生更好的参数估计</p>
<h4 id="Label-Function-Dependency-Graph"><a href="#Label-Function-Dependency-Graph" class="headerlink" title="Label Function Dependency Graph"></a>Label Function Dependency Graph</h4><p>augment the data programming specification with <strong><em>label function dependency graph</em></strong><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/Data ProgrammingCreating Large Training Sets, Quickly/image-20200717114531272.png" alt="image-20200717114531272" style="zoom:50%;" />是labeling functions的有向图，每条边是一种commonly-occurring types of dependencies：<strong><em>similar,fixing,reinforcing, andexclusive</em></strong></p>
<p>举例：两个函数$\lambda_1, \lambda_2$ 而$\lambda_2$ 通常仅在</p>
<ol>
<li>$\lambda_1$ 也对这个object 打标签</li>
<li>$\lambda_1, \lambda_2$在标签上存在分歧，</li>
<li>$\lambda_2$ 打的标签是对的</li>
</ol>
<p>我们称此为fixing dependency，因为$\lambda_2$修正了$\lambda_1$的错误。</p>
<p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/Data ProgrammingCreating Large Training Sets, Quickly/image-20200717115042583.png" alt="image-20200717115042583" style="zoom:67%;" /></p>
<h4 id="Modeling-Dependencie"><a href="#Modeling-Dependencie" class="headerlink" title="Modeling Dependencie"></a>Modeling Dependencie</h4><p><strong>factor graph</strong>建模 </p>
<ol>
<li><p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/Data ProgrammingCreating Large Training Sets, Quickly/image-20200717120026831.png" alt="image-20200717120026831" style="zoom:67%;" /></p>
</li>
<li><p>对于每个依赖边（d，i，j），我们添加一个或多个factors。</p>
<p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/Data ProgrammingCreating Large Training Sets, Quickly/image-20200717131549162.png" alt="image-20200717131549162" style="zoom:67%;" /></p>
</li>
</ol>
<p>因子图 <a href="[https://longaspire.github.io/blog/%E5%9B%A0%E5%AD%90%E5%9B%BE%E4%BB%8B%E7%BB%8D/](https://longaspire.github.io/blog/因子图介绍/">因子图介绍</a>)</p>
<h4 id="Learning-with-Dependencies"><a href="#Learning-with-Dependencies" class="headerlink" title="Learning with Dependencies"></a>Learning with Dependencies</h4><h3 id="评价"><a href="#评价" class="headerlink" title="评价"></a>评价</h3><p>在这个框架下，用户提供一组Heuristic标注函数（Labeling Functions）。这些标注函数可以互相抵触，可以重复，也可以依赖外部的Knowledge Base等。然后，文章提出的框架则学习各个标注函数之间的Correlation关系，从而可以利用多种标注函数，达到监督学习（Supervised Learning）的效果。</p>
<p>文章采用Logistic Regression在Binary的分类问题上作为一个例子。每一个Heuristic标注函数拥有两个参数，一个是控制有多大可能性标注一个对象，而另一个则是控制标注对象的准确度。于是学习这两个参数就成为目标函数的主要部分。</p>
<p>在所有的标注函数都是独立的情况下，文章采用了最大似然（Maximum Likelihood Estimation）的方法估计到这两个参数的取值。在已经得到了这两个估计的情况下，作者们进一步利用原本的Logistic Regression来学习一个分类器。也就是说，整个框架分为两个部分。</p>
<p>当然，独立的标注函数作用还是有限。文章提出了一个类似Markov Random Field的方式来处理各个标注函数之间的相互关系。在数据实验中，基于Data Programming的方法不管是在人工Feature还是采取LSTM自动学习的Feature中都有很显著的效果提升。这篇文章非常适合需要对Crowdsourcing进行学习和研究的学者。</p>
]]></content>
      <categories>
        <category>Training Data Generation</category>
        <category>Snorkel</category>
        <category>Data Programming</category>
        <category>PGM</category>
        <category>Factor Graph</category>
        <category>MC</category>
      </categories>
      <tags>
        <tag>snorkel</tag>
        <tag>data programming</tag>
        <tag>ensemble learning</tag>
        <tag>probabilistic graph model</tag>
        <tag>factor graph</tag>
        <tag>monte carlo method</tag>
        <tag>gibbs sampling</tag>
      </tags>
  </entry>
  <entry>
    <title>Snorkel-- rapid training data creation with weak supervision</title>
    <url>/blog/2020/07/16/Snorkel%20rapid%20training%20data%20creation%20with%20weak%20supervision/</url>
    <content><![CDATA[<a id="more"></a>
<h3 id="『Snorkel—-rapid-training-data-creation-with-weak-supervision』阅读笔记"><a href="#『Snorkel—-rapid-training-data-creation-with-weak-supervision』阅读笔记" class="headerlink" title="『Snorkel— rapid training data creation with weak supervision』阅读笔记"></a>『Snorkel— rapid training data creation with weak supervision』阅读笔记</h3><ol>
<li>早期版本的Snorkel的问题之一是用户难以在一个模型中应用不同的标签来源。通过在<em>标签功能</em>（LF）周围创建一层接口以及特定语言来表达这些功能的不同种类，可以解决此问题——。用户可以自实现标注函数，也可以用snorkel提供的接口，包括：正则、远程监督、弱分类器以及标注函数生成器。</li>
<li>用生成模型学习weak supervision sources 的准确性，而且能够学习其依赖性和相关性。</li>
<li>通过label density作为是否选择使用生成模型的依据，middle-density most benefit from applying the generative model</li>
<li>automatically choose a value of that trades-off between predictive performance and computational cost——包含多少的LF相关 correlation threshold</li>
<li>主要通过一个 running example 解释snorkel的运行过程：<ol>
<li>Data Model：context hierarchy的数据结构，以parent/child relation存储在关系数据库中。</li>
<li>可以手动编写Labeling Functions或是使用Snorkel includes 的library of declarative operators</li>
<li>Pattern-based：higher information density input</li>
<li>Distant supervision </li>
<li>Weak classifiers：limited coverage, noisy, biased, and/or trained on a different dataset—can be used as labeling functions</li>
<li>Labeling function generators:generate multiple labeling functions from a single resource,such as crowdsourced labels and distant supervision from structured knowledge bases </li>
</ol>
</li>
</ol>
<h3 id="专有名词"><a href="#专有名词" class="headerlink" title="专有名词"></a>专有名词</h3><ol>
<li>Spans of text——文本跨距</li>
<li>生成模型、辨别模型</li>
<li>无监督</li>
<li>对数似然、对数边际似然</li>
<li>迭代随机梯度下降</li>
<li>吉布斯采样</li>
<li>contrastive divergence [23]</li>
<li>Numbskull library—— Python NUMBA-based Gibbs sampler.</li>
<li>ablation stud——</li>
</ol>
<h3 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h3><h3 id="1-Introduction"><a href="#1-Introduction" class="headerlink" title="1 Introduction"></a>1 Introduction</h3><div class="group-picture"><div class="group-picture-container"><div class="group-picture-row"><div class="group-picture-column" style="width: 50%;"><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/Snorkel rapid training data creation with weak supervision/image-20200717151559194.png" alt="image-20200717151559194" style="zoom:60%;" /></div><div class="group-picture-column" style="width: 50%;"><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/Snorkel rapid training data creation with weak supervision/image-20200717151939755.png" alt="image-20200717151939755" style="zoom:60%;" /></div></div></div></div>
<p>理想情况下，我们将合并许多弱监督来源的标签，以提高训练集的准确性和覆盖范围。但是，有效地进行操作存在<strong>两个关键挑战</strong>。首先，源 source将重叠和冲突，要解决它们的冲突，我们需要估计其准确性和相关性结构，而又无法获得 ground truth。其次，我们需要将有关标签质量的关键沿袭信息传递给正在训练的终端模型</p>
<p><strong>Fig1</strong>：Source1， high-accuracy, low-coverage ； Source2，low-accuracy, high-coverage 。两者在中间的label(分色点处) overlap and disagree 。如果我们以不加权的多数票解决冲突，那么最终将得到无效（并票）标签。如果我们可以<strong>正确地估计源准确性</strong>，我们将朝源1的方向解决冲突。——在用训练集用于训练end model时，<strong>要给high-accuracy sources更大的权重，因此要represent training label lineage</strong> </p>
<p><strong><em>data programming：</em></strong> generating probabilistic training labels representing the lineage of the individual labels—— we can recover source accuracy and correlation structure without hand-labeled training data。这是之前的理论</p>
<p>现在推出<strong><em>Snorkel：</em></strong> the first end-to-end system for combining weak supervision sources to rapidly create training data </p>
<p>提取了三条原则：</p>
<p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/Snorkel rapid training data creation with weak supervision/image-20200717154507574.png" alt="image-20200717154507574" style="zoom:67%;" /></p>
<p><strong>我们的工作做出了以下技术贡献：</strong></p>
<ol>
<li><p><strong><em>A Flexible Interface for Sources</em></strong>： </p>
<p>challenge：不同类型的弱监管对输入数据的不同范围进行操作。distant supervision has to be mapped programmatically to specific spans of text. Crowd workers and weak classifiers often operate over entire documents or images. Heuristic rules，他们可以同时利用来自多个上下文的信息，例如将文档标题，文本中的命名实体和知识库中的信息组合在一起。这种异质性非常繁琐。</p>
<p>解决：我们围绕labeling function (LF)的抽象概念构建了一个接口层interface layer</p>
</li>
<li><p><strong><em>Trade-offs in Modeling of Sources：</em></strong> Snorkel<strong>使用生成模型来学习弱监督源的准确性[</strong>而不需要用到ground truth43]。此外，它还学习了源之间的相关性和其他统计相关性，并纠正了标注函数中那些会使得估计的准确性产生偏差的相关性correlations。这种范例在预测性能和速度之间产生了以前没探索的trade-off。自然而然的第一个问题是：<strong>何时对源准确性进行建模可以提高预测性能？此外，有多少依赖关系（例如相关性）值得建模？</strong></p>
<p>在弱化监督的生成模型中，我们研究预测性能与训练时间之间的权衡。虽然建模源的准确性和相关性不会妨碍预测性能，但我们提出了对简单多数表决simple majority vote何时同样有效的理论分析。根据我们的结论，<strong>我们引入了一种优化器，用于确定何时对标签函数的准确性进行建模，以及何时可以跳过学习以进行简单的多数表决</strong>。此外，我们的优化器会自动确定标签函数之间的哪些相关性要进行建模。该优化器正确地预测了生成模型过大投票的优势，使平均在我们的评估任务中的投票精度在2.16个准确度点之内，并通过以下方式加快了管道的执行速度1.8倍它还使我们可以获得相关学习优势的60–70％，同时节省多达61％的培训时间（每次执行34分钟）。</p>
</li>
<li><p><strong><em>First End-to-End System for Data Programming：</em></strong> </p>
</li>
</ol>
<h3 id="2-Snorkel-architecture"><a href="#2-Snorkel-architecture" class="headerlink" title="2 Snorkel architecture"></a>2 Snorkel architecture</h3><p><strong>工作流的三个阶段：</strong></p>
<ol>
<li><strong>Writing Labeling Functions：</strong> 能够使用不同的sources such as patterns, heuristics, external knowledgebases,</li>
<li><strong><em>Modeling Accuracies and Correlations：</em></strong>通过标注函数自动学习生成模型，这样就可以估算其准确性和相关性。此步骤不使用任何ground-truth data,，而是从标注函数的 agreements and disagreements 中学习。我们观察到，与未加权标签组合相比，此步骤比Snorkel的最终预测性能提高了5.81％，并且有趣的是，它通过提供有关标注函数质量的可行反馈，简化了用户开发经验。</li>
<li><strong><em>Training a Discriminative Model：</em></strong> Snorkel的输出是一组概率标签probabilistic labels，可用于训练各种最先进的机器学习模型，例如流行的深度学习模型。虽然生成模型本质上是用户提供的标签功能的重新加权组合（这些标签功能往往精确但覆盖率较低），但现代判别型模型可以保持这种精度，同时学会推广标签功能之外的其他方面，从而增加了覆盖范围和稳健性看不见的数据。</li>
</ol>
<h4 id="Setup"><a href="#Setup" class="headerlink" title="Setup"></a>Setup</h4><p>目标是学习参数分类模型$h_{\theta}$ ，提供data $x\in\mathcal{X}$，预测label $y\in\mathcal{Y}$</p>
<p>我们将重点放在二元的问题上，尽管我们在实验中包括了多类应用程序。例如，x可能是医学图像，而y是一个标签表示正常与异常。在我们查看的关系提取示例中，我们经常将 x 称为候选对象。在传统的监督学习设置中，我们将通过将其拟合到一组训练有标记的数据点来学习hθ。但是，在我们的设置中，我们假设我们只能访问未标记的数据进行培训。我们确实假设可以访问开发过程中使用的一小部分标记数据（称为开发集）和还有一个访问不到的，带有标签的测试集以进行评估。这些集合的大小可以比训练集合小几个数量级，从而使它们的获得很经济。</p>
<p>Snorkel旨在通过提供一组标注函数（黑盒函数）来生成训练标签：$\lambda:\mathcal{X}\rightarrow\mathcal{Y}\cup\{\emptyset\}$use ∅ to denote that the labeling function abstains放弃</p>
<p> Given m unlabeled data points and n labeling functions, Snorkel 将标注函数应用于未标记的数据，以生成标注函数输出矩阵 $\Lambda\in(\mathcal{Y}\cup\{\emptyset\})^{m\times n}$</p>
<p>剩下的工作是将这个label标签矩阵 $\Lambda$ （可能包含每个数据点的重叠和冲突标签）合成为一个概率训练标签向量<img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/Snorkel rapid training data creation with weak supervision/image-20200717165027488.png" alt="image-20200717165027488" style="zoom: 67%;" />然后，可以使用这些训练标签来训练判别模型</p>
<h4 id="文本关系提取任务的运行示例，可以作为许多现实世界中的知识库构建和数据分析任务的代理"><a href="#文本关系提取任务的运行示例，可以作为许多现实世界中的知识库构建和数据分析任务的代理" class="headerlink" title="文本关系提取任务的运行示例，可以作为许多现实世界中的知识库构建和数据分析任务的代理"></a>文本关系提取任务的运行示例，可以作为许多现实世界中的知识库构建和数据分析任务的代理</h4><p>考虑从生物医学文献中提取不良化学疾病关系的提及的任务，给定带有化学药品和疾病标签的文件，我们将每个co-occurring (chemical, disease) 提及对称为“候选提取物”，我们将其视为数据点用于分类为真或假</p>
<p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/Snorkel rapid training data creation with weak supervision/image-20200717231833760.png" alt="image-20200717231833760" style="zoom:67%;" /></p>
<p><strong><em>Data Model</em></strong></p>
<p>一个设计挑战是管理复杂的，非结构化的数据，使中小企业能够在其上编写标注函数。在Snorkel中，输入数据存储在上下文层次结构<strong><em>context hierarchy</em></strong>中。它由通过父/子关系连接的上下文类型组成 context types connected by parent/child relationships,，这些上下文类型存储在一个关系数据库中，并且可以通过使用SQLAlchemy构建的对象关系映射 object-relational mapping（ORM）层来使用。每个context type表示的是系统要处理或使用的数据的概念性组成部分当在编写标注函数时；例如文档，图像，段落，句子或嵌入式表格。然后将候选对象（即数据点x）定义为上下文元组。</p>
<p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/Snorkel rapid training data creation with weak supervision/image-20200717232634028.png" alt="image-20200717232634028" style="zoom: 80%;" /></p>
<p>在我们正在运行的CDR示例中，<strong>输入的文档可以在Snorkel中表示为由文档组成的层次结构hierarchy</strong> consisting of <em>Documents</em>，每个文档包含一个或多个句子<em>Sentences</em>，每个文档包含一个或多个文本跨距Spans of text.也可以用元数据标记这些跨距Spans，例如实体标记将其标识为化学或疾病的表态such as <em>Entity</em> markers identifying them as chemical or disease mentions 。 A <strong>candidate</strong> is then <strong>a tuple of two Spans</strong>.</p>
<h4 id="2-1-A-language-for-weak-supervision"><a href="#2-1-A-language-for-weak-supervision" class="headerlink" title="2.1 A language for weak supervision"></a>2.1 A language for weak supervision</h4><p>Snorkel使用标注函数的核心抽象来允许用户指定各种弱监督源，例如patterns, heuristics, external knowledge bases, crowdsourced labels, 等。如后面的部分所述，这种较高级别higher-level,，精度较低的输入提供的效率更高（请参见第4.2节），并且可以自动去噪和合成。</p>
<p>因此，我们允许用户在两个抽象级别上编写标签函数：自定义Python函数和声明性运算符——: custom Python functions and declarative operators.，从而权衡了表达性和效率</p>
<p><strong><em>Hand-Defined Labeling Functions</em></strong></p>
<p><strong>input:</strong>    Candidate object </p>
<p><strong>output:</strong>  a label or abstains</p>
<p>这些函数通常类似于extract–transform–load scripts，表达基本模式或启发式方法patterns or heuristic，但可能会使用支持的编码器 supporting code 或者 资源，并且会很复杂。</p>
<p>这些函数是写在<strong>ORM</strong> 层——它将上下文层次结构和关联的元数据associated metadata映射为面向对象的语法，从而允许用户轻松遍历输入数据的结构</p>
<p>以上面一直举出的例子来说明</p>
<p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/Snorkel rapid training data creation with weak supervision/image-20200718171755942.png" alt="image-20200718171755942" style="zoom:80%;" /></p>
<p><strong><em>Declarative Labeling Functions</em></strong></p>
<p>Snorkel包含一个声明性运算符库，该运算符库根据我们去年与用户的经验对最常见的weak supervision函数类型进行编码</p>
<p>这些操作符的语义和语法 semantics and syntax易于使用，并且可以轻松自定义，包括以下两种主要类型</p>
<ol>
<li>labeling function templates：输入一个或多个参数，并输出一个 labeling function；</li>
<li>labeling function generators：它接受一个或多个参数，并输出一组标记函数（如下所述）。这些功能捕获了一系列常见的弱监督形式，例如</li>
</ol>
<ul>
<li><strong>Pattern-based</strong> For example, pattern-based heuristics encompass feature annotations [64] and pattern-bootstrappingapproaches [19,22] (Example2.3)</li>
<li><strong>Distant supervision</strong>  Distant supervision generates training labels by heuristically aligning data points with anexternal knowledge base and is one of the most popularforms of weak supervision [3,24,36]</li>
<li><strong>Weak classifiers </strong>  Classifiers that are insufficient for our task—e.g., limited coverage, noisy, biased, and/or trainedon a different dataset—can be used as labeling functions.</li>
<li><strong>Labeling function generators</strong>  One higher-level abstraction that we can build on top of labeling functions inSnorkel islabeling function generators, which generate multiple labeling functions from a single resource,such as crowdsourced labels and distant supervision from structured knowledge bases (Example2.4).</li>
</ul>
<p><strong><em>Example2.4</em></strong>   ——  Labeling function generators</p>
<p>传统 distant supervision遇到的问题是：知识库的不同子集具有不同的准确性和覆盖范围 </p>
<p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/Snorkel rapid training data creation with weak supervision/image-20200719104439998.png" alt="image-20200719104439998" style="zoom:80%;" /></p>
<p><strong>Interface Implementation</strong></p>
<p><strong>Execution Model</strong></p>
<p>由于标注函数在离散的候选对象上运行，它们的执行是并行的。如果连接到一个关系型数据库提供同时连接，例如PostgreSQL，然后主进程(通常是笔记本内核)将候选主键分配给Python工作进程。工作人员独立地从数据库中读取，通过ORM层实现候选人，然后在他们上面执行标记功能。标签被返回给主进程，主进程通过ORM层保存它们。由于表级锁定，在主服务器上收集标签比让工人直接写入数据库更有效。Snorkel包含一个Spark集成层，允许在集群中运行标记函数。一旦候选集被缓存为Spark数据帧，只需要关闭标签功能和产生的标签需要与工人沟通。这在Snorkel的迭代工作流中特别有用。跨集群分布大型非结构化数据集的成本相对较高，但只需执行一次。然后，随着用户改进他们的标签功能，他们可以有效地重新运行。</p>
<blockquote>
<p>如果连接到一个关系型数据库提供simultaneous connections, e.g., PostgreSQL,then the masterprocess (usually the notebook kernel) distributes the primary keys of the candidates to be labeled to Python worker processes. The workers independently read from the database to materialize the candidates via the ORM layer, then executethe labeling functions over them. The labels are returned to the master process which persists them via the ORM layer.Collecting the labels at the master is more efficient than having workers write directly to the database, due to table-level locking.Snorkel includes a Spark integration layer, enabling labeling functions to be run across a cluster. Once the set of candidates is cached as a Spark data frame, only the closure of the labeling functions and the resulting labels need to be communicated to and from the workers. This is particularly  helpful in Snorkel’s iterative workflow. Distributing a large unstructured data set across a cluster is relatively expensive,but only has to be performed once. Then, as users refine their labeling functions, they can be rerun efficiently。</p>
</blockquote>
<h4 id="2-2-Generative-model"><a href="#2-2-Generative-model" class="headerlink" title="2.2 Generative model"></a>2.2 Generative model</h4><p>The core operation of Snorkel is modeling and integrating the noisy signals provided by a set of labeling functions.</p>
<p>我们将数据点的真实类标签rrue class label 建模为概率模型中的隐变量。在最简单的情况下，每个labeling functions都看成是独立的投票，错误labeling是和其他labeling functions不相关的。这将标注函数的投票的生成模型定义为 noisy signals about the true label.</p>
<p>对上面简单的改进，我们还可以对标记函数之间的统计依赖性tatistical dependencies进行建模，以提高预测性能。如果两个标记函数express similar heuristics，我们可以在模型中包括这种依赖性，从而避免出现“重复计算double counting”问题。我们观察到这种成对的相关性是最常见的，因此我们在本文中重点介绍（尽管处理高阶相关性很简单）。我们将我们的结构学习方法[5]用于这个生成模型，以选择a set C of标记函数对（j，k）来建模成 相关模型model as correlated。 </p>
<p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/Snorkel rapid training data creation with weak supervision/image-20200719113151286.png" alt="image-20200719113151286" style="zoom:80%;" /></p>
<p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/Snorkel rapid training data creation with weak supervision/image-20200719113207933.png" alt="image-20200719113207933" style="zoom:80%;" /></p>
<p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/Snorkel rapid training data creation with weak supervision/image-20200719114152928.png" alt="image-20200719114152928" style="zoom:80%;" /></p>
<p>​    因子图建模，包括多种relation的因子函数，对LFs给出的标注向量做最大似然估计，采用对和真实标注—隐变量的边际概率</p>
<h4 id="2-3-Discriminative-model"><a href="#2-3-Discriminative-model" class="headerlink" title="2.3 Discriminative model"></a>2.3 Discriminative model</h4><p>Snorkel的最终目标是训练一种模型，该模型可以对标注函数中表达的信息进行泛化。</p>
<p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/Snorkel rapid training data creation with weak supervision/image-20200719115359359.png" alt="image-20200719115359359" style="zoom:80%;" /></p>
<p>正式分析表明，随着我们增加未标记数据的数量，使用Snorkel训练的判别模型的泛化误差将以与传统监督学习模型对其他手工标记数据相同的渐近率降低[43]，从而使我们能够通过以下方式提高预测性能：添加更多未标记的数据。从直觉上讲，此属性成立是因为随着提供更多数据，判别模型会看到更多与标记功能中编码的启发式同时出现的功能。</p>
<p><strong><em>Example 2.5</em></strong>“  Myasthenia gravis presenting as weakness after magnesium administration.”  我们开发的33个标注函数中没有一个对$Causes(magnesium,myasthenia gravis)$ 投票, 都abstain</p>
<p> 然而，经过Snorkel概率训练标签probabilistic training labels训练的深度神经网络可以正确地将其识别为正确的提及true mention。Snorkel为流行的机器学习库（如TensorFlow [1]）提供了连接器，使用户可以利用商品模型，例如不需要人工设计特征的深度神经网络。并在各种任务中具有强大的预测性能</p>
<h3 id="3-Weak-supervision-trade-offs"><a href="#3-Weak-supervision-trade-offs" class="headerlink" title="3 Weak supervision trade-offs"></a>3 Weak supervision trade-offs</h3><p>我们研究了一个基本问题，即何时以及以何种复杂程度期望Snorkel的生成模型能够最大程度地提高预测性能。了解这些性能机制可以帮助指导用户，并在预测性能和速度之间进行权衡。我们将这个空间分为两个部分：首先，通过分析何时可以通过未加权多数票unweighted majority vote来近似生成模型；其次，通过自动选择要建模的相关结构的复杂度。然后，我们引入了一个基于规则的两阶段优化器，以支持快速的开发周期。</p>
<h4 id="3-1-Modeling-accuracies"><a href="#3-1-Modeling-accuracies" class="headerlink" title="3.1 Modeling accuracies"></a>3.1 Modeling accuracies</h4><h4 id="3-1-1-Trade-off-space"><a href="#3-1-1-Trade-off-space" class="headerlink" title="3.1.1 Trade-off space"></a>3.1.1 Trade-off space</h4><p>considering the label density标签密度 $d_{\varLambda} $of the label matrix${\varLambda} $定义为每个数据点非弃权标签的平均数量。当标签密度低时，标签的稀疏性意味着即使对标签功能进行最佳加权，与he majority vote 比较也很有限。 It is the <strong>middle density regime</strong> where we expect to most benefit from applying the generative model.</p>
<p>我们以labeling 的 true accuracies来度量the benefit of weighting the labeling functions 对比an unweighted majority vote——<strong>true accuracies</strong>是指the predictions of a perfectly estimated generative model</p>
<p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/Snorkel rapid training data creation with weak supervision/image-20200719155650788.png" alt="image-20200719155650788" style="zoom:80%;" /></p>
<p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/Snorkel rapid training data creation with weak supervision/image-20200719161855442.png" alt="image-20200719161855442" style="zoom:80%;" /></p>
<p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/Snorkel rapid training data creation with weak supervision/image-20200719162034944.png" alt="image-20200719162034944" style="zoom:80%;" /></p>
<p><strong>Low Label Density</strong>——在这种稀疏设置中，很少有数据点具有不止一个non-abstaining 标签。只有少数具有多个冲突标签——证明此情况下的upper bound</p>
<p><strong>High Label Density</strong>——大多数数据点具有大量标签——比如，我们可能会在极大量的众包环境中工作，或者在具有许多高覆盖率知识库的应用程序中进行远程监管——证明此情况下的upper bound</p>
<p><strong>Medium Label Density</strong>——在这种中间状态下，我们期望对标签函数的准确性进行建模将在预测性能方面带来最大的收益，因为我们将拥有许多带有少量不同标签函数的数据点。对于这样的点，估计的标记函数准确性会严重影响预测的标记。我们确实看到，使用仅包含准确度因子$φ_{i,j}^{Acc}$，j的独立生成模型，经验结果有所提高（表1）。此外，[43]中的保证确立了我们可以学习最优权重，从而获得最优优势。</p>
<h4 id="3-1-2-Automatically-choosing-a-modeling-strategy"><a href="#3-1-2-Automatically-choosing-a-modeling-strategy" class="headerlink" title="3.1.2 Automatically choosing a modeling strategy"></a>3.1.2 Automatically choosing a modeling strategy</h4><p>The bounds in the previous subsection imply that there are settings in which we should be able to safely <strong>skip</strong> modeling the labeling function accuracies, simply taking the unweighted majority vote instead. </p>
<p>整体标签密度 $d_{\varLambda} $在 given a user time-cost trade-off preference (characterized by the advantage tolerance parameterγ in Algorithm1)的精确度不足以确定目标转换点determine the transition points of interest</p>
<p>除了查看 $d_{\varLambda} $，相反，我们通过查看每个数据点的正负标签比率来开发最佳案例启发式方法。这种启发式方法可以作为true expectedadvantage的上限，因此，我们可以使用它来确定何时可以安全地跳过训练生成模型</p>
<p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/Snorkel rapid training data creation with weak supervision/image-20200719194640763.png" alt="image-20200719194640763" style="zoom:80%;" /></p>
<h4 id="3-2-Modeling-structure"><a href="#3-2-Modeling-structure" class="headerlink" title="3.2 Modeling structure"></a>3.2 Modeling structure</h4><p>在本小节中，我们将考虑在独立模型之外建模其他统计结构。我们研究了预测性能和计算成本之间的折衷，并描述了如何在此折衷空间中自动选择一个好点。</p>
<p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/Snorkel rapid training data creation with weak supervision/image-20200719232014913.png" alt="image-20200719232014913" style="zoom:80%;" /></p>
<p>消除这种依赖性很重要，因为它们会影响我们对真实标签的估计。考虑一种极端的情况，其中不考虑依赖项会造成灾难性的后果：</p>
<p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/Snorkel rapid training data creation with weak supervision/image-20200719234737567.png" alt="image-20200719234737567" style="zoom:80%;" /></p>
<p><strong>3.2.1 Trade-off space</strong></p>
<p>我们研究了预测性能与由此引起的计算成本之间的取舍。我们发现，通常存在一个“肘点”，超过这个“肘点”“elbow point”，选择的相关数he number of correlations selected（从而导致计算成本）爆炸，并且该点是预测性能和计算时间之间的安全折衷点</p>
<p><em>Predictive Performance</em></p>
<p>在一个极端情况下，很大的 $\varepsilon$ 值将不会在生成模型中包含任何相关性，从而使其与独立模型相同。减少，将添加相关性。</p>
<p>因为编写的标注函数存在大量冗余</p>
<p><em>Computational Cost</em></p>
<p>计算成本与模型复杂度相关。在Snorkel中进行的学习是通过Gibbs采样器完成的，对其他相关建模的开销在相关数量上是线性的</p>
<h5 id="3-2-2-Automatically-choosing-a-model"><a href="#3-2-2-Automatically-choosing-a-model" class="headerlink" title="3.2.2 Automatically choosing a model"></a>3.2.2 Automatically choosing a model</h5><p>我们力求仅使用标注函数的输出 $\Lambda$ 来自动找到 $\varepsilon$ 在预测性能和计算成本之间进行权衡。将$\varepsilon$ 设置在“elbow point”是安全的权衡，在预测性能最终下降（中间）的情况下，肘点也会选择相对较少的相关性，从而使F1点提高0.7，并避免过拟合。</p>
<p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/Snorkel rapid training data creation with weak supervision/image-20200720103418571.png" alt="image-20200720103418571" style="zoom:80%;" /></p>
<p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/Snorkel rapid training data creation with weak supervision/image-20200720103544501.png" alt="image-20200720103544501" style="zoom:80%;" /></p>
<h3 id="4-Evaluation"><a href="#4-Evaluation" class="headerlink" title="4 Evaluation"></a>4 Evaluation</h3><h4 id="4-1-Applications"><a href="#4-1-Applications" class="headerlink" title="4.1 Applications"></a>4.1 Applications</h4><p><em>Discriminative Models</em>  </p>
<p>为了更好地利用powerful, open source machine learning tools ，Snorkel为具有标准损失函数的任何判别模型创建概率训练标签。</p>
<p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/Snorkel rapid training data creation with weak supervision/image-20200720104330658.png" alt="image-20200720104330658" style="zoom:80%;" /></p>
<p>测试的结论：</p>
<p>判别模型的适用范围超出了标记函数中编码的启发式方法</p>
<p><em>DataSet Details</em><br><div class="group-picture"><div class="group-picture-container"><div class="group-picture-row"><div class="group-picture-column" style="width: 50%;"><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/Snorkel rapid training data creation with weak supervision/image-20200720104516116.png" alt="image-20200720104516116" style="zoom:67%;" /></div><div class="group-picture-column" style="width: 50%;"><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/Snorkel rapid training data creation with weak supervision/image-20200720104532189.png" alt="image-20200720104532189" style="zoom:67%;" /></div></div></div></div></p>
<h5 id="4-1-1-Relation-extraction-from-text"><a href="#4-1-1-Relation-extraction-from-text" class="headerlink" title="4.1.1 Relation extraction from text"></a>4.1.1 Relation extraction from text</h5><p><em>Scientific Articles (Chem)</em></p>
<p><em>Electronic Health Records (EHR)</em></p>
<p><em>Chemical–Disease Relations (CDR)</em></p>
<p><em>Spouses</em></p>
<p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/Snorkel rapid training data creation with weak supervision/image-20200720105152138.png" alt="image-20200720105152138" style="zoom:80%;" /></p>
<h5 id="4-1-2-Cross-modal-images-and-crowdsourcing"><a href="#4-1-2-Cross-modal-images-and-crowdsourcing" class="headerlink" title="4.1.2 Cross-modal: images and crowdsourcing"></a>4.1.2 Cross-modal: images and crowdsourcing</h5><p>我们在一个数据模式（例如a text report, or the votes of crowd workers)）上编写标签函数，并使用结果标签来训练在完全独立的第二个模式（例如an image或tweet文本）上定义的分类器。</p>
<p><em>Abnormality Detection in Lung Radiographs (Rad)</em></p>
<p>在许多现实世界的放射学环境中，都有大量的图像数据存储库，带有相应的叙述性文本报告，但是有限的标签或没有标签可用于训练图像分类模型。在此应用程序中，我们与放射科医生合作，在文本放射学报告上编写了标签功能，并使用得到的标签来训练图像分类器以检测肺部X射线图像中的异常。我们使用了来自OpenI生物医学图像库15的公开可用数据集，该数据集由3,851个不同的放射学报告（由非结构化文本和医学主题词（MeSH）16代码组成）以及随附的X射线图像组成。</p>
<p><em>Crowdsourcing (Crowd)</em></p>
<p>训练了一个模型，使用来自Crowdflower的天气情感任务中的众包注释进行情感分析。在此任务中，要求贡献者对与天气相关的不明确推文的情感进行评级，并在五类情感中进行选择。20个贡献者给每个推文评分，但是由于任务困难和缺少人群工作者筛选，工作者标签上存在许多冲突。我们以标签功能代表了每个群众工作人员，展示了Snorkel吸收现有工作的能力</p>
<h5 id="4-1-5-Labeling-function-type-ablation"><a href="#4-1-5-Labeling-function-type-ablation" class="headerlink" title="4.1.5 Labeling function type ablation"></a>4.1.5 Labeling function type ablation</h5><p>研究了不同类型的标注函数对最终预测性能的影响</p>
<ul>
<li>Text Patterns：Basic word, phrase, and regular expression labeling functions.</li>
<li>Distant Supervision：External knowledge bases mapped to candidates, either directly or filtered by a heuristic.</li>
<li>Structure-Based： Labeling functions expressing heuristics over the context hierarchy, e.g., reasoning about position in the document or relative to other candidates.</li>
</ul>
<p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/Snorkel rapid training data creation with weak supervision/image-20200720115626636.png" alt="image-20200720115626636" style="zoom:80%;" /></p>
<h3 id="5-Extensions-and-next-steps"><a href="#5-Extensions-and-next-steps" class="headerlink" title="5 Extensions and next steps"></a>5 Extensions and next steps</h3><h4 id="5-1-Extensions-for-real-world-deployments"><a href="#5-1-Extensions-for-real-world-deployments" class="headerlink" title="5.1 Extensions for real-world deployments"></a>5.1 Extensions for real-world deployments</h4><h4 id="5-2-Ascending-the-code-as-supervision-stack"><a href="#5-2-Ascending-the-code-as-supervision-stack" class="headerlink" title="5.2 Ascending the code-as-supervision stack"></a>5.2 Ascending the code-as-supervision stack</h4><p>由于难以直接在图像或视频数据上编写标签功能，先使用无监督方法在原始数据上先计算a set of features或primitives，然后在这些 building blocks上编写标注函数[58]。例如，如果目标是标记骑乘自行车的实例，则我们可以先运行一种现成的预训练算法，将 bounding boxes 放置在人和自行车周围，然后在这些边界框的 dimensions 或relative locations上编写标记函数。</p>
<p>在医学成像任务中，解剖学分割蒙版 anatomical segmentation masks 为写入标记函数提供了相似的直观语义抽象。例如，在来自UK Biobank的大量心脏MRI视频中，创建了主动脉的分割使心脏病专家能够定义标签功能来识别罕见的主动脉瓣畸形[17]。</p>
<p>甚至更高级别的界面是自然语言。BabbleLabble项目[20]接受数据点的自然语言解释 natural language explanations of data points，然后使用语义解析器 semantic parsers 解析这些explanations 到labeling functions.。这样，没有编程知识的用户仅通过解释数据点为何具有特定标签的原因就具有编写标注函数的能力。另一种相关方法是使用程序合成技术，结合少量标记的数据点，以自动生成标记功能</p>
]]></content>
      <categories>
        <category>Training Data Generation</category>
        <category>Snorkel</category>
      </categories>
      <tags>
        <tag>snorkel</tag>
      </tags>
  </entry>
  <entry>
    <title>Automatically Labeled Data Generation for Large Scale Event Extraction</title>
    <url>/blog/2020/07/15/Automatically%20Labeled%20Data%20Generation%20for%20Large%20Scale%20Event%20Extraction/</url>
    <content><![CDATA[<a id="more"></a>
<h3 id="『Automatically-Labeled-Data-Generation-for-Large-Scale-Event-Extraction』阅读笔记"><a href="#『Automatically-Labeled-Data-Generation-for-Large-Scale-Event-Extraction』阅读笔记" class="headerlink" title="『Automatically Labeled Data Generation for Large Scale Event Extraction』阅读笔记"></a>『Automatically Labeled Data Generation for Large Scale Event Extraction』阅读笔记</h3><ol>
<li>原本远程监督的三元组表示的是两个entity和两者间的relation，因此可以用三元组在大型语料库中提取包含这两个实体的句子，作为关系提取的训练数据。本文将远程监督用于事件提取。将argument 和 event 看作relation extraction中的两个”entity”，则可以将event extraction看作是多种或复杂multiple  or  complicated的关系数据relational  data，也就可以像DS for RE一样使用event  instance和argument来自动生成训练数据以进行argument identification(<strong>role</strong>)</li>
<li>因为根据ACE2005，一个event instance是表示为a trigger word，所以文中也将event detction转换成 trigger detection问题</li>
<li>做了两个关于 event instance、argument和 trigger(文中直接用verb) 的假设</li>
<li>For example, compared with arguments like time, location and so on, spouses are key arguments in a marriage event. We call these arguments as key arguments。用<strong>Freebase</strong>来 figure out <strong>key arguments</strong> of an event使用key arguments来标记事件并找出触发词trigger words</li>
<li>因为一个event type 的所有argument被包含在一个sentence中的情况很少，因此选出一个key argument认为句子中如果出现这个key argument则这个句子很可能在表达这个key argument代表的event type，因此可以在这个sentence中提取trigger。设计了 KR(key rate)找key argument即一个argument在这个event type 的所有instance中出现的频率乘上与其他event type不相关的程度。用 key argument 来 label sentence，在label过的sentence中找trigger，设计了TR(trigger rate)来找 trigger (类似于 TF-IDF中的思想)</li>
<li><strong>FrameNet</strong>——被用来 noisy trigger words and expand more triggers。因为只用verb作为trigger，则像marriage这种名词trigger就不包含，因此引入 linguistic KG FrameNet。计算framebass中event type下所有words 的word embedding的均值和framnet中的frame下的LUs的word embedding，比较两个向量的相似度来作为map的依据。如果map到framenet的frame后不包含verb trigger则作为noise去掉，如果words中的nounswith high confidence inthe mapped frame to expand trigger lexicon。</li>
<li>SDS 软远程监督：如果文档中的句子包含一个event type 的所有key argument和一个trigger，则用这个句子生成训练数据。</li>
<li>event extraction过程：生成训练数据后，做监督训练，使用的是《Event Extraction via Dynamic Multi-Pooling Convolutional Neural Networks》中的网络模型提取词汇级和句子级的特征，两个任务：对event进行分类，以及句子中包含的word做 argument role分类</li>
<li>因为远程监督的noise影响，为了减少错误标签的影响，使用Multi-instance Learning训练，目标函数的定义也是以instance bag</li>
</ol>
<h3 id="专有名词"><a href="#专有名词" class="headerlink" title="专有名词"></a>专有名词</h3><ol>
<li><p><strong>KBP——Knowledge Base Population</strong> KBP 公开任务的研究目标，是让机器可以自动从自然书写的非结构化文本中抽取实体，以及实体之间的关系。</p>
<p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/Automatically Labeled Data Generation for Large Scale Event Extraction//image-20200813101927421.png" alt="image-20200813101927421" style="zoom:80%;" /></p>
</li>
<li><p><strong>Distant Supervision远程监督（DS）</strong>：our automatically labeled data  face  a  noise  problem,  which  is  a  intrinsic problem  of  using  DS  to  construct  training  data。</p>
</li>
<li><p>DS for <strong>标记 Relation Extraction（RE）的training data</strong></p>
</li>
<li><p><strong>知识库——knowledge bases </strong>  </p>
</li>
<li><p>Dynamic Multi-pooling Convolutional Neural Network-s  <strong>(DMCNNs)</strong>： is the best reported CNN-based model for event extraction (Chen et al., 2015) by using human-annotated training data. </p>
</li>
<li><p><strong>Multi-instance Learning (MIL)</strong> 多实例学习</p>
<p><a href="https://zhuanlan.zhihu.com/p/40812750">知乎参考1</a></p>
<p><a href="http://www.lamda.nju.edu.cn/CH.Data.ashx?AspxAutoDetectCookieSupport=1#code">南大周志华教授 miVLAD and miFV,</a></p>
</li>
</ol>
<p><strong><a href="https://github.com/acl2017submission/event-data">Event Data</a></strong></p>
<h3 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h3><p>​    用于诸如ACE之类任务的事件提取的现代模型都是基于监督学习的，该学习是从少量<strong>手工标记</strong>small hand-labeled的数据中进行的。<strong>手工标记</strong>small hand-labeled的数据————expensive，low  coverage of event types， limited in size——所以难以提取large scale of events  for <strong>KBP</strong></p>
<p>​    因此，为了<strong>解决数据标记问题</strong>，我们提议通过使用world knowledge and linguistic knowledge语言知识 automatically label training data，which can detect key arguments and trigger words for each event type and employ  them  to  label  events  in  texts  auto matically.</p>
<p>​    而且我们的自动标记数据可以与人工标记数据结合在一起，然后提高从这些数据中学到的模型的性能</p>
<h3 id="1-简介"><a href="#1-简介" class="headerlink" title="1  简介"></a>1  简介</h3><ol>
<li><p>事件提取：检测和typing events，extracting  arguments  with  different  <strong>roles</strong>(Argument  Identification)</p>
<p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/Automatically Labeled Data Generation for Large Scale Event Extraction//image-20200713204833668.png" alt="image-20200713204833668"></p>
</li>
<li><p>到目前为止，大多数方法使用详尽的注释数据——manually labeling training data cost high、预定义事件类型的覆盖率低。</p>
</li>
<li><p>因此，对于提取大规模事件，尤其是在开放域场景open domain scenarios，如何自动高效地生成足够的训练数据是一个重要的问题。</p>
</li>
<li><p><strong>本文旨在自动为EE生成训练数据，其中包括labeling triggers，event types，arguments及其role(Argument  Identification)。</strong></p>
</li>
<li><p>事实证明，<strong>Distant Supervision远程监督（DS）</strong>的最近被证明可有效地<strong>标记 Relation Extraction（RE）的training data</strong>，<strong>Relation Extraction（RE）</strong>的目的是<strong>predict 两个命名实体的语义关系semantics relation</strong> between  pairs  of  entities。$(entity_1,relation,entity_2)$——————<strong>DS for RE假设如果两个实体在已知的知识库中有关系have  a  relationship  in a known knowledge base，则所有提及这两个实体的句子将以某种方式表达这种关系。</strong></p>
</li>
<li><p>当用DS for RE来做EE时，遇到以下的挑战</p>
<p> <strong>Triggers are not given out in existing knowledge bases</strong>:EE aims to detect an event instance of a specific type and extract their arguments and roles, formulated as$ (event instance,event type;role1,argument_1;role_2,argument_2;…;role_n,argument_n)$——<strong>这可以看作是多种或复杂multiple  or  complicated的关系数据relational  data</strong>。在以an  example  of spouse of relation between Barack Obama and Michelle Obama, </p>
<p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/Automatically Labeled Data Generation for Large Scale Event Extraction//image-20200713214520119.png" alt="image-20200713214520119"></p>
<p>中，<strong>DS  for  RE</strong>  uses  <strong>two  entities</strong>  to  automatically  <strong>label  training  data</strong>。像左边的图，中间的是event  instance，周围的矩形是arguments of the event instance，边指的是 the role of the argument——————看起来可以像DS for RE一样使用event  instance和argument来自动生成训练数据以进行argument identification(<strong>role</strong>)。————但是event instance是在text中隐式地提及，只是 a virtual node in existing knowledge bases————in  Freebase，前面提到的婚姻事件实例表示为$m.02nqglv$，所以不能直接拿event  instance  and  an  argumen来label  back in  sentences——————在ACE中，一个event instance是表示为a trigger word，最清楚地代表句子中事件发生的main word————受ACE启发，可以用trigger word来表示event instance，像$married$作为event instance  $people.marriage$  的trigger——但是，现有知识库 existing knowledgebases中未给出触发器</p>
</li>
<li><p>为了解决trigger  missing  problem，我们需要在使用distant supervision来自动标记event argument之前<strong>先去找trigger words</strong>————根据上面<strong>DS for RE</strong>的假设，</p>
<p><strong>下面做了很多关于语言学上的假设：</strong></p>
<p>a.   我们自然地假设<strong>a  sentence  contains all arguments of an event in the knowledge base tend to express that event, and the verbs occur in these sentences tend to evoke引发 this type of events</strong></p>
<p>b.   However,<strong>arguments for a specific event instance are usually mentioned in multiple sentences.</strong> ——所以仅仅用知识库中所有的arguments来标注句子只能生成很少的training data——只有很少的event instances能在一个sentence中找到所有的argument<img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/Automatically Labeled Data Generation for Large Scale Event Extraction//image-20200714161509083.png" alt="image-20200714161509083"></p>
</li>
<li><p>因此我们提出用<strong>world knowledge(Freebase)</strong>和<strong>linguistic knowledge (FrameNet)</strong>来自动<strong>generate labeled data</strong> for <strong>large scale EE</strong>。 </p>
<p><strong>a.</strong>  首先，我们提出了一种使用Freebase为每个事件类型优先化参数prioritize arguments并选择key或代表参数(representative arguments)（请参阅第3.1节中的详细信息）</p>
<p><strong>b.</strong>  其次，我们仅使用key arguments来标记事件并找出触发词trigger words</p>
<p><strong>c.</strong>  第三，外部语言知识资源external linguistic knowledge  resource——FrameNet——被用来filter <strong>noisy trigger words</strong> and <strong>expand more triggers</strong></p>
<p><strong>d.</strong>  之后，我们为EE提出了一个<strong>软远程监督(SDS)</strong>，以自动标记训练数据————SDS假设了<strong>Freebase</strong>中任何包含all key arguments和一个 corresponding trigger word的句子都可能以某种方式表达该事件，该句子中出现的arguments可能在该事件中play the corresponding roles </p>
<p><strong>e.</strong>   我们通过手动和自动评估方法来评估自动标记的培训数据的质量</p>
<p><strong>f.</strong>    we employ a <strong>CNN-based  EE  approach</strong>  with  <strong>multi-instance  learning</strong>  在自动标记的data上作为baseline</p>
</li>
</ol>
<h4 id="做出的三大贡献"><a href="#做出的三大贡献" class="headerlink" title="做出的三大贡献"></a>做出的三大贡献</h4><ol>
<li>the first work to automatically label data for large scale EE via world  knowledge  and  linguistic  knowledge</li>
<li>用Freebase来 figure out <strong>key arguments</strong> of an event，并使用它们来自动检测events和相应的corresponding trigger words。并且用FrameNet来过滤noisy triggers并expand more triggers.</li>
<li>大规模自动标记数据的质量有保证，可以扩充传统的人工注释数据，从而可以显着改善the extraction performance</li>
</ol>
<h3 id="2-背景"><a href="#2-背景" class="headerlink" title="2   背景"></a>2   背景</h3><ol>
<li>使用Freebase作为包含event  instance的world  knowledge，以及使用FrameNet作为包含trigger information的linguistic knowledge。————Wikipedia中文章用作要标记的非结构化文本，</li>
<li><strong>Freebase</strong>——是semantic  knowledge  base——利用复合值类型compound  value  type， CVTs，来将多个值合并为一个值——$people.marriage$  是CVT值中的一个type——这个type有很多的instance，比如 the marriage of $Barack Obama$ and $Michelle Obama$ is numbered as $m.02nqglv$ .  $Spouse,from,to and  location  of   ceremony$ 是 $people.marriage$ CVT type的<strong>roles</strong><div class="group-picture"><div class="group-picture-container"><div class="group-picture-row"><div class="group-picture-column" style="width: 50%;"><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/Automatically Labeled Data Generation for Large Scale Event Extraction//image-20200714173434756.png" alt="" style="zoom:60%;" /></div><div class="group-picture-column" style="width: 50%;"><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/Automatically Labeled Data Generation for Large Scale Event Extraction//image-20200714173530661.png" alt="" style="zoom:60%;" /></div></div></div></div>
</li>
</ol>
<h3 id="3-Method-of-Generating-Training-Data"><a href="#3-Method-of-Generating-Training-Data" class="headerlink" title="3     Method of Generating Training Data"></a>3     Method of Generating Training Data</h3><p><strong>Architecture</strong><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/Automatically Labeled Data Generation for Large Scale Event Extraction//image-20200714174457629.png" alt="image-20200714174457629"></p>
<h4 id="3-1-Key-Argument-Detection"><a href="#3-1-Key-Argument-Detection" class="headerlink" title="3.1  Key Argument Detection"></a>3.1  Key Argument Detection</h4><p><strong>总结：</strong>prioritizes 每个event type 的arguments，为each type of event选择key arguments——<strong>如何通过FreeBase为每个event type找到key arguments</strong></p>
<ol>
<li><p><strong>point：</strong>arguments of a type of event play different roles——在区分不同类型的events时key arguments能作为线索——use <strong>Key  Rate(KR)</strong>  to estimate  the  <strong>importance  of  an argument</strong> to a type of event，由两个因素：角色显著性(Role Saliency)和事件相关性(Event Relevance)</p>
</li>
<li><p><strong>角色显著性(Role Saliency)</strong>: 什么是显著性Saliency：If we tend to <strong>use an argument</strong> to <strong>distinguish</strong> one <strong>event instance</strong> from other instances of a given <strong>event type</strong>, this argument will play <strong>a salient role</strong> in the given event type.</p>
<p>定义：<img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/Automatically Labeled Data Generation for Large Scale Event Extraction//image-20200714194641930.png" alt="image-20200714194641930"></p>
<p>其中$RS_{ij}$是第 i 个argument对第 j 个event type的role saliency值。$Count(A_i,ET_j)$ 是$arguement_i$ 在Freebase的$eventType_j$的所有实例中出现的次数，$Count(ET_j)$是Freebase中$eventType_j$的所有实例个数</p>
<p>(候选的argument集如何选出的？)</p>
</li>
<li><p><strong>事件相关性(Event Relevance)</strong>：反映一个argument 能被用来区分不同event type的能力</p>
<p>定义：<img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/Automatically Labeled Data Generation for Large Scale Event Extraction//image-20200714195554100.png" alt="image-20200714195554100"></p>
<p>$Sum(ET)$是在Freebase中所有event types的个数和，$Count(ETC_i)$是所有包含第 i 个argument的event type的个数。</p>
</li>
<li><p><strong>Key  Rate(KR)</strong>的计算是</p>
<p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/Automatically Labeled Data Generation for Large Scale Event Extraction//image-20200714200858515.png" alt="image-20200714200858515"></p>
</li>
<li><p>同<strong>KR</strong>值排序，选择前K个arguments作为key arguments。</p>
</li>
</ol>
<h4 id="3-2-Trigger-Word-Detection"><a href="#3-2-Trigger-Word-Detection" class="headerlink" title="3.2  Trigger Word Detection"></a>3.2  Trigger Word Detection</h4><p><strong>总结：</strong>使用key arguments来label可以初步表达事件的句子，然后detect  triggers</p>
<ol>
<li><p><strong>通过key  arguments对在Wikipedia中可能表达event的句子进行label。</strong></p>
<p>使用<strong>Standford CoreNLP tool</strong>将原始的Wikipedia文本转换为句子序列并附加 NLP annotation (POS tag, NER tag)，然后我们把包含一个Freebase中event实例所有arguments的句子选择出来，这个句子我i们认为是能够表达corresponding events. 最后，我们用这些labeled句子来detect triggers</p>
</li>
<li><p>在句子中，一个verb更可能意味着一个event的出现(AES中，60%的event的trigger是verbs)——所以直观地说，在labeled sentences中一个verb出现的次数多于另外的verb，则这个verb更可能是trigger；但是像$is$这些verb作为trigger 的probability 要小。————这里用到$Trigger Candidate Frequency(TCF)$和$TriggerEvent Type Frequency(TETF)$</p>
<p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/Automatically Labeled Data Generation for Large Scale Event Extraction//image-20200714202823550.png" alt="image-20200714202823550"><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/Automatically Labeled Data Generation for Large Scale Event Extraction//image-20200714202832708.png" alt="image-20200714202832708"><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/Automatically Labeled Data Generation for Large Scale Event Extraction//image-20200714202846272.png" alt="image-20200714202846272"></p>
<p>其中，$TR_{ij}$是第 i 个verb对第 j 个event type的trigger rate，$Count(V_i,ETS_j)$ 是表达第 j 个event type并且包含第 i 个verb的句子的个数，$Count(ETS_j)$是表达第 j 个event type的句子个数，$Count(ETI_i)$是number of event types, which have  the  labeled  sentences  containing i-th  verb————最后，我们选取有高TR值的verbs作为event type的trigger words</p>
</li>
</ol>
<h4 id="3-3-Trigger-Word-Filtering-and-Expansion"><a href="#3-3-Trigger-Word-Filtering-and-Expansion" class="headerlink" title="3.3 Trigger Word Filtering and Expansion"></a>3.3 Trigger Word Filtering and Expansion</h4><p><strong>总结：</strong>使用<strong>linguistic resource——FrameNet to filter noisy verbal triggers and expand nominal triggers</strong></p>
<p>通过上面<strong>3.2</strong>步得到初始的trigger lexicon，但是这个 lexicon is noisy 并且只包含动词的 triggers，名词 triggers是缺失的，像marriage等。——为什么不用<strong>TR值</strong>来找？，因为一个句子中名词的数量通常大于动词。</p>
<ol>
<li>因为<strong>word embedding </strong>成功捕捉word的语义，使用word embedding来把Freebase中的event映射到 FrameNet中——将 $i-th$ Freebase event type中的所有词的word embedding取平均记为$e_i$ ， 记 k-th lexical units of j-th frame为$e_{j,k}$，选择具有最高$similarity(e_i,e_{k,j})$ 的frame为映射的frame<img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/Automatically Labeled Data Generation for Large Scale Event Extraction//image-20200714204542697.png" alt="image-20200714204542697"></li>
<li>we filter the verb, which is in initial verbal trigger word lexicon and not in the mapping frame. And we use nouns with high confidence in the mapped frame to expand trigger lexicon</li>
</ol>
<h4 id="3-4-Automatically-labeled-data-generation"><a href="#3-4-Automatically-labeled-data-generation" class="headerlink" title="3.4  Automatically labeled data generation"></a>3.4  Automatically labeled data generation</h4><p><strong>总结：</strong>uses a <strong>SDS</strong> 来生成训练数据</p>
<h3 id="4-Method-of-Event-Extraction"><a href="#4-Method-of-Event-Extraction" class="headerlink" title="4  Method of Event Extraction"></a>4  Method of Event Extraction</h3><p>event  extraction被分为两个阶段：第一步：<strong>Event  Classification</strong>： predict  whether  the  <strong>key  argument</strong>  candidates  participate  in  a  Freebase  event.——如果是，则进行第二步<strong>argument classification</strong>：assign arguments  to  the  event  and  identify  their  corresponding  roles为事件分配参数并确定其相应角色</p>
<p>用<strong>Distant Supervision远程监督（DS）</strong>存在的问题：自动标注的训练数据存在噪声————为了减轻<strong>wrong label problem</strong>，采用<strong>Multi-instance Learning (MIL)</strong> </p>
<p>用的模型是two similar Dynamic Multi-pooling Convolutional Neural Networks with Multi-instance Learning (DMCNNs-MIL)</p>
<p>以下阐述Multi-instance Learning (MIL) 用在<strong>argument classification</strong>的方法：</p>
<ol>
<li><p>定义在 DM-CNNs  训练的参数$\theta$</p>
</li>
<li><p>假设有T bags${M_1,M_2,…,M_T}$，the $i-th$ bag包含$q_i$ 个实例instance $M_i={m_i^1,m_i^2,…,m_i^{q_i}}$</p>
</li>
<li><p><strong>Multi-instance Learning (MIL)</strong>的目的是predict the labels of the unseen <strong>bags</strong></p>
</li>
<li><p><strong>什么是bag</strong>——we take <strong>sentences</strong> containing the same <strong>argument candidate</strong> and <strong>triggers</strong> with a <strong>same event type</strong> as a bag and all <strong>sentences</strong> in a bag  are  considered  independently. 我们采用包含相同自变量候选词和具有与bag相同的事件类型的触发器的句子，并且bag中的所有实例均认为是相互独立。</p>
</li>
<li><p>输入实例$m_i^j$，参数$\theta$ 的网络的输出向量$O$ ，其中向量第r的元素指的是 argument role r对应的值，这里求极大似然值$p(r|m_i^j,\theta)$ ，这个值由softmax operation over all <strong>argument role types</strong></p>
<p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/Automatically Labeled Data Generation for Large Scale Event Extraction//image-20200714230406990.png" alt="image-20200714230406990"></p>
</li>
<li><p><strong>区分 bags</strong>，目标函数using cross-entropy at the bag leve：</p>
<p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/Automatically Labeled Data Generation for Large Scale Event Extraction//image-20200714231727305.png" alt="image-20200714231727305"></p>
<p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/Automatically Labeled Data Generation for Large Scale Event Extraction//image-20200714231750908.png" alt="image-20200714231750908"></p>
</li>
</ol>
<h3 id="5-实验"><a href="#5-实验" class="headerlink" title="5    实验"></a>5    实验</h3><p>在21个选择的Freebase中的events上自动生成大量的标记数据，选择最大的5个event。</p>
<p>通过grid search将两个超参（我们的自动数据标签中的key arguments的数量和TR的值）分别设置为2和0.8</p>
<ol>
<li>先手动评估自动标记的数据。</li>
<li>基于ACE corpus对标记的数据进行自动评估</li>
<li>展示了DMCNNs-MIL在自动标记数据上的性能。</li>
</ol>
<p>以及讨论了key arguments数量对结果的影响</p>
]]></content>
      <categories>
        <category>Event Extraction</category>
        <category>Distant Supervision</category>
        <category>Training Data Generation</category>
      </categories>
      <tags>
        <tag>distant supervision</tag>
        <tag>knowledge bases</tag>
        <tag>Training Data Generation</tag>
        <tag>weak supervision</tag>
        <tag>Multi-instance Learning</tag>
        <tag>event extraction</tag>
        <tag>key arguments</tag>
        <tag>FrameNet</tag>
        <tag>Freebase</tag>
      </tags>
  </entry>
  <entry>
    <title>Event Detection with Neural Networks-- A Rigorous Empirical Evaluation</title>
    <url>/blog/2020/07/14/Event%20Detection%20with%20Neural%20Networks%20A%20Rigorous%20Empirical%20Evaluation/</url>
    <content><![CDATA[<a id="more"></a>
<h3 id="『Event-Detection-with-Neural-Networks—-A-Rigorous-Empirical-Evaluation』阅读笔记"><a href="#『Event-Detection-with-Neural-Networks—-A-Rigorous-Empirical-Evaluation』阅读笔记" class="headerlink" title="『Event Detection with Neural Networks— A Rigorous Empirical Evaluation』阅读笔记"></a>『Event Detection with Neural Networks— A Rigorous Empirical Evaluation』阅读笔记</h3><ol>
<li>文章仅包含了对 GRU输出 word 的 hidden state向量 ht 的具体改进，其余的设置需要看 JRNN及改进模型的文章[Joint Event Extraction via Recurrent Neural Networks] [Joint Extraction of Events and Entities within a Document Context]</li>
<li>Event detection is often framed as a multi-class classification problem</li>
<li>本文借助DAG-GRU建模语法信息<strong>syntactic  information</strong>(当前大多数神经网络模型都忽略了文本中的syntactic relationships)与时间结构temporal  structure 结合在一起。单纯的GRU不能建模远距离的关系（两个token间远距离存在一条边）,某种程度上是一种图结构。本文借助Attention解决某个token上存在多条边的问题</li>
<li>另一个贡献是“<strong>对系统性能对模型初始化的敏感性进行了实证研究</strong>”</li>
<li>word embedding 方法 用的 EMLo</li>
</ol>
<hr>
<h3 id="DAG-GRU-model"><a href="#DAG-GRU-model" class="headerlink" title="DAG-GRU model"></a>DAG-GRU model</h3><p>The standard GRU model works as follows:</p>
<p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/Event Detection with Neural Networks A Rigorous Empirical Evaluation/image/image-20200309164528918.png" alt="image-20200309164528918"></p>
<p><strong>contribution:</strong> <strong>incorporates syntactic information through dependency parse relationships</strong>,using <strong>attention</strong> to <strong>combine syntactic and temporal information.</strong> </p>
<p>Think of the standard GRU as a graph structure. The standard GRU edges are included as <em>(t, t -1</em>, <em>temporal)</em>.</p>
<p>can’t understand this part….</p>
<p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/Event Detection with Neural Networks A Rigorous Empirical Evaluation/image/image-20200309202056357.png" alt="image-20200309202056357" style="zoom:80%;" /></p>
<p>dependency relationship will produce a  dependency tree according to the rules.</p>
<p>By adding dependency relationship to GRU, the model may have problem in implementing back-propagation as it requires a directed acyclic graph(DAG).  </p>
<p><strong>Solution</strong> split it into two parts</p>
<p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/Event Detection with Neural Networks A Rigorous Empirical Evaluation/image/image-20200309203031882.png" alt="image-20200309203031882" style="zoom:80%;" /> </p>
<p><strong>Attention mechanism:</strong></p>
<p>Used to combine the multiple hidden vectors.  Traditional GRU is much like the LSTM, choosing to memorize ht or forget ht-1, as the author says, only the temporal edges. For event detection, involve the  dependency edge can add syntactic relationships of the text into the model. Then using attention to compute the weight according to all the edges link to the node.</p>
<hr>
<h2 id="神经网络的事件检测：严格的经验评估——Event-Detection-with-Neural-Networks-A-Rigorous-Empirical-Evaluation"><a href="#神经网络的事件检测：严格的经验评估——Event-Detection-with-Neural-Networks-A-Rigorous-Empirical-Evaluation" class="headerlink" title="神经网络的事件检测：严格的经验评估——Event Detection with Neural Networks: A Rigorous Empirical Evaluation"></a>神经网络的事件检测：严格的经验评估——Event Detection with Neural Networks: A Rigorous Empirical Evaluation</h2><h3 id="专有名词"><a href="#专有名词" class="headerlink" title="专有名词"></a>专有名词</h3><ol>
<li><strong>event detection</strong>：包括识别表示事件的“触发”词 trigger 并将事件分类为精炼类型——事件检测是推断有关事件的更多语义信息inferring more semantic information about the event的必要的第一步，包括提取事件的参数arguments以及识别不同事件之间的时间和因果关系。</li>
<li><strong>ACE2005</strong>用于精确定义precise definition任务和数据以进行评估for the purposes of evaluation.  它由599个文档组成，分为529training、30development和40testing——这个分割是事实上的评估标准————但是测试集很小并且仅包含newswire documents，然而在ACE2005里包含multiple domains。————These two factors lead to a significant difference between the training and testing event type distribution训练集和测试集的事件类型分布差异——虽然已经有跨域 across domains比较方法的工作（Nguyen和Grishman，2015年）——<strong>variations  in  the training/test split including all the domains has not been studied.</strong> <strong><em>(同样也是使用数据集训练的神经网络的局限性)</em></strong></li>
<li>DAG——directed acyclic graph有向无环图</li>
</ol>
<h3 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h3><p>检测事件events detection并将其分类为预定义predefined  types的类型是从自然语言文本natural  language  texts中提取知识 knowledge  extraction的重要步骤。<strong>尽管神经网络模型通常领先于最新技术，但尚未严格研究不同体系结构different  architectures之间的性能差异</strong>  </p>
<p>本文中提出<strong>GRU-based mode</strong> 通过注意机制attention mechanism将句法信息syntactic  information与时间结构temporal  structure 结合在一起。</p>
<p>我们通过在ACE2005数据集的不同随机初始化和训练-验证-测试拆分下的经验评估表明，它与其他神经网络体系结构具有竞争力。</p>
<h3 id="1-简介"><a href="#1-简介" class="headerlink" title="1   简介"></a>1   简介</h3><ol>
<li><p><strong>问题：</strong></p>
<p>a.     当前大多数神经网络模型都忽略了文本中的句法关系——syntactic relationships。</p>
<p>b.   <strong>event detection任务的其中一个挑战是the  size  and  sparsity  of  this  dataset。</strong></p>
</li>
<li><p><strong>提出的模型：</strong>a new <strong>DAG-GRU</strong> architecture 通过具有依存解析关系dependency parse relationships 的文本的双向读取bidirectional reading of the text来捕获上下文和语法信息。通过注意力机制，通用化了GRU模型以<strong>在图上</strong>运行。</p>
</li>
<li><p>我们评估模型准确率的敏感性，通过随机性研究，改变训练和测试集的划分</p>
</li>
<li><p>鉴于与神经网络模型使用的和其他数据集相比训练集的数据量十分有限，并且许多高性能方法之间的裕度狭窄，因此需要考虑这些方法的不同初始化得到的不同效果。<strong>在本文中，我们对系统性能对模型初始化的敏感性进行了实证研究。</strong></p>
</li>
<li><p>所有方法的性能对随机模型初始化的敏感性比预期的要高。重要的是，基于标准训练-验证-测试拆分的性能的不同方法的排名有时与基于多个拆分的平均值的排名不同，这表明社区应远离单个拆分评估。</p>
</li>
</ol>
<h3 id="2-Related-work"><a href="#2-Related-work" class="headerlink" title="2   Related work"></a>2   Related work</h3><p>跟踪了Nguyen,  Kyunghyun的工作</p>
<p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/Event Detection with Neural Networks A Rigorous Empirical Evaluation/image-20200812162212731.png" alt="image-20200812162212731" style="zoom:80%;" /></p>
<p>在<a href="https://www.aaai.org/ocs/index.php/AAAI/AAAI18/paper/download/16222/16157">Jointly Extracting Event Triggers and Arguments by Dependency-Bridge RNN and Tensor-Based Argument Interaction</a> 中给出一下的结构，通过增加一个 控制依存关系的门信号，引入依存关系，对输入到当前节点的有关隐层向量 $h_i$ 进行加权平均 </p>
<p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/Event Detection with Neural Networks A Rigorous Empirical Evaluation/image-20200812215240862.png" alt="image-20200812215240862" style="zoom: 80%;" /></p>
<h3 id="3-DAG-GRU-Models"><a href="#3-DAG-GRU-Models" class="headerlink" title="3   DAG GRU Models"></a>3   DAG GRU Models</h3><ol>
<li><p><strong>event detection</strong>通常被建模成multi-class classification problem——<strong>所以event detection的目标</strong>是预测测试文档中每个单词的事件标签event label ，NIL if the word is not an event，一个句子是n个word $x_1, …x_n$ 的一个序列，每个word由一个k长度的向量表示</p>
</li>
<li><p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/Event Detection with Neural Networks A Rigorous Empirical Evaluation/image-20200812161254941.png" alt="image-20200812161254941" style="zoom:80%;" /></p>
</li>
<li><p>标准的GRU model是</p>
<p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/Event Detection with Neural Networks A Rigorous Empirical Evaluation/image-20200709224035732.png" alt="image-20200709224035732" style="zoom:67%;" /></p>
<p>GRU模型通过将word $x_t$ 的表示representation与前一个的hidden vector $h_{t-1}$ 结合起来，生成当前的word的hidden vector $h_{t}$ 。这样，$h_{t}$概括了the word and its prior context。</p>
</li>
<li><p>我们提出的DAG-GRU模型通过依存解析关系dependency  parse relationships 将句法信息syntactic  information  纳入其中，其实质类似于（Nguyenand Grishman，2018）和（Qian等人，2018————改进处在用attention机制把syntactic  information和temporal information结合之后与前一个$h_t$ 组合成新的hidden vector然后应用在标准GRU模型。</p>
</li>
<li><p>在标准依存关系表达中加入了parent-child orientation  </p>
<p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/Event Detection with Neural Networks A Rigorous Empirical Evaluation/image-20200812115313571.png" alt="image-20200812115313571" style="zoom:80%;" /></p>
</li>
<li><p>Each  relationship  表示成一条edge，$(t,t^\prime,e)$，即在index $t^\prime$ and $t^\prime$ 的word间有一条edge，类型是e——作为对比，标准的GRU的edge格式为 $(t,t-1,temporal)$——edge $e$  包含了dependency relationship 和 temporal 时间表达</p>
</li>
<li><p>因为边(dependency relationship)可能存在在任意两个word间，所以生成的图可能包含cycle。但是，而BPTT需要有向无环图（DAG）——因此将由时间temporal和依存边dependency  parse relationships <strong>E</strong>  组成的句子图被分为两个DAG：“正向” DAG $G_f$ 包含的edge $(t,t^\prime,e)$ 只有 $t^\prime&lt; t$ ；以及一个“反向” DAG $t^\prime&gt; t$ ————$t,t^\prime$ 间的依存关系包含 parent-child orientation e.g., nsubj-parent or nsubj-child for an subj(subject) relation。</p>
</li>
<li><p>注意力机制attention mechanism用于组合多个隐藏向量multiple hidden vectors————每个word都要经过system生成一个 $h_{a}$ 通过collecting and transforming所有先前的hidden  vectors 指向node t(当前这个word)，同一个hidden vertor有不同的edge type $e$ 就要多重复放入一次组成一个 input matrix，经过非线性的变换来形成矩阵 $D_t$ ——$D_t$ 和一个权重矩阵生成 $\alpha$ gives the attention, 分布加权在边缘的importance——————在标准的RNN模型下，the subject “members”将是遥不可及的，但是DAG-GRU模型可以通过依赖边缘和注意力集中在这一重要连接上via dependency edges and attention.</p>
<p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/Event Detection with Neural Networks A Rigorous Empirical Evaluation/image-20200710000624298.png" alt="image-20200710000624298" style="zoom: 67%;" /></p>
</li>
</ol>
<p><strong>DAG体现在哪</strong>？ 类似于</p>
<p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/Event Detection with Neural Networks A Rigorous Empirical Evaluation/image-20200812231236378.png" alt="image-20200812231236378"></p>
<p>这个模型，分成正反两个方向</p>
<p><strong>对GRU的应用不同在哪</strong>？经典的GRU输入间只有时序关系，现在在时序关系中加上句法关系</p>
<p>用 attention 结合 syntactic information(这里即dependency information) 和 temporal information，</p>
]]></content>
      <categories>
        <category>Event Extraction</category>
        <category>JRNN related model</category>
      </categories>
      <tags>
        <tag>GRU</tag>
        <tag>DAG-GRU</tag>
        <tag>syntactic relationships</tag>
        <tag>event detection</tag>
        <tag>JRNN</tag>
      </tags>
  </entry>
  <entry>
    <title>Liberal Event Extraction and Event Schema Induction</title>
    <url>/blog/2020/07/13/Liberal%20Event%20Extraction%20and%20Event%20Schema%20Induction/</url>
    <content><![CDATA[<a id="more"></a>
<h3 id="『Liberal-Event-Extraction-and-Event-Schema-Induction』阅读笔记"><a href="#『Liberal-Event-Extraction-and-Event-Schema-Induction』阅读笔记" class="headerlink" title="『Liberal Event Extraction and Event Schema Induction』阅读笔记"></a>『Liberal Event Extraction and Event Schema Induction』阅读笔记</h3><ol>
<li>抛开ACE2005等固有的event schema</li>
<li>以 distribution hypothesis 为依据，提出两个假设</li>
<li>以这两个假设为依据，将 event trigger 的上下文中包含的 argument和argument对应的role和type 作为给 trigger 进行聚类的依据(通过聚类给trigger生成type，聚的新类就产生新的trigger type，超越ACE这些固有schema)</li>
<li>对 argument的选取依据是 AMR meaning representation，trigger和其他word间的 semantic relation</li>
<li>word 的 embedding 都是用 一个 大型的语料库通过常见的 wod2vec得到的general embedding</li>
</ol>
<h4 id="code"><a href="#code" class="headerlink" title="code"></a><a href="https://github.com/HKUST-KnowComp/RINANTE">code</a></h4><p>文中训练过程和推理过程混在一起说，比较混乱</p>
<h3 id="专有名词"><a href="#专有名词" class="headerlink" title="专有名词"></a>专有名词</h3><h3 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h3><p>discover  event  schemas  from  any  input corpus  simultaneously</p>
<p>我们提出了一个全新的“自由的”EventExtraction范例，它可以同时从任何输入语料库中提取事件和发现事件模式。我们结合语义(如抽象意义表达)和分布语义来检测和表示事件结构，并采用联合类型框架来模拟抽取事件类型和论证角色，发现事件模式。对一般领域和特定领域的实践表明，该框架可以构建具有多种事件和参数角色类型的高质量模式，在手动定义的模式中涵盖了很大比例的事件类型和争论角色。我们展示了所发现模式的提取性能与从根据预定义事件类型标记的大量数据中训练出的监督模型相当。</p>
<h3 id="1-Introduction"><a href="#1-Introduction" class="headerlink" title="1  Introduction"></a>1  Introduction</h3><p>手动定义的事件模式缺点：Manually-defined event schemas often provide low coverage and fail to generalize to new domains.  </p>
<p>文章提出的pipelined system可以<strong>automatically discovers a complete event schema</strong>, customized for a specific input corpus. </p>
<p>文中举例：</p>
<p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/Liberal Event Extraction and Event Schema Induction/image-20200810115503699.png" alt="image-20200810115503699"></p>
<p>对提取出的event triggers and event arguments进行聚类，each cluster represents a type，聚类的依据是distributional similarity(类似于Brown Cluster ?)。关于distributional similarity的依据是一个假设：The distributional hypothesis (Harris, 1954) states that words often occurring in similar contexts tend to have similar meanings.  于是作者对<strong>trigger的type的判断</strong>做出了下面两个假设：</p>
<div class="group-picture"><div class="group-picture-container"><div class="group-picture-row"><div class="group-picture-column" style="width: 50%;"><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/Liberal Event Extraction and Event Schema Induction/image-20200810115939290.png" alt="image-20200810115939290" style="zoom:80%;" /></div><div class="group-picture-column" style="width: 50%;"><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/Liberal Event Extraction and Event Schema Induction/image-20200810175018536.png" alt="image-20200810175018536" style="zoom:80%;" /></div></div></div></div>
<ol>
<li>when we  simply  <strong>learn  general  word  embeddings</strong>  from a  large  corpus  for  each  word，可观察到类似的词，比如那些围绕“injure”和“fight”的词，倾向于相似的类型，然而，对于具有多种含义的词，如“fire”(射击或解雇)，similar的词可能表示多种事件类型。因此，我们<strong>建议应用词义消歧(WSD)并学习每个意义word sense的独特嵌入(2.3节)</strong></li>
<li>上下文不同对trigger 的type确定也有影响。We  therefore  propose  to  enrich  each  trigger’s representation by incorporating the distributional representations  of  various  words  in  the  trigger’s context. ——如何挑选要放在上下文中的词? 依靠semantic relations</li>
</ol>
<h3 id="2-Approach"><a href="#2-Approach" class="headerlink" title="2   Approach"></a>2   Approach</h3><p>pipelined system</p>
<p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/Liberal Event Extraction and Event Schema Induction/image-20200810181111708.png" alt="image-20200810181111708"></p>
<p><strong>对于输入文本的event extraction和event schema过程</strong></p>
<p>Given a set of input documents, we <strong>first</strong> extract semantic relations( AMR relations 上图左边虚线框), apply WSD词义消歧(WSD用的算法是？) and learn word sense embeddings(上图右边，消歧后输出一个较确定的sense，然后对这个sense学习embedding吗？). Next, we identify candidate triggers and arguments.</p>
<p>为了trigger type的准确性，需要生成trigger’s event structure representation，同时生成Argument representations</p>
<p>Trigger and argument representations被同时送入 joint constraint clustering framework进行聚类，对聚类结果命名得到 event type name，通过the  <strong>meaning  representation  and  semantic role description</strong>s in FrameNet, VerbNet (Kipper etal., 2008) and Propbank (外部KG)间的对应关系 做 argument role labeling</p>
<p>还做出了一点贡献：比较不同的meaning  representations  <strong>semantic  relations   connecting</strong>   triggers   to   context   words are  derived  from  three  meaning  representations <strong>使用  CAMR，Stanford’s  dependency  parse， SEMAFOR 分别从Abstract  Meaning  Representation  (AMR)， Stanford  Typed  Dependencies，FrameNet</strong> 三种meaning  representations提取semantic relations </p>
<h3 id="3-系统拆分分析"><a href="#3-系统拆分分析" class="headerlink" title="3    系统拆分分析"></a>3    系统拆分分析</h3><ul>
<li><p><strong>candidate event triggers:</strong>   Given a sentence, we consider all <strong>noun and verb concepts</strong> that are assigned an <strong>OntoNotes  sense</strong> by WSD as <strong>candidate event triggers</strong>.(Word Sense Disambiguation Using OntoNotes: An Empirical Study). Any remaining concepts that match both <strong>a verbal and a nominal lexical unit</strong> in the <strong>FrameNet corpus</strong> are considered candidate event triggers as well.   一段句子内所有的在Ontonotes Sense Groups 中的verb和noun都作为candidate</p>
</li>
<li><p><strong>Argument Identification</strong>： all concepts 和 candidate  event  trigger间有  semantic  relations的都作为 candidate arguments—— semantic  relations是在一个 manually-selected  set中的—— For <strong>dependencies</strong>, we manually  mapped  dependency  relations  to  AMR  relations and use Event-Related AMR Relations  (dependency  relations 怎么更好利用？)</p>
<p>(用 AMR relation 和 candidate  event  trigger 找到  candidate arguments)</p>
<p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/Liberal Event Extraction and Event Schema Induction/image-20200811101720258.png" alt="image-20200811101720258" style="zoom:80%;" /></p>
</li>
<li><p>为sense 学习embeddings，( map  WordNet sense output to OntoNotes senses这一步的意义是什么？)</p>
<p>used the August 11, 2014 English Wikipedia dump to <strong>learn trigger sense and argument embeddings.</strong></p>
<p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/Liberal Event Extraction and Event Schema Induction/image-20200811211955437.png" alt="image-20200811211955437"></p>
<p>对 unlabled corpus 应用 WSD，根据描述最终得到 <img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/Liberal Event Extraction and Event Schema Induction/image-20200811103509300.png" alt="image-20200811103509300">对candidate trigger的sense的推理，然后再是训练trigger sense 的embedding</p>
<p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/Liberal Event Extraction and Event Schema Induction/image-20200811093757552.png" alt="image-20200811093757552" style="zoom:80%;" /></p>
</li>
<li><p>为了 incorporate  inter-dependencies between  <strong>event  and  argument  role  types</strong> (event 相应的 argument role之间有必然的依赖) into  our event  structure  representation。许多  meaning representations  could  provide，采用 <strong>semantic relations from meaning representations using AMR.</strong></p>
<p>提取与 event trigger(with sense，即trigger包含确定的词义) 语义相关的 words</p>
</li>
<li><p>提出  <strong>Tensor  based  Recursive  Auto-Encoder (TRAE) </strong>——对根据 AMR 得到的 Event Structure编码成一个  representation</p>
<p>目的是 we aim to exploit linguistic  knowledge  to  incorporate  inter-dependencies between  event  and  argument  role  types在表示中融入依赖关系</p>
<p>对  AMR  semantic  relations的每个子集应用一个 composition function ，然后compose  the  event  structure  representation 基于这些 function。</p>
<p>AMR  semantic  relations的自己是作者手动选择的认为分类trigger type有帮助：</p>
<p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/Liberal Event Extraction and Event Schema Induction/image-20200811101720258.png" alt="image-20200811101720258" style="zoom:80%;" /></p>
<p>对于两个 word vector和 AMR relation $:mod$ 定义输出 相同维度的representation vector的公式：</p>
<p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/Liberal Event Extraction and Event Schema Induction/image-20200811120026045.png" alt="image-20200811120026045"></p>
<p>use  the  <strong>statistical  mean(average)</strong>  to  compose  the words  connected  by  <strong>“:op”</strong>  relations </p>
<p>当完成将两个word 根据 relation 进行compose后，将输出的vector apply an element-wise <strong>sigmoid activation</strong> function 得到 hidden layerrepresentations $Z$ ，autoencoder的思想，利用重建结果的reconstruction errors去 optimize  $Z$ ：</p>
<div class="group-picture"><div class="group-picture-container"><div class="group-picture-row"><div class="group-picture-column" style="width: 50%;"><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/Liberal Event Extraction and Event Schema Induction/image-20200811135520868.png" alt="image-20200811135520868" style="zoom:80%;" /></div><div class="group-picture-column" style="width: 50%;"><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/Liberal Event Extraction and Event Schema Induction/image-20200811165907944.png" alt="image-20200811165907944" style="zoom:80%;" /></div></div></div></div>
<p><strong>(感觉不能叫event structure，应该叫sentence structure)</strong></p>
<p>中间的每个向量表示$Z_1 Z_2$ 都表示 trigger 和 argument 以及 relation r 的语义关系的表示</p>
<p>SGD来优化这个目标</p>
<p>Recursive：当得到composition vector of $Z_1$ 后，将 $Z_1$ 和下一个word vector compose</p>
<p>为每种  event structure  生成一个 representation</p>
</li>
<li><p>trigger 和 arguments 的 type 确定</p>
<p>We observe that, for two triggers t1 and t2, if their arguments have the same type and role,  then they are more likely to belong to the same type</p>
<p>让相似的trigger 有相同的type</p>
<p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/Liberal Event Extraction and Event Schema Induction/image-20200811164852225.png" alt="image-20200811164852225" style="zoom:80%;" /></p>
<p>trigger间的相似度</p>
<p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/Liberal Event Extraction and Event Schema Induction/image-20200811170631150.png" alt="image-20200811170631150"></p>
<p>argument 的 type 和 role 是与 trigger 间的 relation 相关，trigger sense的embedding表示不能直接说明相似，还与argument有关，但这里感觉没有体现argument same type and role，$E_r^{t}$ 是直接trigger和argument串联经过变换得到的，在relation已经相同的情况下，argument 用的只是general lexical embeddings，那不同的argument显然会导致 sim 的值下降</p>
</li>
</ul>
<p>  对于argument间的相似度</p>
<p>  <img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/Liberal Event Extraction and Event Schema Induction/image-20200811172247599.png" alt="image-20200811172247599"></p>
<p>  <img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/Liberal Event Extraction and Event Schema Induction/image-20200811172415368.png" alt="image-20200811172415368"></p>
<p>  f 函数对 trigger 作为 自变量 是有定义的，对于 argument呢？文章没有明确指出。</p>
<ul>
<li><p>joint  constraint  clustering  approach, which iteratively produces new clustering results based on the above constraints.  </p>
<p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/Liberal Event Extraction and Event Schema Induction/image-20200811195415111.png" alt="image-20200811195415111" style="zoom:80%;" /></p>
<p>同时给argument 和 trigger 进行clusting：</p>
<p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/Liberal Event Extraction and Event Schema Induction/image-20200811201143524.png" alt="image-20200811201143524" style="zoom:80%;" /></p>
<p>目标函数的优化方法使用 谱聚类</p>
</li>
<li><p>we  utilize  the  trigger which is nearest to the centroid of the cluster as the event type name</p>
<p>For a given event trigger，first  map  the  event  trigger’s OntoNotes   sense   to   PropBank,   VerbNet,   and FrameNet</p>
<p><strong>AMR</strong>： 对 AMR 的argument map到 FrameNet VerbNet PropBank</p>
<p><strong>Stanford  Typed  Dependencies</strong>：</p>
</li>
</ul>
<h3 id="4-Evaluation"><a href="#4-Evaluation" class="headerlink" title="4    Evaluation"></a>4    Evaluation</h3><h4 id="Schema-Discovery"><a href="#Schema-Discovery" class="headerlink" title="Schema Discovery"></a>Schema Discovery</h4><p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/Liberal Event Extraction and Event Schema Induction/image-20200811212423697.png" alt="image-20200811212423697"></p>
<p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/Liberal Event Extraction and Event Schema Induction/image-20200811212432966.png" alt="image-20200811212432966" style="zoom:80%;" /></p>
<p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/Liberal Event Extraction and Event Schema Induction/image-20200811212820115.png" alt="image-20200811212820115"></p>
<p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/Liberal Event Extraction and Event Schema Induction/image-20200811212540739.png" alt="image-20200811212540739" style="zoom:80%;" /></p>
]]></content>
      <categories>
        <category>Event Extraction</category>
      </categories>
      <tags>
        <tag>schema discovery</tag>
        <tag>WSD</tag>
        <tag>AMR</tag>
        <tag>semantic relationship</tag>
        <tag>distribution hypothesis</tag>
        <tag>clusting</tag>
      </tags>
  </entry>
  <entry>
    <title>Event detection and co-reference with minimal supervision</title>
    <url>/blog/2020/07/12/Event%20Detection%20and%20Co-reference%20with%20Minimal%20Supervision/</url>
    <content><![CDATA[<a id="more"></a>
<h3 id="『Event-detection-and-co-reference-with-minimal-supervision』阅读笔记"><a href="#『Event-detection-and-co-reference-with-minimal-supervision』阅读笔记" class="headerlink" title="『Event detection and co-reference with minimal supervision』阅读笔记"></a>『Event detection and co-reference with minimal supervision』阅读笔记</h3><ol>
<li>weakly supervised algorithm——i唯一监督信息是提供对于event type 的先验知识，限定了type 的feature vector</li>
<li>Event detection: constructing a <strong>feature vector</strong> using several instances of the type<strong>,</strong> and <strong>measures similarity</strong> with the <strong>event vector(embedding)</strong> of a text;</li>
<li>通过co-reference: measures similarity between two event vector  得到相似event mention 的集合，提高预测精度</li>
<li>similarity都是在语义层面上，两个vector间的相似度度量用的都是余弦相似性</li>
<li>Freebase</li>
<li>event表示：SRL 以谓词为中心(认为一般trigger为谓词)</li>
<li>对事件向量的表示做修改，更强调谓词的作用，具体使用的现有的embedding方法看具体的效果，没有特别指定</li>
<li>逆着用 event type classification过程——已知type的vector，用于Event Mention Detection</li>
<li>共指co-reference：比较event vector 的相似度</li>
</ol>
<hr>
<h3 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h3><p><strong>Uses a weakly supervised algorithm to tackle Event detection and co-reference problem</strong>. </p>
<p>In the article, both <strong>event detection and co-reference problem</strong> both are considered <strong>similarity detection problems.</strong> Using several instances of each type as event vectors of that type, calculating the similarity between the <strong>new event vector</strong> and <strong>event vector of each type</strong>, judging <strong>whether the event belongs to that type based on similarity.</strong></p>
<h3 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h3><p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/Event Detection and Co-reference with Minimal Supervision/image/image-20200308193457898.png" alt="image-20200308193457898" style="zoom:140%;" /></p>
<center>the MSEP framwork. Event example is the only source of suppervison </center>  

<ul>
<li><strong>Event detection</strong>:   identifying whether an event in context is semantically related to a set of <strong>events of a specific type.</strong></li>
<li><strong>Co-reference problem</strong>:   whether two event mentions are semantically similar enough to indicate that the author intends to refer to the same thing.</li>
</ul>
<p>As for Event detection, more like <strong>constructing a feature vector using several instances of the type</strong>, and measures similarity with the event vector of a text; </p>
<p>As for co-reference problem, <strong>measures similarity between two event vector.</strong></p>
<ul>
<li><strong>How to represent an event</strong>:  using SRL, different embedding  methods(ESA, BC, W2V, DEP) to convert event components  structured vector representation.</li>
<li><strong>How to measure similarity</strong>:  calculating the cosine distance.</li>
</ul>
<h4 id="Structured-Vector-Representation"><a href="#Structured-Vector-Representation" class="headerlink" title="Structured Vector Representation"></a>Structured Vector Representation</h4><p> Event triggers are mostly predicates of sentences or clauses. Predicates roughly corresponds to event types. </p>
<p> Map SRL arguments to : action, agent<em>sub</em>, agent<em>obj</em> , location and time. </p>
<p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/Event Detection and Co-reference with Minimal Supervision/image/image-20200308195646493.png" alt="image-20200308195646493"></p>
<h4 id="Event-Mention-Detection"><a href="#Event-Mention-Detection" class="headerlink" title="Event Mention Detection"></a>Event Mention Detection</h4><p>We define the <strong><em>event type representation</em></strong> as the <strong>numerical average</strong> of all vector representations corresponding to example events under that type.</p>
<p>similarity measurement: </p>
<p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/Event Detection and Co-reference with Minimal Supervision/image/image-20200308195931031.png" alt="image-20200308195931031"></p>
<p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/Event Detection and Co-reference with Minimal Supervision/image/image-20200308195955412.png" alt="image-20200308195955412"></p>
<h4 id="Event-co-reference"><a href="#Event-co-reference" class="headerlink" title="Event co-reference"></a>Event co-reference</h4><p>We compare agent<em>sub</em> and agent<em>obj</em> . If none of the types for the aligned event arguments match, this pair is determined to be in conflflict. If the event argument is missing, we deem it compatible with any type.</p>
<p>we generate a “conflict set”. </p>
<p>For event not in “conflict set”,</p>
<p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/Event Detection and Co-reference with Minimal Supervision/image/image-20200308201247562.png" alt="image-20200308201247562"></p>
<p><a href="[https://juewang.me/posts/%5B2018.1.21%5DEvent-detection-and-co-referentce/](https://juewang.me/posts/[2018.1.21]Event-detection-and-co-referentce/">reference——jue wang的blog</a>)</p>
<hr>
<h3 id="Introduction-1"><a href="#Introduction-1" class="headerlink" title="Introduction"></a>Introduction</h3><h4 id="自然语言理解的一个重要方面涉及到对事件及其之间的关系进行识别和分类"><a href="#自然语言理解的一个重要方面涉及到对事件及其之间的关系进行识别和分类" class="headerlink" title="自然语言理解的一个重要方面涉及到对事件及其之间的关系进行识别和分类"></a>自然语言理解的一个重要方面涉及到对<strong><em>事件及其之间的关系进行识别和分类</em></strong></h4><h4 id="解决从少量的数据中学习复杂的模型的过拟合情况"><a href="#解决从少量的数据中学习复杂的模型的过拟合情况" class="headerlink" title="解决从少量的数据中学习复杂的模型的过拟合情况"></a><strong>解决从少量的数据中学习复杂的模型的过拟合情况</strong></h4><p>developing an event detection and co-reference system with minimal supervision,  in  the  form  of  <strong>a  few  event  examples</strong>. </p>
<p>We view these tasks as <strong>semantic similarity</strong> problems between <strong>event mentions</strong> or <strong>event mentions  and  an  ontology</strong> <strong>of  types</strong>我们将这些任务视为事件提及或事件与类型本体之间的语义相似性问题</p>
<p>有助于使用大量域外数据，</p>
<p>模型利用文本的结构our semantic relatedness function exploits the structure of the text by making use of a semantic-role-labeling based representation of an event.</p>
<p>我们的语义相关性功能利用事件的基于语义角色标记的表示来利用文本的结构。</p>
<ol>
<li>理解事件还需要理解它们之间的关系Understanding events also necessitates  understanding  relations  among  them。关系有助于确定两个文本片段是否表示同一事件</li>
<li>the frame-based structure of events基于帧的事件结构必须解决多个耦合问题(multiple coupled problems)，这些问题很难单独研究。</li>
<li>可能是更核心的问题：whether current set of events’ definitions is adequate </li>
<li>该领域当前的评估方法侧重于事件的有限领域 limited  domain of event</li>
<li>Consequently, this allows researchers to train supervised systems that are tailored to these sets of events and that overfit the small domain covered in the annotated data, rather than address the realistic problem of understanding events in text训练的模型是适合于带注释的数据所覆盖的小范围的监督系统</li>
<li>根本上说，事件检测是关于识别上下文中的事件是否与特定类型的事件集有语义上的关联；事件共同引用是关于两个事件提及在语义上是否足够相似，以表明作者打算引用相同的内容。如果将事件检测和共引用表示为语义相关性问题，则可以对其进行扩展以处理更多类型，并且有可能跨领域进行概括。此外，这样做有助于我们使用大量数据，这些数据不属于现有带注释的事件集合，甚至不属于同一域。</li>
<li>主要的问题是 a. how to represent events。 b.  how to model event similarity。 这些都很难，因为events have structure</li>
</ol>
<h4 id="1-我们的框架："><a href="#1-我们的框架：" class="headerlink" title="1   我们的框架："></a>1   我们的框架：</h4><ol>
<li><p>which essentially requires no labeled data；Event examples 是唯一的监督来源，用于产生 Example vectors</p>
</li>
<li><p>在实践中，为了将事件映射到事件本体(map an event mention to an event ontology)（作为与用户通信的方式），对于用户想要提取的每种类型，我们只需要用纯文本形式的几个事件示例即可。event  type 用几个example作为definition</p>
</li>
<li><p>与标准无监督方法相比，我们的方法所做的假设要少得多less assumption，后者通常需要实例的集合和实例之间的近似相似性才能最终学习模型。</p>
</li>
<li><p>给定事件类型定义，我们可以classify a single event into  a  provided  ontology 然后判断两者是否are co-referent</p>
</li>
<li><p>从这个意义上讲，我们的方法类似于所谓的无数据分类dataless classification</p>
</li>
<li><p>我们的方法基于两个关键思想：</p>
<p>a.  首先，为了表示事件结构event structures，我们使用通用的名义general purpose nominal和语言语义角色标记verbial semantic role labeling representation（SRL）表示。这使我们能够开发事件的结构化表示。</p>
<p>b. 我们将事件组件embed event component在保持结构的同时嵌入到多个语义空间中，在上下文，主题和句法层面上。 multiple semantic space at a contextual, topical, and syntactic levels.</p>
<p>这些语义表示是从大量文本中得出的，其方式完全独立于手头的任务，并且用于表示事件提及和事件类型，来用于分类事件</p>
<p>1). 这些语义空间的组合以及事件的结构化矢量表示，使我们能够直接确定候选事件的提及是否为有效事件。如果是，则是哪种类型。</p>
<p>2). <strong>且</strong>在具有相同表示形式的情况下，我们可以评估事件相似性，并确定两个事件提及是否是共同引用，所以这个模型can also adapt to new domains without any training</p>
</li>
<li><p>A few event examples就是MSEP所需要的全部监督信息了。这些示例甚至一劳永逸地确定了需要确定的几个决策阈值，并用于我们评估的所有测试案例。</p>
</li>
</ol>
<h4 id="专有词汇"><a href="#专有词汇" class="headerlink" title="专有词汇"></a>专有词汇</h4><ol>
<li>event mentions</li>
<li>semantic-role-labeling based representation of an event</li>
<li>event  co-reference on <strong>benchmark data sets</strong></li>
<li>transfer across domains 跨域转移</li>
<li>event co-reference  problem——determining  whether  two  snippets  of text represent the same event or not</li>
<li>dataless classification(Chang et al.,  2008;  Song and Roth,2014).</li>
<li>通用的名义general purpose nominal</li>
<li>语言语义角色标记verbial semantic role labeling representation（SRL）</li>
<li>ESA vector</li>
<li>seed-based event trigger labeling technique employed in Bronstein et al. (2015)</li>
<li>the  mention-pair  model  in  entity  co-reference (Ng and Cardie, 2002; Bengtson and Roth,2008;  Stoyanov   et  al.,  2010),</li>
<li>the  Illinois  Wikification  (Chengand  Roth,  2013)  tool </li>
<li>Explicit  Semantic  Analysis(ESA), Brown Cluster (BC), Word2Vec (W2V) and Dependency-Based Word Embedding (DEP) </li>
<li>TF-IDF vector</li>
<li>event detection 即 <strong>trigger  identification</strong></li>
</ol>
<p>​    </p>
<h3 id="2-The-MSEP-System"><a href="#2-The-MSEP-System" class="headerlink" title="2   The MSEP System"></a>2   The MSEP System</h3><h4 id="2-1-Structured-Vector-Representation"><a href="#2-1-Structured-Vector-Representation" class="headerlink" title="2.1 Structured Vector Representation"></a>2.1 Structured Vector Representation</h4><ol>
<li><p>事件结构和句子结构存在相似性，事件触发器 Event  triggers主要是句子或从句 clauses的谓词Predicates。谓词可以消除歧义sense disambiguated</p>
</li>
<li><p>事件自变量Event arguments主要是实体提及entity mentions或时间/空间自变量temporal/spatial argument。它们充当事件中的特定角色，类似于为谓词分配角色标签的SRL参数</p>
</li>
<li><p>Illinois SRL <strong>pre-process</strong> the text。 good coverage of SRL predicates and arguments on event triggers and arguments</p>
</li>
<li><p>评估事件触发器和事件参数event  triggers  and  event  arguments,的SRL覆盖率。   对于事件触发器，我们仅关注recall，因为我们希望事件提及检测模块vent mention detection能够过滤掉大多数非触发谓词。即使我们仅获得近似的事件参数，将其归类为五个抽象角色也比确定事件触发器的确切角色标签更容易，更可靠。</p>
</li>
<li><p>我们确定了五个最重要的抽象事件语义成分：<img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/Event Detection and Co-reference with Minimal Supervision/image-20200707110825519.png" alt="image-20200707110825519" style="zoom:67%;display:inline" align="middle"  />为了将SRL参数映射到这些事件参数，执行以下过程：</p>
<p>a.  set predicates as actions,and preserve SRL negations for action;</p>
<p>b.   set SRL subject as$agent_{sub}$</p>
<p>c.   set SRL object and indirect object as $agent_{obj}$</p>
<p>d.  set SRL spatial argument as event  location如果没有此类SRL标签，则将扫描该动作所属的句/句中的任何NER位置标签 NER location label。我们会根据NER信息设置位置set the location according to NER information如果它存在</p>
<p>e.   We set the SRL temporal argument as event time.  如果没有这种 SRL  label, 则use the Illinois Temporal Expression Extractor  在事件的主句或从句中找到temporal argument</p>
<p>f.  允许$agent_{sub}、agent_{obj}$、location or time missing， 但是action一定有</p>
<p><strong>在2.3中我们将每个事件分量event  component转换为其相应的向量vector  representation表示形式</strong></p>
</li>
<li><p>我们将action所在的主句或从句作为上下文信息，append its corresponding vector to the event representation。   对missing 的event arguments, we set the corresponding  vector  to  be  “NIL”  (we  set  each  position as “NaN”）</p>
</li>
<li>我们还通过连接更多的文本片段来增强事件向量表示，以增强动作和其他自变量之间的交互<img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/Event Detection and Co-reference with Minimal Supervision/image-20200707115835192.png" alt="image-20200707115835192" style="zoom:67%;display:inline" align="middle" />Here, “+” means that we first put text fragments together and then convert the combined text fragment into an ESA vector</li>
<li>本质上，我们将事件结构展宽以保留事件参数的对齐方式，以便结构化信息可以反映在向量空间中。</li>
</ol>
<h4 id="2-2-Event-Mention-Detection"><a href="#2-2-Event-Mention-Detection" class="headerlink" title="2.2    Event Mention Detection"></a>2.2    Event Mention Detection</h4><ol>
<li><p>我们将针对每个事件类型标签下描述的事件示例使用ACE注释准则turn to ACE annotation guidelines for event examples described under each event type label 即在ACE的guidelines event types下找event examples</p>
</li>
<li><p>则event  type的表示可以用the numerical average of all vector representations corresponding to example events under that type.</p>
</li>
<li><p>我们使用事件候选者event candidate与事件类型event type表示之间的相似性来确定候选者是否属于事件类型</p>
<p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/Event Detection and Co-reference with Minimal Supervision/image-20200707184516462.png" alt="image-20200707184516462" style="zoom: 67%;" /></p>
<p>请注意，可能缺少事件参数 event  argument（NIL）。在这种情况下，我们使用该特定组件的所有非NIL相似度分数的平均值作为贡献分数</p>
</li>
<li><p>这些平均贡献分数独立于语料库，可以提前进行预先计算。我们使用临界值确定事件不属于任何事件类型，因此可以将其消除。此阈值仅通过调整事件示例集来设置，该事件示例与语料库无关</p>
</li>
</ol>
<h4 id="2-3-Event-Co-reference"><a href="#2-3-Event-Co-reference" class="headerlink" title="2.3    Event Co-reference"></a>2.3    Event Co-reference</h4><ol>
<li><p>在应用共同引用模型之前，我们首先使用外部知识库来识别冲突事件，<strong>the  Illinois  Wikification tool </strong> link  event  arguments  to Wikipedia pages</p>
</li>
<li><p>使用Wikipedia ID，我们将事件参数event arguments映射到Freebase条目。我们将顶层Freebase类型视为事件参数类型event argument type。一个事件参数可以包含多个wiki的实体entities，从而导致多个Wikipedia页面以及一组Freebase类型。我们还使用NER标签扩充了参数类型集argument type set：PER（人）和ORG（组织）。如果我们检测到这样的命名实体，则添加NER标签之一</p>
</li>
<li><p>conflict:      we check event arguments $agent_{sub}、agent_{obj}$ respectively.如果对齐的事件参数的类型都不匹配，则确定 this pair该对存在冲突。 如果缺少事件参数，我们认为它与任何类型兼容。。通过检查是否有conflict，得到一个$Set_{conflict}$，里面的元素间不会有共指链接 co-reference links</p>
</li>
<li><p>left-linking greedy algorithm————for performing  event  co-reference  inference：：</p>
<p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/Event Detection and Co-reference with Minimal Supervision/image-20200707223550299.png" alt="image-20200707223550299" style="zoom: 67%;" /></p>
</li>
<li><p>当$S(e_p,e_{k+1})$ event-pair similarity大于一个阈值时，make  co-reference  links。这个阈值是tuned only on event examples ahead of time。这里的$e_{k+1}$相当于共指聚类的聚类中心，当$e_{k+1}$和$e\in\{e_1,e_2,e_3,…,e_k\}$所有的event的相似度都低于阈值时，将$e_{k+1}$作为一个新的聚类中心的</p>
</li>
</ol>
<h3 id="3-Vector-Representations"><a href="#3-Vector-Representations" class="headerlink" title="3.   Vector Representations"></a>3.   Vector Representations</h3><p>测试了包括 Explicit  Semantic  Analysis(ESA), Brown Cluster (BC), Word2Vec (W2V) and Dependency-Based Word Embedding (DEP)  分别将文本转换为矢量。然后，我们将事件的所有组成部分串联在一起，以形成结构化的向量表示形式。</p>
<h4 id="3-1-Explicit-Semantic-Analysis-ESA显式语义分析"><a href="#3-1-Explicit-Semantic-Analysis-ESA显式语义分析" class="headerlink" title="3.1 Explicit  Semantic  Analysis ESA显式语义分析"></a>3.1 Explicit  Semantic  Analysis ESA显式语义分析</h4><p>使用Wikipedia作为外部知识库为给定的文本片段生成概念generate  concepts for a given fragment of text （Gabrilovich和Markovitch，2009年）。ESA首先将给定的文本片段表示为TF-IDF向量，然后对每个单词使用一个反向索引来搜索Wikipedia语料库。因此，文本片段表示是对应于其单词的概念向量的加权组合。我们使用与Chang等人（2008）中相同的设置来过滤掉少于100个单词的页面和少于5个超链接的页面。为了在ESA表示的有效性和成本之间取得平衡，我们使用权重最高的200个概念。因此，我们将每个文本片段转换为数以百万计的非常稀疏的矢量（但我们仅存储200个非零值）</p>
<h4 id="3-2-Brown-Cluster"><a href="#3-2-Brown-Cluster" class="headerlink" title="3.2  Brown Cluster"></a>3.2  Brown Cluster</h4><p>support abstraction in NLP tasks，测量单词的分布相似度measuring  words’  distributional  similarities。 This method generates a hierarchical tree of word clusters by evaluating the word co-occurrence based on a  n-gram  mode</p>
<p><strong>use the implementation by Song and Roth (2014) </strong> generated over the latest Wikipedia dump转储.使用长度为4,6和10的路径前缀的组合作为我们的BC表示。Thus, we convert each word to a vector of $2^4+2^6+2^{10}=1104$dimensions</p>
<h4 id="3-3-Word2Vec"><a href="#3-3-Word2Vec" class="headerlink" title="3.3  Word2Vec"></a>3.3  Word2Vec</h4><p> the skip-gram tool by Mikolov etal. (2013) over the latest Wikipedia dump, resulting in word vectors of dimensionality 200.</p>
<h4 id="3-4-Dependency-Based-Embedding"><a href="#3-4-Dependency-Based-Embedding" class="headerlink" title="3.4  Dependency-Based Embedding"></a>3.4  Dependency-Based Embedding</h4><p>DEP is the generalization of the skip-gram model with negative sampling to include arbitrary contexts.  In particular, it deals with dependency-based contexts, and produces markedly different embeddings. DEP exhibits more functional similarity than the original skip-gram embeddings (Levy and Goldberg,  2014).  We directly use the released 300-dimension word embeddings</p>
<p>请注意，对于ESA，这是直接的文本向量转换。但是对于BC，W2V和DEP，我们首先从文本中remove stop words，然后对所有剩余的词向量进行元素平均，以生成文本碎片的结果向量表示。</p>
<h3 id="4-Experiments"><a href="#4-Experiments" class="headerlink" title="4  Experiments"></a>4  Experiments</h3><h4 id="4-1-Datasets"><a href="#4-1-Datasets" class="headerlink" title="4.1   Datasets"></a>4.1   Datasets</h4><p><strong>ACE</strong> ACE-2005英语语料库（NIST，2005）包含细粒度的事件注释event  annotations，包括事件触发器，参数，实体和时间戳记注释event trigger, argument, entity, and time-stamp annotations。我们从新闻报道中选择40个文档进行事件检测评估，其余用于培训（与Chen等人（2015年）相同）。我们对事件共同引用进行了十折交叉验证</p>
<p><strong>TAC-KBP</strong>   TAC-KBP-2015语料库带有事件块event  nuggets ，分为38种类型，并且事件之间具有共同引用关系.我们使用官方TAC提供的训练/测试数据拆分</p>
<h4 id="4-2-Compared-Systems"><a href="#4-2-Compared-Systems" class="headerlink" title="4.2  Compared Systems"></a>4.2  Compared Systems</h4><h4 id="4-3-Evaluation-Metrics"><a href="#4-3-Evaluation-Metrics" class="headerlink" title="4.3  Evaluation Metrics"></a>4.3  Evaluation Metrics</h4><p>对于事件检测，我们使用标准精度，召回率和F1指标。对于事件共指event  co-reference，我们使用标准F1指标比较所有系统。 </p>
<p> <img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/Event Detection and Co-reference with Minimal Supervision/image-20200708000900237.png" alt="image-20200708000900237" style="zoom: 67%;" /></p>
<p>我们使用这四个指标的平均得分（AVERAGE）作为主要比较指标。</p>
<h4 id="4-4-result"><a href="#4-4-result" class="headerlink" title="4.4 result"></a>4.4 result</h4><p>在事件检测上，SSED  achieves  state-of-the-art  performance。。。SEED和MSEP都是使用SRL谓词作为输入，因此可以使用更好的SRL模块进一步改进。</p>
<h4 id="4-5-Results-for-Event-Co-reference"><a href="#4-5-Results-for-Event-Co-reference" class="headerlink" title="4.5  Results for Event Co-reference"></a>4.5  Results for Event Co-reference</h4><p>关于如何进行Semantic Role Labeling，先引用juewang博客中的内容<a href="[https://juewang.me/posts/%5B2018.1.21%5DEvent-detection-and-co-referentce/](https://juewang.me/posts/[2018.1.21]Event-detection-and-co-referentce/">引用</a>)</p>
<p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/Event Detection and Co-reference with Minimal Supervision/image-20200810113906464.png" alt="image-20200810113906464" style="zoom:80%;" /></p>
]]></content>
      <categories>
        <category>Event Extraction</category>
      </categories>
      <tags>
        <tag>Freebase</tag>
        <tag>SRL</tag>
        <tag>co-reference</tag>
        <tag>pairwise similarity</tag>
      </tags>
  </entry>
  <entry>
    <title>Open Domain Event Extraction from Twitter</title>
    <url>/blog/2020/07/11/Open%20Domain%20Event%20Extraction%20from%20Twitter/</url>
    <content><![CDATA[<a id="more"></a>
<h3 id="『Open-Domain-Event-Extraction-from-Twitter』阅读笔记"><a href="#『Open-Domain-Event-Extraction-from-Twitter』阅读笔记" class="headerlink" title="『Open Domain Event Extraction from Twitter』阅读笔记"></a>『Open Domain Event Extraction from Twitter』阅读笔记</h3><p><a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.481.6809&amp;rep=rep1&amp;type=pdf">pdf</a></p>
<ol>
<li>Open Domain</li>
<li>根据<strong>[Named entity recognition in tweets: An experimental study.]</strong>中的模型 twitter文本有较多OOV(用Brown Cluster对lexical variations产生的OOV进行聚类来解决OOV)，manually annotated tweets as in-domain data 用于train POS system(特殊的词性标注集)，CRF(包含Brown Cluster的feature函数以及以及POS dictionary，spelling and contextual feature)，来完成POS tag任务。 named entity segmentation和classification任务的具体细节见文章</li>
<li>event phrase extraction——即EE任务中的对event mention的提取，用 linear chain CRF model作为序列标注任务的模型，识别trigger(这里的CRF用到的特征函数包括 contextual, dictionary, and orthographic features, and also include features based on our Twitter-tuned POS tagger [Named entity recognition in tweets: An experimental study], and dictionaries of event terms gathered from WordNet by Sauri et al.[Evita: a robust event recognizer for QA systems.])</li>
<li>temporal expression提取，即event argument ——TempEx</li>
<li>event type classification——因为推文open domain性质：首先，目前还不清楚哪些类别适合Twitter(?)。其次，使用事件类型标记tweet需要大量的手工工作。第三，重要类别(和实体)的集合很可能会随着时间的推移而改变，或者在特定的用户群体中改变。最后，许多重要的类别是相对少见的，所以即使一个大的带注释的数据集可能只包含这些类别的几个例子，使分类困难。——无监督方法，生成模型，使用主题模型中的LDA方法，该模型推断出一组适当的事件类型来匹配我们的数据，并通过利用大量的未标记数据将事件分类为不同的类型。</li>
<li>推断——LDA方法的inference，gibbs sampling</li>
</ol>
<h3 id="code"><a href="#code" class="headerlink" title="code"></a>code</h3><p><a href="https://github.com/aritter/twitter_nlp">https://github.com/aritter/twitter_nlp</a></p>
<h3 id="专有名词"><a href="#专有名词" class="headerlink" title="专有名词"></a>专有名词</h3><ol>
<li>recent work on NLP in noisy text</li>
<li>latent variable models</li>
<li>POS tagged pos标记</li>
<li>NLP tool 命名实体分割器和旨在处理经编辑文本（例如新闻文章）的部分语音标记器</li>
<li>TEMPORAL EXPRESSIONS 解决时间表达式</li>
<li>Event indicator phrase </li>
<li><p>LinkLDA </p>
<p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/Open Domain Event Extraction from Twitter/image-20200705193641839.png" alt="image-20200705193641839" style="zoom:80%;" /></p>
<p>提及事件短语的类型分布的信息可以在提及的内容中共享，而歧义性也可以自然保留。该方法基于生成的概率模型，对数据执行许多不同的概率查询很简单。例如，在对Ag-Aggregate事件进行分类时，这很有用。</p>
</li>
<li><p>为了进行推断(inference)，我们使用折叠(collapsed)的Gibbs采样: 其中依次对每个隐藏变量进行采样，并对参数进行积分。</p>
</li>
<li>折叠(collapsed)的Gibbs采样(sampling)</li>
<li>流方法(a streaming approach)进行推理以预测</li>
<li>Gibbs markov链</li>
<li>symmetric Dirichlet distribution对称狄利克雷分布</li>
<li>Bayesian Inference techniques 贝叶斯推理技术</li>
<li>流推论技术 streaming inference techniques</li>
<li><p>$G^2$ log likelihood ratio statistic，对于text分析比卡方更有效<br>Fisher’s Exact test   ——— produce P values 但对于大数据量，计算Fisher’s Exact test statistic困难。。。。在我们的环境中，G2测试足够好用，因为计算实体和日期之间的关联比使用成对的实体（或单词）时产生的稀疏列联表(sparse contingency table)要少。</p>
<p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/Open Domain Event Extraction from Twitter/image-20200705205639212.png" alt="image-20200705205639212" style="zoom:80%;" /></p>
</li>
<li>Locally Sensitive Hash Functions </li>
</ol>
<h3 id="challenge："><a href="#challenge：" class="headerlink" title="challenge："></a>challenge：</h3><ol>
<li>大多数tweets是琐事</li>
<li>没有足够信息将其归类到一个category的event</li>
<li>tweets的格式不是正式的书写方式，传统的NLP不适合</li>
</ol>
<h3 id="Opportunities"><a href="#Opportunities" class="headerlink" title="Opportunities:"></a>Opportunities:</h3><ol>
<li>NLP in noisy text</li>
<li>找到事件的总体表示，为<strong>事件分类</strong>提供额外的上下文</li>
<li><strong>识别那些和唯一时间相关的重要事件，而不是在一段时间内均匀发生的</strong></li>
<li>如何找到重要事件的集合</li>
<li>监督和半监督需要manually annotate。提出一种自动找type，然后filter和annotate with label的方法，用找到的类别对extracted event进行分类。</li>
<li>主要的优点是使用了大量无标签的数据</li>
</ol>
<h3 id="Representation"><a href="#Representation" class="headerlink" title="Representation"></a>Representation</h3><p>extracts a 4-tuple representation of events which includes <strong>a named entity, event phrase, unambiguous calendar date, and event type</strong> </p>
<p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/Open Domain Event Extraction from Twitter/image-20200308135214464-1596944096144.png" alt="image-20200308135214464"></p>
<p>选择这种表达方式是为了与Twitter中重要事件的典型表达方式紧密匹配，目的是找到Twitter中重要event并以这种格式记录。</p>
<h3 id="Model-框图"><a href="#Model-框图" class="headerlink" title="Model 框图"></a>Model 框图</h3><p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/Open Domain Event Extraction from Twitter/image-20200809113907373.png" alt="image-20200809113907373"></p>
<p>open domain下做 命名实体提取NER、事件提取EE和时间表达式解析Temporal Resolution。对提取的Event进行分类，根据significance进行排序。</p>
<p>分类依据：</p>
<p>significance排序依据:  根据每个date中出现的次数决定the strengthen association between each named entity and date</p>
<h3 id="NLP-tool"><a href="#NLP-tool" class="headerlink" title="NLP tool"></a>NLP tool</h3><ol>
<li>named entity segmenters </li>
<li>PoS tagger</li>
</ol>
<p>因为推文的形式不规范，没有可靠的特征描述，所以 ENR tool 是在 <strong>in-domain Twitter data</strong>重新训练的</p>
<h3 id="EXTRACTING-EVENT-MENTIONS"><a href="#EXTRACTING-EVENT-MENTIONS" class="headerlink" title="EXTRACTING EVENT MENTIONS"></a>EXTRACTING EVENT MENTIONS</h3><ol>
<li><p>手动 annotate a corpus of tweets 用于 train <strong>sequence models</strong> to extract event</p>
</li>
<li><p>对推文用现成的 PoS tagger (chain CRF, which is beneficial for extracting multi-word event phrase)打上PoS tag</p>
</li>
<li><p>Event phrases can consist of many different 词性(event mentions?) </p>
<p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/Open Domain Event Extraction from Twitter/image-20200809152426429.png" alt="image-20200809152426429"></p>
</li>
<li><p>手动注释的细节：</p>
<p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/Open Domain Event Extraction from Twitter/image-20200809152646060.png" alt="image-20200809152646060"></p>
</li>
<li><p>CRF方法，定义feature function的细节：</p>
<p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/Open Domain Event Extraction from Twitter/image-20200809154338160.png" alt="image-20200809154338160"></p>
</li>
</ol>
<h3 id="EXTRACTING-AND-RESOLVING-TEM-PORAL-EXPRESSIONS"><a href="#EXTRACTING-AND-RESOLVING-TEM-PORAL-EXPRESSIONS" class="headerlink" title="EXTRACTING AND RESOLVING TEM-PORAL EXPRESSIONS"></a>EXTRACTING AND RESOLVING TEM-PORAL EXPRESSIONS</h3><p>时间表达的抽取和解析</p>
<p>use <strong>TempEx</strong></p>
<p>直接用在推文中出现的描述date 的text上准确率也很高——直接使用的TempEx，pipelined system</p>
<p> input a reference date, some text, and parts of speech (from our Twitter-trained POS tagger) and marks temporal expressions with unambiguous calendar references.(<strong>designed for use on newswire text, future work adapting temporal extraction to Twitter</strong> )</p>
<h3 id="CLASSIFICATION-OF-EVENT-TYPES"><a href="#CLASSIFICATION-OF-EVENT-TYPES" class="headerlink" title="CLASSIFICATION OF EVENT TYPES"></a>CLASSIFICATION OF EVENT TYPES</h3><p>将事件类型 event type 作为 latent variables $z$ ，推断一组适当的事件类型以匹配我们的数据，并通过利用大量未标记的数据将事件分类为各种类型  (用的是 LinkLDA ，主题模型中的一种，主题为隐变量，为文档预测主题 )</p>
<p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/Open Domain Event Extraction from Twitter/image-20200809165055337.png" alt="image-20200809165055337" style="zoom:80%;" /></p>
<p>unsupervised approaches that will automatically induce event types which match the data.</p>
<p>Each type corresponds to a distribution over named entities n involved in specific instances of the type, in addition to a distribution over dates d on which events of the type occur. </p>
<p>每个type有一个该类型特定实例的命名实体的分布，和该类型事件发生的日期 的 分布。</p>
<h3 id="Inference"><a href="#Inference" class="headerlink" title="Inference"></a>Inference</h3><p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/Open Domain Event Extraction from Twitter/image-20200809165151047.png" alt="image-20200809165151047" style="zoom:80%;" /></p>
<p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/Open Domain Event Extraction from Twitter/image-20200809165207521.png" alt="image-20200809165207521"></p>
<p><strong>pipelined system</strong></p>
<h3 id="Algorithm"><a href="#Algorithm" class="headerlink" title="Algorithm"></a>Algorithm</h3><h4 id="算法细节："><a href="#算法细节：" class="headerlink" title="算法细节："></a>算法细节：</h4><ol>
<li><p>这些推文经过POS标记，然后提取命名的实体和事件短语，解析时间表达式，并将提取的事件分类。最后，我们根据它们共同出现的推文的数量来测量每个命名实体与日期之间的关联强度，以便确定事件是否重要。</p>
</li>
<li><p>NLP tool：我们利用named entity segmenters 和PoS tagger， ENR tool是根据先前工作[46]中介绍的域内Twitter数据进行训练的。我们还针对域内带注释的数据开发了一个事件标记器</p>
</li>
<li><p>我们使用命名实体tagger对先前工作中提出的域内Twitter数据进行了培训[46] .3对tweet进行培训可以大大提高对命名实体进行分段的性能。 域内训练的重要性</p>
</li>
<li><p>event phrase提供了重要的上下文信息，提供的信息也有助于categorizing event into types</p>
</li>
<li><p>我们使用条件随机场（conditional random filed)进行学习learning 和推理inference，将事件触发的识别问题视为序列标记任务sequence labeling task[24</p>
</li>
<li><p>线性链CRF(linear chain CRF)对相邻单词(adjacent words)的预测标签(predicted label)之间的相关性(dependencies)进行建模，这有助于提取多单词事件短语(extract multi-word event phrase)</p>
</li>
<li><p>我们使用上下文(contextual)，字典(dictionary)和正字法(orthographic)特征，还包括基于Twitter调整的POS标记器[46]的功能，以及Sauri等人[50]从WordNet收集的事件项的词典。</p>
</li>
<li><p>除了提取事件和相关的命名实体之外，我们还需要在事件发生时进行提取。</p>
</li>
<li><p>解决时间表达式：resolve temporal expression。 使用TempEx——输入参考日期，一些文本和词性（来自我们的Twitter训练的POS标记器），并使用明确的日历参考标记时间表达。 a reference date, some text, and parts of speech(from our Twitter-trained POS tagger)TempEx在推文上的高精度可以用以下事实来解释，即某些时间表达相对明确 TempEx’s high precisionon Tweets can be explained by the fact that some temporal expressions are relatively unambiguous.尽管通过处理嘈杂的时间表达似乎有改善Twitter上时间提取（例如，“明天”一词的50多个拼写变化列表，请参见Ritter等人[46]），但我们保留了适应时间的提取到Twitter作为潜在的未来工作（for example see Ritter et. al. [46] for a list of over50 spelling variations on the word “tomorrow”）</p>
</li>
<li><p>为了将提取的事件分类为不同的类型，我们提出了一种基于潜在变量模型(atent variable models )的方法，该方法可以推断出适当的事件类型集以匹配我们的数据，并通过利用大量未标记的数据将事件分类为各种类型。 模型的来由 by recent work on modeling selectional preferences [47, 39, 22, 52, 48], and unsupervised information extraction [4, 55, 7].</p>
</li>
<li><p><strong>Supervised or semi-supervised classification of event categories存在一些问题：</strong></p>
<p><strong>a. priori unclear不清楚哪个类别适用于Twitter。</strong></p>
<p><strong>b. 用事件类型注释推文需要大量的人工。</strong></p>
<p><strong>c. 重要的类别（和实体）可能会随着时间的推移而变化，或者随着关注的用户人群而变化。 important categories (and entities) is likely to shift over time</strong></p>
<p><strong>d. 即使是大型带注释的数据集也可能仅包含这些重要类别的少量示例making classification difficult.</strong></p>
</li>
<li><p>事件指示器短语event indicator phrase ，都被建模为类型的混合a mixture of types<img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/Open Domain Event Extraction from Twitter/image-20200705172439009.png" alt="image-20200705172439009" style="zoom:67%;display:inline" align="middle" />每种type对应于该种type的特定实例中涉及到的命名实例的分布</p>
</li>
<li><p>在我们的模型中包括日历日期，具有鼓励在同一日期发生的事件被分配为相同类型的作用。有助于指导推理，因为对同一事件的不同引用也应具有相同的类型.</p>
</li>
<li><p>为了估计给定事件在类型上的分布，在充分 burn in(扔掉前几个迭代) 后从Gibbs markov链中获取相应的隐藏变量的样本。使用流方法(a streaming approach)进行推理以预测新数据</p>
</li>
<li>用于注释自动发现的事件类型的完整标签列表以及每种类型的覆盖范围。请注意，将标签分配给类型仅需要完成一次，并为任意数量的事件实例生成标签。</li>
</ol>
<h4 id="评价"><a href="#评价" class="headerlink" title="评价"></a>评价</h4><ol>
<li><p>为了评估模型对重大事件进行分类的能力，收集， we gathered 65 million extracted events of the form 。We then ran <strong>Gibbs Sampling</strong> with 100 types for 1,000 iterations of burn-in, keeping the hidden variable assignments found in the last sample.</p>
</li>
<li><p>可以使用流推论技术轻松地使用相同的类型集对新事件实例进行分类[efficient methods for <strong>topic model inference</strong> on streaming document collections.]。未来工作的一个有趣方向是自动标记和对自动发现的事件类型进行一致性评估，类似于主题模型的最新工作[38，25]。</p>
</li>
<li><p>为了评估模型对<strong>汇总事件</strong>进行分类的能力(classify aggregate events,).我们将出现20倍或20倍以上数据的所有（实体，日期）对组合在一起，然后使用模型发现的<strong>事件类型</strong>对<strong>关联性最高的500</strong>（请参阅第7节）进行注释</p>
</li>
<li><p>为了帮助证明利用大量未标记数据进行事件分类的好处.compare against a supervised <strong>Maximum Entropy baseline</strong> 最大熵模型基线  which makes use of the 500 annotated events using 10-fold crossv alidation</p>
</li>
<li><p>For features, we treat the set of event phrases that co-occur with each (entity, date) pair as a <strong>bag-of-words</strong>, and also include the associated entity. Because many event categories are infrequent, there are often few or no training examples for a category, leading to low performance</p>
</li>
<li><p>仅使用频率来确定哪些事件是重大事件是不够的，因为许多推文都涉及用户日常生活中的常见事件。为了从Twitter提取一般兴趣的重大事件，我们需要某种方法来<strong>衡量实体与日期之间的关联强度</strong>。</p>
</li>
<li><p>然后，我们将提取的三元组添加到第6节中所述的用于推断事件类型的数据集中，并对Gibbs采样执行了50次迭代，以预测新数据上的事件类型，同时使原始数据中的隐藏变量保持不变。。使用的是 streaming inference</p>
</li>
<li><p>按照第7节中的描述对提取的事件进行排名，并从排名最高的100,500和1,000中随机抽取50个事件。我们用4个单独的标准注释了事件。</p>
</li>
<li><p>注释事件 annotate the event</p>
<p>标准：</p>
<p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/Open Domain Event Extraction from Twitter/image-20200705210901858.png" alt="image-20200705210901858" style="zoom:80%;" /></p>
</li>
</ol>
<h3 id="Ranking-Event"><a href="#Ranking-Event" class="headerlink" title="Ranking Event"></a>Ranking Event</h3><p>重要的事件可以被区分为那些与一个独特的日期有强烈关联的事件，而不是在日历中均匀地分布。为了从Twitter中提取一般意义上的重要事件，我们需要某种方法来衡量一个实体和一个日期之间的关联强度。</p>
<p>To <strong>extract significant events of general interests</strong> from Twitter, we thus need some way to <strong>measure the strength of association between an entity and a date.</strong></p>
<p>用 G 检验 (异常值检验)</p>
<p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/Open Domain Event Extraction from Twitter/image-20200308154402927.png" alt="image-20200308154402927"></p>
<p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/Open Domain Event Extraction from Twitter/image-20200308154656117.png" alt="image-20200308154656117"></p>
<h4 id="实验"><a href="#实验" class="headerlink" title="实验"></a>实验</h4><ol>
<li>我们从每个100M的文本中提取了<strong>事件短语</strong>和时态表达式之外的命名实体。提取包括event phrases、temporal expressions 和named entities </li>
<li>predictions (“entity + date + event + type”)</li>
</ol>
<h4 id="相关工作"><a href="#相关工作" class="headerlink" title="相关工作"></a>相关工作</h4><ol>
<li>研究有两个与之相关的关键环节：从Twitter提取特定类型的事件，以及从新闻中提取开放域事件。</li>
</ol>
<p>推文具有高度重复性，因此我们有动力集中精力提取事件的总体表示形式，从而为诸如事件分类之类的任务提供额外的上下文，并通过利用信息的重复性来过滤掉平凡的事件</p>
]]></content>
      <categories>
        <category>Event Extraction</category>
        <category>Topic Model</category>
      </categories>
      <tags>
        <tag>gibbs sampling</tag>
        <tag>twitter</tag>
        <tag>linear chain CRF model</tag>
        <tag>LDA</tag>
        <tag>calendar event</tag>
      </tags>
  </entry>
  <entry>
    <title>Useful stackexchange-answers collect</title>
    <url>/blog/2020/08/25/stackexchange-answer/</url>
    <content><![CDATA[<a id="more"></a>
<p><a href="https://stats.stackexchange.com/questions/330559/why-is-tanh-almost-always-better-than-sigmoid-as-an-activation-function">Why is tanh almost always better than sigmoid as an activation function?</a></p>
]]></content>
      <categories>
        <category>StackExchange</category>
      </categories>
  </entry>
  <entry>
    <title>概念名词解析</title>
    <url>/blog/2020/07/10/%E6%A6%82%E5%BF%B5%E5%90%8D%E8%AF%8D%E8%A7%A3%E6%9E%90/</url>
    <content><![CDATA[<a id="more"></a>
<ol>
<li><p>Dirichlet 过程   <a href="https://juejin.im/entry/58e09c2cda2f60005fcd5573">参考1 掘金</a> </p>
</li>
<li><p>贝叶斯推断</p>
</li>
<li><p>贝叶斯网络  <a href="https://humboldt-wi.github.io/blog/research/information_systems_1819/uncertainty-and-credit-scoring/">Uncertainty in Profit Scoring (Bayesian Deep Learning)</a>  <a href="https://zhuanlan.zhihu.com/p/81170602">知乎大佬Bayesian Neural Networks：贝叶斯神经网络</a></p>
</li>
<li><p>无偏蒙特卡洛梯度 <a href="[https://www.google.com/search?q=%E6%97%A0%E5%81%8F%E8%92%99%E7%89%B9%E5%8D%A1%E6%B4%9B%E6%A2%AF%E5%BA%A6&amp;oq=%E6%97%A0%E5%81%8F%E8%92%99%E7%89%B9%E5%8D%A1%E6%B4%9B%E6%A2%AF%E5%BA%A6&amp;aqs=chrome..69i57.408j0j1&amp;sourceid=chrome&amp;ie=UTF-8](https://www.google.com/search?q=无偏蒙特卡洛梯度&amp;oq=无偏蒙特卡洛梯度&amp;aqs=chrome..69i57.408j0j1&amp;sourceid=chrome&amp;ie=UTF-8">参考</a>)</p>
</li>
<li><p>蒙特卡罗方法（Monte Carlo method）<a href="https://oneraynyday.github.io/ml/2018/05/24/Reinforcement-Learning-Monte-Carlo/">Reinforcement-Learning-Monte-Carlo</a></p>
</li>
<li><p>蒙特卡洛dropout<a href="https://datascience.stackexchange.com/questions/44065/what-is-monte-carlo-dropout">What is Monte Carlo dropout?</a></p>
</li>
<li><p>蒙特卡洛积分 <a href="https://zhuanlan.zhihu.com/p/61611088">Monte Carlo数学原理</a>  <a href="https://www.jianshu.com/p/3d30070932a8">随机模拟-Monte Carlo积分及采样（详述直接采样、接受-拒绝采样、重要性采样）</a></p>
</li>
<li><p>Dropout variational inference Dropout变分推理</p>
</li>
<li><p><a href="https://zhuanlan.zhihu.com/p/56986840">reference—深度学习中的两种不确定性</a></p>
</li>
<li><p><a href="http://www.cs.ox.ac.uk/people/yarin.gal/website/blog_3d801aa532c1ce.html"><em>What My Deep Model Doesn’t Know</em></a></p>
<ul>
<li>prediction uncertainty 预测不确定性</li>
</ul>
</li>
<li><p>变分贝叶斯方法   <a href="https://blog.csdn.net/aws3217150/article/details/57072827">cnblog讲解</a></p>
</li>
<li><p>深度学习 回归任务 高斯噪声</p>
</li>
<li><p>prediction uncertainty 在分类问题中，预测不确定性可以利用蒙特卡洛积分来近似</p>
</li>
<li><p>混合尺度高斯先验（scale mixture gaussian prior）</p>
</li>
<li><p>自动编码器</p>
<p>自动编码器的基本问题在于，它们将其输入转换成其编码矢量，其所在的潜在空间可能不连续，或者允许简单的插值。</p>
</li>
<li><p>变分自动编码器</p>
</li>
<li><p>变分推理variational inference <a href="[http://blog.rexking6.top/2019/05/30/%E5%8F%98%E5%88%86%E6%8E%A8%E7%90%86/](http://blog.rexking6.top/2019/05/30/变分推理/">变分推理</a>)   <a href="https://www.zhihu.com/question/324099754/answer/696409097">变分推断 贝叶斯神经网络有什么论文可以推荐阅读吗？</a></p>
</li>
<li><p>残差</p>
<ul>
<li><p>普通残差：</p>
<p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/概念名词解析/image-20200806103226995.png" alt="image-20200806103226995"  /></p>
</li>
<li><p>残差图：估计观察或预测到的误差error(残差residuals)与随机误差(stochastic error)是否一致</p>
</li>
</ul>
</li>
<li><p><strong>减弱 错误标签 的影响</strong> <a href="https://zhuanlan.zhihu.com/p/110959020">PaperReading：Learning with Noisy Label-深度学习廉价落地</a></p>
</li>
<li><p><a href="https://zhuanlan.zhihu.com/p/65137250">利用不确定性来衡量多任务学习中的损失函数</a></p>
</li>
<li><p>高斯过程 <a href="https://kivy-cn.github.io/Stanford-CS-229-CN/#/Markdown/cs229-gaussian_processes">CS229——Gaussian processes</a>       <a href="cs.cornell.edu/courses/cs4780/2018fa/lectures/lecturenote15.html">cornell——Lecture 15: Gaussian Processes</a>     <a href="https://www.kesci.com/home/project/5d8da105037db3002d3a4c4a">高斯过程Gaussian Process教程</a>     <a href="http://krasserm.github.io/2018/03/19/gaussian-processes/">krasserm blog——code contained</a></p>
<p><a href="http://www.gaussianprocess.org/gpml/chapters/">Gaussian Processes for Machine Learning——book</a></p>
</li>
<li><p>深度高斯过程</p>
</li>
<li><p>点估计 区间估计 </p>
</li>
<li><p><a href="https://www.cnblogs.com/hapjin/p/8834794.html">贝叶斯推断之最大后验概率(MAP)</a>     花书 19.3节</p>
</li>
<li><p>Epsilon greedy search </p>
</li>
<li><p>Confidence calibration 置信度校正    模型的校正度：</p>
<ul>
<li>校正的目的是 makes the confidence scores reflect true probabilities.</li>
<li>A simple way to visualize calibration is plotting accuracy as a function of confidence (known as a <strong><a href="http://www.datascienceassn.org/sites/default/files/Predicting good probabilities with supervised learning.pdf">reliability diagram</a></strong>). </li>
<li>“On Calibration of Modern Neural Networks”</li>
</ul>
</li>
<li><p><a href="https://stackoverflow.com/questions/41455101/what-is-the-meaning-of-the-word-logits-in-tensorflow">What is the meaning of the word logits in TensorFlow?</a>      logits    <a href="https://datascience.stackexchange.com/questions/31041/what-does-logits-in-machine-learning-mean">What does Logits in machine learning mean?</a></p>
</li>
<li><p>Batch Normalization <a href="[http://www.huaxiaozhuan.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/chapters/4_optimization.html](http://www.huaxiaozhuan.com/深度学习/chapters/4_optimization.html">第十节——Batch Normalization</a>)</p>
</li>
<li><p>Isotonic Regression   <a href="[http://vividfree.github.io/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/2015/12/21/classifier-calibration-with-isotonic-regression](http://vividfree.github.io/机器学习/2015/12/21/classifier-calibration-with-isotonic-regression">使用 Isotonic Regression 校准分类器</a>)</p>
</li>
<li><p>共轭梯度法  <a href="[https://alkane0050.fun/2019/05/18/%E5%85%B1%E8%BD%AD%E6%A2%AF%E5%BA%A6%E6%B3%95%E5%88%9D%E6%AD%A5/](https://alkane0050.fun/2019/05/18/共轭梯度法初步/">共轭梯度法的简单分析</a>)</p>
</li>
<li><p>远程监督：主要是对知识库与非结构化文本对齐来自动构建大量训练数据，减少模型对人工标注数据的依赖，增强模型跨领域适应能力。但有  noise  problem </p>
<p><strong>基本假设：</strong>两个实体如果在知识库中存在某种关系，则包含该两个实体的非结构化句子均能表示出这种关系</p>
<p><a href="https://zhuanlan.zhihu.com/p/44772023">知识抽取-实体及关系抽取—DS</a></p>
</li>
<li><p>Knowledge Graph</p>
<ul>
<li><p>Entity-Centric Knowledge Graph</p>
<p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/概念名词解析/image-20200808170218438.png" alt="image-20200808170218438"></p>
<p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/概念名词解析/image-20200808170106351.png" alt="image-20200808170106351" style="zoom:80%;" /></p>
</li>
<li><p>Event-Centric Knowledge Graph</p>
<p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/概念名词解析/image-20200808170316162.png" alt="image-20200808170316162"></p>
</li>
<li></li>
</ul>
</li>
<li><p>事件提取  Event Extraction</p>
<p>定义： Identify the relation between $\color{red}{an event and an entity}$</p>
<p>Event定义：An event is defined as a specific occurrence involving participants</p>
<p>要找到Event trigger, Event Type, Event argument, Argument role</p>
<p>Event 一般与 trigger有紧密关系(Event Identification(TriggerWords))，且 trigger一般为 verb </p>
<p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/概念名词解析/image-20200808170633114.png" alt="image-20200808170633114"></p>
<p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/概念名词解析/image-20200808170527436.png" alt="image-20200808170527436"></p>
</li>
<li><p>开放域事件提取 Open Domain Event Extraction</p>
<ul>
<li><p><strong>Features  Representation</strong> </p>
<ul>
<li><p>Traditional Methods for Feature Representation</p>
<ul>
<li>Human designed features</li>
<li>Too much rely on imprecise NLP tools for feature extraction</li>
<li>Limitations for low-resources languages</li>
</ul>
</li>
<li><p>Dynamic CNN</p>
</li>
<li><p>Argument Attention(Event arguments) </p>
<p>arguments 识别对Event Detection有很大帮助</p>
<p>If we consider the argument phrase “former protege” (Role=Position), we will have more confidence to predict it as an End-·ition event</p>
<ul>
<li>从 contextual words 和 entities 的信息找 arguments—— context representation learning(CRL) 学到 contextual words 和 entities的representation(embedding或是其它)，与对应的attention $\alpha$ 内积</li>
</ul>
</li>
</ul>
</li>
<li><p>Training Data Generation</p>
<ul>
<li><p>External Resources</p>
<ul>
<li><p>Employing <strong>FrameNet</strong>( semantic role descriptions in FrameNet, VerbNet (Kipper etal., 2008) and Propbank (Palmer et al., 2005).) <a href="https://blog.csdn.net/qq_36771895/article/details/91355166">FrameNet &amp; FrameNet Python API </a></p>
<p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/概念名词解析/image-20200813154936884.png" alt="image-20200813154936884" style="zoom:80%;" /></p>
<p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/概念名词解析/image-20200809095354724.png" alt="image-20200809095354724"></p>
<p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/概念名词解析/image-20200809110609620.png" alt="image-20200809110609620"></p>
<p><strong>How to generate training data in FrameNet</strong></p>
<ul>
<li><p>方法1 [Open Domain Event Extraction from Texts]<img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/概念名词解析/image-20200809101143166.png" alt="image-20200809101143166"></p>
<p>对生成数据准确度的评价</p>
<p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/概念名词解析/image-20200809101547986.png" alt="image-20200809101547986"></p>
</li>
<li></li>
</ul>
</li>
<li><p>Employing <strong>Freebase</strong> 2016年，谷歌宣布将Freebase的数据和API服务都迁移至Wikidata，并正式关闭了Freebase  <a href="https://developer.aliyun.com/article/717320">知识图谱调研-Freebase</a></p>
</li>
</ul>
</li>
<li><p>Generating Labeled Data from <strong>Structured KB</strong></p>
<ul>
<li><p>Distant Supervision(Weak) Supervision in <strong>Relation Extraction</strong>($\color{red}{doesn’t}$ work for Event Extraction)</p>
<p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/概念名词解析/image-20200809101755184.png" alt="image-20200809101755184"></p>
<p><code>Automatically Labeled Data Generation for Large Scale Event Extraction</code>文中对Freebase 的介绍</p>
<p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/概念名词解析/image-20200813153441759.png" alt="image-20200813153441759" style="zoom:80%;" /></p>
</li>
<li><p><strong>Triggers</strong> are not given out in existing knowledge bases 所以没法直接用existing  <strong>Structured KB</strong></p>
<p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/概念名词解析/image-20200809103434298.png" alt="image-20200809103434298"></p>
<p>所以可以根据<strong>Structured KB</strong>中的 Key Arguments label back，依据假设提取Trigger：</p>
<ol>
<li><p>Event <strong>Trigger Words Extraction</strong></p>
<p>假设：The sentences mention <strong>all arguments denote such events</strong></p>
</li>
<li><p>Argument Extraction/Role Identification</p>
<p>根据 Trigger words and Entities</p>
<p>语言学上的规律：Arguments for a specific event instance are usually mentioned in multiple sentences，<strong>Only 0.02% of instances can find all argument mentions in one sentence</strong></p>
</li>
</ol>
</li>
<li><p>method</p>
<ol>
<li><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/概念名词解析/image-20200809110639296.png" alt="image-20200809110639296"></li>
</ol>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li><p>关系抽取 Relation Extraction</p>
<p>定义： Identify the relation between $\color{}{}$ $\color{red}{two given entities}$</p>
<p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/概念名词解析/image-20200808171310420.png" alt="image-20200808171310420"></p>
<p><a href="https://zhuanlan.zhihu.com/p/44772023">实体及关系抽取</a></p>
<p><a href="https://zhuanlan.zhihu.com/p/50903358">事件抽取</a></p>
</li>
<li><p>Event Extraction(EE) 事件提取</p>
<p><a href="[https://chriszhangcx.github.io/%E5%A6%82%E4%BD%95%E7%8C%9C%E5%87%BA%E5%A5%B3%E6%9C%8B%E5%8F%8B%E8%AF%9D%E4%B8%AD%E7%9A%84%E5%90%AB%E4%B9%89%EF%BC%9F%E2%80%94%E2%80%94%E5%85%B3%E4%BA%8E%E4%BA%8B%E4%BB%B6%E6%8A%BD%E5%8F%96-Event-Extraction/#fn_%E5%8D%9A%E5%AE%A2](https://chriszhangcx.github.io/如何猜出女朋友话中的含义？——关于事件抽取-Event-Extraction/#fn_博客">reference1—chriszhangcx blog</a>) and <a href="http://www.caojiarun.com/2019/11/Introduction-of-Event-Extraction/">2—Introduction of Event Extraction</a></p>
<p><a href="https://pdfs.semanticscholar.org/0eef/643c744ac3e4ffd68d4328b5f445dbf9e10e.pdf">A Survey of Open Domain Event Extraction</a></p>
<p><a href="https://chriszhangcx.github.io/如何猜出女朋友话中的含义？——关于事件抽取-Event-Extraction/">事件抽取(Event Extraction)经典模型</a></p>
</li>
<li><p>POS tagged pos标记<a href="https://www.tutorialspoint.com/natural_language_processing/natural_language_processing_part_of_speech_tagging.htm">Part of Speech (PoS) Tagging</a></p>
<ul>
<li>概率方法 (CRF GMM) <a href="https://medium.com/analytics-vidhya/pos-tagging-using-conditional-random-fields-92077e5eaa31">Identifying Part of Speech Tags using Conditional Random Fields</a></li>
</ul>
</li>
<li><p>ACE Corpus：ACE2005: 529 Training, 33 Development, 40 Testing</p>
</li>
<li><p>NLTK <a href="https://www.nltk.org/">Natural Language Toolkit3.5</a></p>
</li>
<li><p>[Attention Mechanism](<a href="https://blog.floydhub.com/attention-mechanism">https://blog.floydhub.com/attention-mechanism</a></p>
</li>
<li><p>截断梯度法  <a href="https://zr9558.com/2016/01/12/truncated-gradient/">TRUNCATED GRADIENT </a></p>
</li>
<li><p>burn-in (Gibbs sampling) <a href="http://users.stat.umn.edu/~geyer/mcmc/burn.html">Burn-In is Unnecessary</a></p>
</li>
<li><p>LDA 主题模型 <a href="https://zhuanlan.zhihu.com/p/31470216">一文详解LDA主题模型</a></p>
</li>
<li><p><a href="https://en.wikipedia.org/wiki/G-test">G-test</a></p>
</li>
<li><p>共指和指代消解 <a href="[https://looperxx.github.io/CS224n-2019-16-Coreference%20Resolution/](https://looperxx.github.io/CS224n-2019-16-Coreference Resolution/">Coreference Resolution</a>)</p>
</li>
<li><p>semantic role labeling representation(SRL) <a href="https://web.stanford.edu/~jurafsky/slp3/20.pdf">Semantic    Role    Labeling</a></p>
<p> meaning  representations：Abstract  Meaning  Representation  (AMR)、Stanford  Typed  Dependencies 、FrameNet  <a href="https://towardsdatascience.com/meaning-representation-and-srl-assuming-there-is-some-meaning-741f35bfdd6">Meaning Representation and SRL: assuming there is some meaning</a></p>
<p><strong><a href="http://people.cs.georgetown.edu/nschneid/cosc672/s17/amr-papers.html">Advanced Semantic Representation</a></strong></p>
<p><strong><a href="https://github.com/nschneid/amr-tutorial/">AMR Tutorial</a></strong></p>
<p><a href="https://github.com/amrisi/amr-guidelines/blob/master/amr.md">Abstract Meaning Representation (AMR) 1.2Specification</a></p>
</li>
<li><p><a href="http://blog.openkg.cn/%E7%BB%BC%E8%BF%B0-%E4%BA%8B%E4%BB%B6%E6%8A%BD%E5%8F%96%E5%8F%8A%E6%8E%A8%E7%90%86-%E4%B8%8A/">综述 | 事件抽取及推理 (上)</a></p>
</li>
<li><p>word sense 词的意思<a href="https://en.wikipedia.org/wiki/Word_sense">Word sense</a></p>
</li>
<li><p><a href="https://zhuanlan.zhihu.com/p/109122090">NLP的任务</a></p>
</li>
<li><p>Word2Vec — <a href="[http://www.huaxiaozhuan.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/chapters/8_word_representation.html](http://www.huaxiaozhuan.com/深度学习/chapters/8_word_representation.html">Skip-Gram</a>) and CBOW </p>
</li>
<li><p>WordNet sense 到 <a href="https://catalog.ldc.upenn.edu/LDC2013T19">OntoNotes sense</a>的 mapping tool </p>
</li>
<li><p><a href="http://clear.colorado.edu/compsem/index.php?page=lexicalresources&amp;sub=ontonotes">Ontonotes Sense Groups</a></p>
</li>
<li><p>分布语义，Distributional Semantic Representation，基于分布假设：<em>linguistic items with similar distributions have similar meanings.</em></p>
</li>
<li><p>GRU   <a href="https://zh.d2l.ai/chapter_recurrent-neural-networks/gru.html">动手深度学习GRU</a></p>
</li>
<li><p>DAG有向无环图：</p>
</li>
<li><p>syntactic parsing语法分析:</p>
<ul>
<li>短语结构树(phrase structure tree 对应语法 context-free grammar CFG 上下文无关法)</li>
<li>依存句法树(dependency parse tree)： 直观来讲，依存句法分析识别句子中的“主谓宾”、“定状补”这些语法成分，并分析各语法成分之间的关系。</li>
</ul>
</li>
<li><p>语义依存分析 (Semantic Dependency Parsing, SDP)：分析句子各个语言单位之间的语义关联，并将语义关联以依存结构呈现</p>
<p><a href="https://my.oschina.net/duanvincent/blog/761108">依存句法分析与语义依存分析的区别</a></p>
<p><a href="https://blog.csdn.net/glory1234work2115/article/details/54906343">Stanford-parser依存句法关系解释</a></p>
</li>
<li><p>Distributional Representation和Distributed Representation <a href="https://zhuanlan.zhihu.com/p/22386230">聊聊文本的分布式表示—邱锡鹏</a></p>
</li>
<li><p><strong>ACE2005:</strong> </p>
<p>ACE2005定义的事件抽取是：(1) 以句子级为单位，识别句子中出现的trigger词及类型，(2) 针对每个trigger词，判断其的论元argument以及论元类型。下图即是ACE2005任务的一个示例。</p>
</li>
<li><p>RNN及变体和BPTT <a href="https://zhuanlan.zhihu.com/p/27485750">RNN 其常见架构</a></p>
</li>
<li><p>dependency parsing <a href="https://looperxx.github.io/CS224n-2019-05-Linguistic Structure Dependency Parsing/">笔记1</a>  <a href="https://www.hankcs.com/nlp/cs224n-dependency-parsing.html">笔记2</a>  <a href="https://zhuanlan.zhihu.com/p/66268929">笔记3</a></p>
</li>
<li><p>bootstrapping 自助法</p>
</li>
<li><p>ELMo  <a href="https://zhuanlan.zhihu.com/p/38254332">ELMo最好用词向量Deep Contextualized Word Representations</a></p>
</li>
<li><p><a href="https://gombru.github.io/2019/04/03/ranking_loss/">Understanding Ranking Loss, Contrastive Loss, Margin Loss, Triplet Loss, Hinge Loss and all those confusing names</a></p>
</li>
<li><p><strong>Multi-instance Learning (MIL)</strong> 多实例学习</p>
<p><a href="https://zhuanlan.zhihu.com/p/40812750">知乎参考1</a></p>
<p><a href="http://www.lamda.nju.edu.cn/CH.Data.ashx?AspxAutoDetectCookieSupport=1#code">南大周志华教授 miVLAD and miFV,</a></p>
</li>
<li><p>Snorkel - 基于弱监督学习的数据标注工具</p>
<p>snorkel <a href="https://zhuanlan.zhihu.com/p/55138499">Sonrkel—从0开始构建机器学习项目</a></p>
<p><a href="https://zhuanlan.zhihu.com/p/78699409">reference1</a></p>
<p>可以视为弱监督源的示例包括：</p>
<ul>
<li>领域启发式搜索，例如：常见模式、经验法则等</li>
<li>已有的正确标注的数据，虽然不完全适用于当前的任务，但有一定的作用。这在传统上被称为远程监督</li>
<li>不可靠的非专家标注人，例如：众包标注</li>
</ul>
<p>标准函数中编码了领域相关的推理规则，可以使用入正则表达式、经验规则等常见的模式进行标注。这样生成的标注是包含噪声的，并且可能彼此冲突。</p>
<p>常见类型的标注函数：</p>
<ul>
<li>硬编码的推导：通常使用正则表达式</li>
<li>语义结构：例如，使用<a href="https://link.zhihu.com/?target=http%3A//sc.hubwiz.com/codebag/zh-spacy-model/">spacy</a>得到的依存关系结构</li>
<li>远程监督：例如使用外部的知识库</li>
<li>有噪声人工标注：例如众包标注</li>
<li>外部模型：其他可以给出有用标注信号的模型</li>
</ul>
<p>当编写好标注函数后，Snorkel将利用这些不同的标注函数之间的冲突训练一个<strong>标注模型（Label Model）</strong>来估算不同标注函数的标注准确度。通过观察标注函数之间的彼此一致性，标注模型能够学习到每个监督源的准确度。</p>
<p>例如，如果一个标注函数的标注结果总是得到其他标注函数的认可，那么这个标注函数将有一个高准确率，而如果一个标注函数总是与其他标注函数的结果不一致，那么这个标注函数将得到一个较低的准确率。通过整合所有的标注函数的投票结果（以其估算准确度作为权重），我们就可以为每个数据样本<strong>分配一个包含噪声的标注（0~1之间）</strong>，而不是一个硬标注（要么0，要么1）。</p>
<p>接下来，当标注一个新的数据点时，每一个标注函数都会对分类进行投票：正、负或弃权。基于这些投票以及标注函数的估算精度，标注模型能够程序化到为上百万的数据点给出概率性标注。最终的目标是训练出一个可以超越标注函数的泛化能力的分类器.通过这种方法得到海量的低质量监督，然后使用统计技术处理有噪标注，我们可以训练出高质量的模型。</p>
<p><a href="https://zhuanlan.zhihu.com/p/55138499">参考—Sonrkel—从0开始构建机器学习项目（完善中）</a></p>
<p>sample_and_sgd函数:    (计算在某一分布下的期望时，用蒙特卡洛积分近似， 去掉极限可以看成是采样点的均值)</p>
<p><img src="https://www.zhihu.com/equation?tex=%5Ctheta_j%5E%7B%28t%29%7D%3D%5Ctheta_j%5E%7B%28t-1%29%7D-%5Calpha%5Csum_%7Bk%3D1%7D%5E%7BN%7D%5Cleft%5C%7B+%5Cleft%5B+%5Cphi_j%28%5Chat%5Clambda_%7Bij%7D%5E%7B%28k%29%7D%2C+%5Chat+y_i%5E%7B%28k%29%7D%29+%5Cright%5D_%7B%7B%5Chat%5CLambda_i%5E%7B%28k%29%7D%2C+%5Chat+y_i%5E%7B%28k%29%7D+%5Csim+P%28%5CLambda_i%2C+y_i%29%7D%7D+-%5Cleft%5B+%5Cphi_j%28%5Clambda_%7Bij%7D%2C+%5Chat+y_i%5E%7B%28k%29%7D%29+%5Cright%5D_%7B%5Chat+y_i%5E%7B%28k%29%7D+%5Csim+P%28y_i%7C%5CLambda_i%29%7D+%5Cright%5C%7D" alt="[公式]"></p>
<p>为了获得指定分布的样本点，我们需要进行采样。对于高维的联合分布，我们通常使用Gibbs采样算法</p>
</li>
<li><p>Gibbs采样算法  <a href="http://nitro.biosci.arizona.edu/courses/EEB596/handouts/Gibbs.pdf">Gibbs采样的原理</a></p>
</li>
<li><p>PGM 概率图模型 </p>
<p><a href="https://link.zhihu.com/?target=http%3A//www.isiweb.ee.ethz.ch/papers/arch/aloe-2004-spmagffg.pdf">An Introduction to Factor Graphs</a></p>
<p><a href="https://zhuanlan.zhihu.com/p/55138499">Snorkel、PGM and sampling、SGD相关论文</a></p>
</li>
<li><p><a href="https://www.cs.toronto.edu/~radford/csc2506/factor.pdf">Factor Graphs and the Sum-Product Algorithm</a></p>
</li>
<li><p>结构学习 structure learning   </p>
<p>贝叶斯网路的学习包括：参数学习、<a href="http://www.huaxiaozhuan.com/统计学习/chapters/16_CRF.html">结构学习</a></p>
<p>李宏毅 4 episode <a href="https://www.youtube.com/watch?v=5OYu0vxXEv8&amp;t=16s">Structured Learning 1: Introduction</a></p>
</li>
<li><p>半监督 <a href="https://www.youtube.com/watch?v=fX_guE7JNnY&amp;list=PLJV_el3uVTsPy9oCRY30oBPNLCo89yu49&amp;index=21">ML Lecture 12: Semi-supervised</a></p>
</li>
<li><p>利用生成模型从噪声标签源合成标签：</p>
</li>
<li><p>玻尔兹曼机 RBM</p>
<p><a href="https://www.cnblogs.com/pinard/p/6530523.html">受限玻尔兹曼机（RBM）原理总结</a></p>
</li>
<li><p>命名实体 NER  <a href="https://zhuanlan.zhihu.com/p/135453456">命名实体识别 NER 论文综述</a></p>
</li>
<li><p>Highway Networks  <a href="https://zhuanlan.zhihu.com/p/38130339">Highway Networks及HBilstm Network</a></p>
</li>
<li><p>entity  span  detection：找出 文本中指向同一实体的所有文段，这是因为，人们对同一个实体往往有多种不同的说法，如代词、省略词、别名等等。 <a href="https://zhuanlan.zhihu.com/p/126544790">reference—基于span prediction的共指消解模型</a></p>
<p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/概念名词解析/image-20200816172814181.png" alt="image-20200816172814181" style="zoom:80%;" /></p>
</li>
<li><p><a href="https://www.zhihu.com/question/62399257">如何理解LSTM后接CRF？</a></p>
<p><a href="https://www.zhihu.com/question/46688107">CRF和LSTM 模型在序列标注上的优劣？</a></p>
</li>
<li><p>Viterbi(维特比算法)<a href="https://zhuanlan.zhihu.com/p/59889195">HMM+Viterbi(维特比算法)+最短路径分析</a></p>
</li>
<li><p>知识图谱上的<strong>实体消歧</strong>  <a href="http://kugwzk.info/index.php/archives/3204">一些关于NER任务调研的小思考</a></p>
</li>
<li><p>实体词典：entity dictionary</p>
</li>
<li><p><strong>What are Chunks ?</strong><br>Chunks are made up of words and the kinds of words are defined using the part-of-speech tags. One can even define a pattern or words that can’t be a part of chuck and such words are known as chinks.</p>
<p><strong>What are IOB tags ?</strong><br>It is a format for chunks. These tags are similar to part-of-speech tags but provide can denote the inside, utside, and the beginning of a chunk. Not just noun phrase but multiple different chunk phrase types are allowed here.</p>
<p><a href="https://www.geeksforgeeks.org/nlp-iob-tags/">code</a></p>
<p><a href="https://www.nltk.org/book/ch07.html">7. Extracting Information from Text—nltk</a></p>
</li>
<li><p><a href="https://zhuanlan.zhihu.com/p/38163970">Karush-Kuhn-Tucker (KKT)条件</a></p>
</li>
<li><p><a href="http://faculty.marshall.usc.edu/gareth-james/ISL/">An Introduction to Statistical Learning with Applications in R</a></p>
</li>
<li><p><a href="https://link.springer.com/referenceworkentry/10.1007%2F978-0-387-30164-8_140">collective classification</a>  <em>jointly</em> determine the correct label assignments of all the objects in the network.</p>
</li>
<li><p><a href="https://en.wikipedia.org/wiki/Ontology_alignment">ontology alignment</a> 本体对齐</p>
</li>
<li><p><a href="https://en.wikipedia.org/wiki/Personalized_medicine">personalized medicine</a> 个性化医学</p>
</li>
<li><p><a href="https://link.springer.com/referenceworkentry/10.1007%2F978-1-4939-7131-2_379">opinion diffusion</a> 意见传播</p>
</li>
<li><p>trust in social networksolollllllllllllllllllll+</p>
</li>
<li><p><a href="https://www.jianshu.com/p/24fcf19b78da">graph summarization</a></p>
</li>
<li><p><a href="https://en.wikipedia.org/wiki/T-norm">t-norm</a>:    t-norm is a binary algebraic operation on the interval [0, 1],  三角范数，用于模糊逻辑</p>
</li>
<li><p><a href="https://blog.csdn.net/jbb0523/article/details/79437497"> MPE inference</a> 贝叶斯网络与最大可能解释(MPE)问题 MostProbable Explanation, MPE</p>
</li>
<li><p>共识优化  <a href="https://www.cvxpy.org/examples/applications/consensus_opt.html">consensus optimization </a></p>
</li>
<li><p><strong>knowledge distillation知识蒸馏：</strong> <a href="https://zhuanlan.zhihu.com/p/51563760">知乎1</a>,  <a href="https://zhuanlan.zhihu.com/p/53864403">知乎2</a>,  <a href="https://github.com/lhyfst/knowledge-distillation-papers">paper reading list</a></p>
</li>
<li><p>后验正则化（posterior regularization）方法</p>
</li>
<li><p>K-dimensional  probability  simplex</p>
<p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/概念名词解析/3987bf963ef4ab9a7920cbb1d57056c3" alt="img"></p>
</li>
<li><p>max-over-time 池化层，NLP中的CNN:  <a href="https://blog.csdn.net/malefactor/article/details/51078135">参考1cnblog</a>  <a href="https://stackoverflow.com/questions/48549670/pooling-vs-pooling-over-time">Pooling vs Pooling-over-time</a></p>
</li>
<li><p><a href="http://www.gabormelli.com/RKB/Bidirectional_LSTM-CNN_(BLSTM-CNN">Bidirectional LSTM-CNN (BLSTM-CNN) Training System</a>_Training_System)</p>
</li>
<li><p>projected gradient descent (PGD)投影梯度下降 </p>
<p><a href="https://medium.com/數學-人工智慧與蟒蛇/投影梯度下降法解正則化問題-以lasso回歸為例-6fc70e4efe65">投影梯度下降法解正则化问题：以Lasso回归为例</a></p>
<p><a href="http://maths.nju.edu.cn/~hebma/New-VS/SF10C-PG.pdf">Professor Bingsheng He—基于梯度投影的凸优化收缩算法和下降算法</a></p>
</li>
<li><p>利普西茨条件 </p>
<p><a href="https://math.berkeley.edu/~mgu/MA128ASpring2017/MA128ALectureWeek9.pdf">Lipschitz condition - Berkeley Math</a></p>
<p><a href="https://zhuanlan.zhihu.com/p/27554191">非凸优化基石：Lipschitz Condition - 知乎</a></p>
<p><a href="https://mathcs.holycross.edu/~spl/old_courses/304_fall_2008/handouts/existunique.pdf">Existence and Uniqueness 1 Lipschitz Conditions</a></p>
</li>
<li><p><a href="https://bindog.github.io/blog/2018/02/10/model-explanation/">CAM 和 Grad-CAM</a></p>
<p>热力图？Class Activation Mapping</p>
</li>
</ol>
<h4 id="相关论文"><a href="#相关论文" class="headerlink" title="相关论文"></a><strong>相关论文</strong></h4><ol>
<li>Joint event extraction via recurrent neural networks <a href="https://zhuanlan.zhihu.com/p/63215208">论文解读</a></li>
<li><a href="https://www.cnblogs.com/kisetsu/p/11906681.html">【论文笔记】Graph Convolutional Networks with Argument-Aware Pooling for Event Detection</a>      <a href="https://www.codenong.com/cs105391780/">笔记2</a></li>
<li>Jointly Extracting Event Triggers and Arguments by Dependency-Bridge RNN and Tensor-Based Argument Interaction   <a href="https://www.jianshu.com/p/9030d25215e3">笔记1</a>   <a href="https://blog.csdn.net/JYZ4MFC/article/details/83309135">笔记2</a></li>
</ol>
]]></content>
  </entry>
  <entry>
    <title>nlp-tool</title>
    <url>/blog/2020/08/25/nlp-tool/</url>
    <content><![CDATA[<a id="more"></a>
<p><a href="http://www.chokkan.org/software/crfsuite/">CRFsuite</a></p>
]]></content>
  </entry>
</search>
