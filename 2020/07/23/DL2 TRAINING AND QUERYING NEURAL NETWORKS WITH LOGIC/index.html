<!DOCTYPE html>
<html lang="en">
<head>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 5.0.2">
  <link rel="apple-touch-icon" sizes="180x180" href="/blog/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/blog/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/blog/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/blog/images/logo.svg" color="#222">

<link rel="stylesheet" href="/blog/css/main.css">


<link rel="stylesheet" href="/blog/lib/font-awesome/css/font-awesome.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"jasonguojz.github.io","root":"/blog/","scheme":"Muse","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":true,"show_result":true,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},"path":"search.xml"};
  </script>

  <meta name="description" content="将包含逻辑比较符号以及合取析取求反的rules通过论文中给出的转化方式转化成几乎处处可微的损失函数，基于标准梯度方法进行优化">
<meta property="og:type" content="article">
<meta property="og:title" content="DL2- TRAINING AND QUERYING NEURAL NETWORKS WITH LOGIC">
<meta property="og:url" content="https://jasonguojz.github.io/blog/2020/07/23/DL2%20TRAINING%20AND%20QUERYING%20NEURAL%20NETWORKS%20WITH%20LOGIC/index.html">
<meta property="og:site_name" content="Guo Jiazhen&#39;s Blog">
<meta property="og:description" content="将包含逻辑比较符号以及合取析取求反的rules通过论文中给出的转化方式转化成几乎处处可微的损失函数，基于标准梯度方法进行优化">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/DL2 TRAINING AND QUERYING NEURAL NETWORKS WITH LOGIC/image-20200729110021659.png">
<meta property="og:image" content="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/DL2 TRAINING AND QUERYING NEURAL NETWORKS WITH LOGIC/image-20200729170259031.png">
<meta property="og:image" content="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/DL2 TRAINING AND QUERYING NEURAL NETWORKS WITH LOGIC/image-20200728221751057.png">
<meta property="og:image" content="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/DL2 TRAINING AND QUERYING NEURAL NETWORKS WITH LOGIC/image-20200728222100274.png">
<meta property="og:image" content="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/DL2 TRAINING AND QUERYING NEURAL NETWORKS WITH LOGIC/image-20200728230500048.png">
<meta property="og:image" content="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/DL2 TRAINING AND QUERYING NEURAL NETWORKS WITH LOGIC/image-20200728234543352.png">
<meta property="og:image" content="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/DL2 TRAINING AND QUERYING NEURAL NETWORKS WITH LOGIC/image-20200729102545691.png">
<meta property="og:image" content="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/DL2 TRAINING AND QUERYING NEURAL NETWORKS WITH LOGIC/image-20200729110408304.png">
<meta property="og:image" content="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/DL2 TRAINING AND QUERYING NEURAL NETWORKS WITH LOGIC/image-20200729110918906.png">
<meta property="og:image" content="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/DL2 TRAINING AND QUERYING NEURAL NETWORKS WITH LOGIC/image-20200729113054171.png">
<meta property="og:image" content="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/DL2 TRAINING AND QUERYING NEURAL NETWORKS WITH LOGIC/image-20200729114140098.png">
<meta property="og:image" content="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/DL2 TRAINING AND QUERYING NEURAL NETWORKS WITH LOGIC/image-20200729115217508.png">
<meta property="og:image" content="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/DL2 TRAINING AND QUERYING NEURAL NETWORKS WITH LOGIC/image-20200729141756243.png">
<meta property="og:image" content="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/DL2 TRAINING AND QUERYING NEURAL NETWORKS WITH LOGIC/image-20200729141948167.png">
<meta property="og:image" content="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/DL2 TRAINING AND QUERYING NEURAL NETWORKS WITH LOGIC/image-20200729142326161.png">
<meta property="og:image" content="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/DL2 TRAINING AND QUERYING NEURAL NETWORKS WITH LOGIC/image-20200729142716002.png">
<meta property="og:image" content="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/DL2 TRAINING AND QUERYING NEURAL NETWORKS WITH LOGIC/image-20200729142835982.png">
<meta property="og:image" content="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/DL2 TRAINING AND QUERYING NEURAL NETWORKS WITH LOGIC/image-20200729145018404.png">
<meta property="og:image" content="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/DL2 TRAINING AND QUERYING NEURAL NETWORKS WITH LOGIC/image-20200729145120347.png">
<meta property="og:image" content="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/DL2 TRAINING AND QUERYING NEURAL NETWORKS WITH LOGIC/image-20200729152436198.png">
<meta property="og:image" content="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/DL2 TRAINING AND QUERYING NEURAL NETWORKS WITH LOGIC/image-20200729153711364.png">
<meta property="og:image" content="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/DL2 TRAINING AND QUERYING NEURAL NETWORKS WITH LOGIC/image-20200729154226150.png">
<meta property="og:image" content="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/DL2 TRAINING AND QUERYING NEURAL NETWORKS WITH LOGIC/image-20200729154520611.png">
<meta property="og:image" content="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/DL2 TRAINING AND QUERYING NEURAL NETWORKS WITH LOGIC/image-20200729154554466.png">
<meta property="og:image" content="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/DL2 TRAINING AND QUERYING NEURAL NETWORKS WITH LOGIC/image-20200729154711886.png">
<meta property="og:image" content="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/DL2 TRAINING AND QUERYING NEURAL NETWORKS WITH LOGIC/image-20200729155217164.png">
<meta property="og:image" content="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/DL2 TRAINING AND QUERYING NEURAL NETWORKS WITH LOGIC/image-20200729163700603.png">
<meta property="og:image" content="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/DL2 TRAINING AND QUERYING NEURAL NETWORKS WITH LOGIC/image-20200729164530533.png">
<meta property="og:image" content="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/DL2 TRAINING AND QUERYING NEURAL NETWORKS WITH LOGIC/image-20200729164459441.png">
<meta property="og:image" content="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/DL2 TRAINING AND QUERYING NEURAL NETWORKS WITH LOGIC/image-20200729170004311.png">
<meta property="og:image" content="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/DL2 TRAINING AND QUERYING NEURAL NETWORKS WITH LOGIC/image-20200729165954557.png">
<meta property="og:image" content="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/DL2 TRAINING AND QUERYING NEURAL NETWORKS WITH LOGIC/image-20200729170031260.png">
<meta property="og:image" content="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/DL2 TRAINING AND QUERYING NEURAL NETWORKS WITH LOGIC/image-20200729170100795.png">
<meta property="og:image" content="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/DL2 TRAINING AND QUERYING NEURAL NETWORKS WITH LOGIC/image-20200729170259031.png">
<meta property="og:image" content="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/DL2 TRAINING AND QUERYING NEURAL NETWORKS WITH LOGIC/image-20200729170512198.png">
<meta property="og:image" content="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/DL2 TRAINING AND QUERYING NEURAL NETWORKS WITH LOGIC/image-20200729171104065.png">
<meta property="og:image" content="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/DL2 TRAINING AND QUERYING NEURAL NETWORKS WITH LOGIC/image-20200729171314064.png">
<meta property="og:image" content="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/DL2 TRAINING AND QUERYING NEURAL NETWORKS WITH LOGIC/image-20200729171814154.png">
<meta property="og:image" content="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/DL2 TRAINING AND QUERYING NEURAL NETWORKS WITH LOGIC/image-20200729204215351.png">
<meta property="og:image" content="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/DL2 TRAINING AND QUERYING NEURAL NETWORKS WITH LOGIC/image-20200729205243397.png">
<meta property="og:image" content="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/DL2 TRAINING AND QUERYING NEURAL NETWORKS WITH LOGIC/image-20200729205545246.png">
<meta property="og:image" content="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/DL2 TRAINING AND QUERYING NEURAL NETWORKS WITH LOGIC/image-20200729220549693.png">
<meta property="og:image" content="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/DL2 TRAINING AND QUERYING NEURAL NETWORKS WITH LOGIC/image-20200729220600062.png">
<meta property="og:image" content="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/DL2 TRAINING AND QUERYING NEURAL NETWORKS WITH LOGIC/image-20200729221406131.png">
<meta property="og:image" content="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/DL2 TRAINING AND QUERYING NEURAL NETWORKS WITH LOGIC/image-20200729221704696.png">
<meta property="og:image" content="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/DL2 TRAINING AND QUERYING NEURAL NETWORKS WITH LOGIC/image-20200729221727188.png">
<meta property="og:image" content="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/DL2 TRAINING AND QUERYING NEURAL NETWORKS WITH LOGIC/image-20200729221859620.png">
<meta property="og:image" content="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/DL2 TRAINING AND QUERYING NEURAL NETWORKS WITH LOGIC/image-20200729221911682.png">
<meta property="og:image" content="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/DL2 TRAINING AND QUERYING NEURAL NETWORKS WITH LOGIC/image-20200729222035065.png">
<meta property="og:image" content="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/DL2 TRAINING AND QUERYING NEURAL NETWORKS WITH LOGIC/image-20200729222743867.png">
<meta property="og:image" content="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/DL2 TRAINING AND QUERYING NEURAL NETWORKS WITH LOGIC/image-20200729223542692.png">
<meta property="og:image" content="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/DL2 TRAINING AND QUERYING NEURAL NETWORKS WITH LOGIC/image-20200729223906576.png">
<meta property="og:image" content="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/DL2 TRAINING AND QUERYING NEURAL NETWORKS WITH LOGIC/image-20200729224145257.png">
<meta property="og:image" content="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/DL2 TRAINING AND QUERYING NEURAL NETWORKS WITH LOGIC/image-20200729225442306.png">
<meta property="article:published_time" content="2020-07-22T16:00:00.000Z">
<meta property="article:modified_time" content="2020-08-22T09:07:44.755Z">
<meta property="article:tag" content="querying neural network">
<meta property="article:tag" content="differentiable loss">
<meta property="article:tag" content="convex set">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/DL2 TRAINING AND QUERYING NEURAL NETWORKS WITH LOGIC/image-20200729110021659.png">

<link rel="canonical" href="https://jasonguojz.github.io/blog/2020/07/23/DL2%20TRAINING%20AND%20QUERYING%20NEURAL%20NETWORKS%20WITH%20LOGIC/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'en'
  };
</script>

  <title>DL2- TRAINING AND QUERYING NEURAL NETWORKS WITH LOGIC | Guo Jiazhen's Blog</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript><!-- hexo-inject:begin --><!-- hexo-inject:end -->

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/blog/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">Guo Jiazhen's Blog</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="menu">
        <li class="menu-item menu-item-home">

    <a href="/blog/" rel="section"><i class="fa fa-fw fa-home"></i>Home</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/blog/tags/" rel="section"><i class="fa fa-fw fa-tags"></i>Tags<span class="badge">77</span></a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/blog/categories/" rel="section"><i class="fa fa-fw fa-th"></i>Categories<span class="badge">28</span></a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/blog/archives/" rel="section"><i class="fa fa-fw fa-archive"></i>Archives<span class="badge">21</span></a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>Search
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off"
           placeholder="Searching..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div id="search-result">
  <div id="no-result">
    <i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>
  </div>
</div>

    </div>
  </div>

</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content post posts-expand">
            

    
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://jasonguojz.github.io/blog/2020/07/23/DL2%20TRAINING%20AND%20QUERYING%20NEURAL%20NETWORKS%20WITH%20LOGIC/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/blog/images/avatar.gif">
      <meta itemprop="name" content="">
      <meta itemprop="description" content="谦卑">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Guo Jiazhen's Blog">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          DL2- TRAINING AND QUERYING NEURAL NETWORKS WITH LOGIC
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2020-07-23 00:00:00" itemprop="dateCreated datePublished" datetime="2020-07-23T00:00:00+08:00">2020-07-23</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2020-08-22 17:07:44" itemprop="dateModified" datetime="2020-08-22T17:07:44+08:00">2020-08-22</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/blog/categories/Neural-Networks-with-Logic-Rules/" itemprop="url" rel="index"><span itemprop="name">Neural Networks with Logic Rules</span></a>
                </span>
            </span>

          
            <span id="/blog/2020/07/23/DL2%20TRAINING%20AND%20QUERYING%20NEURAL%20NETWORKS%20WITH%20LOGIC/" class="post-meta-item leancloud_visitors" data-flag-title="DL2- TRAINING AND QUERYING NEURAL NETWORKS WITH LOGIC" title="Views">
              <span class="post-meta-item-icon">
                <i class="fa fa-eye"></i>
              </span>
              <span class="post-meta-item-text">Views: </span>
              <span class="leancloud-visitors-count"></span>
            </span>
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="fa fa-comment-o"></i>
      </span>
      <span class="post-meta-item-text">Valine: </span>
    
    <a title="valine" href="/blog/2020/07/23/DL2%20TRAINING%20AND%20QUERYING%20NEURAL%20NETWORKS%20WITH%20LOGIC/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/blog/2020/07/23/DL2%20TRAINING%20AND%20QUERYING%20NEURAL%20NETWORKS%20WITH%20LOGIC/" itemprop="commentCount"></span>
    </a>
  </span>
  
  <br>
            <span class="post-meta-item" title="Symbols count in article">
              <span class="post-meta-item-icon">
                <i class="fa fa-file-word-o"></i>
              </span>
                <span class="post-meta-item-text">Symbols count in article: </span>
              <span>9k</span>
            </span>
            <span class="post-meta-item" title="Reading time">
              <span class="post-meta-item-icon">
                <i class="fa fa-clock-o"></i>
              </span>
                <span class="post-meta-item-text">Reading time &asymp;</span>
              <span>8 mins.</span>
            </span>
            <div class="post-description"><div align=center> 将包含逻辑比较符号以及合取析取求反的rules通过论文中给出的转化方式转化成几乎处处可微的损失函数，基于标准梯度方法进行优化</div></div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <a id="more"></a>
<h3 id="『』阅读笔记"><a href="#『』阅读笔记" class="headerlink" title="『』阅读笔记"></a>『』阅读笔记</h3><ol>
<li>将rules 逻辑规则，论文中的是在网络中纳入约束。方式是通过将 包含逻辑比较符号以及合取析取求反的rules通过论文中给出的<strong>转化</strong>方式转化成几乎处处<strong>可微的损失函数</strong>。</li>
<li>将逻辑约束转换为具有所需数学特性的可微分损失函数 differentiable loss，基于标准梯度方法进行优化</li>
<li>用期望来建模，把最大化满足约束找到满足的输入集转化成最小化对约束的最大冲突，然后拆成内部的最大化目标，找到满足的输入集，再带入外部的最小化目标，优化网络的参数。</li>
<li>因为 3 中描述的第一步往往很难优化，因此对输入的变量 z 先投影到一个 convex set，而不是将变量是从convex set采样的作为constraint</li>
</ol>
<h4 id="code-for-DL2"><a href="#code-for-DL2" class="headerlink" title="code for DL2 "></a><a target="_blank" rel="noopener" href="https://github.com/eth-sri/dl2">code for DL2 </a></h4><h4 id="project-地址"><a href="#project-地址" class="headerlink" title="project 地址"></a><a target="_blank" rel="noopener" href="https://www.sri.inf.ethz.ch/publications/fischer2019dl2">project 地址</a></h4><h3 id="专有名词"><a href="#专有名词" class="headerlink" title="专有名词"></a>专有名词</h3><ol>
<li><p>projected gradient descent (PGD)</p>
</li>
<li><p>In <a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Mathematical_logic">mathematical logic</a>, a <strong>literal</strong> is an <a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Atomic_formula">atomic formula</a> (atom) or its <a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Negation">negation</a>.</p>
<p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/DL2 TRAINING AND QUERYING NEURAL NETWORKS WITH LOGIC/image-20200729110021659.png" alt="image-20200729110021659" style="zoom:80%;" /></p>
</li>
<li><p>convex combination： <a href="[https://zh.wikipedia.org/wiki/%E5%87%B8%E7%BB%84%E5%90%88](https://zh.wikipedia.org/wiki/凸组合">凸组合</a>)  <a target="_blank" rel="noopener" href="https://math.stackexchange.com/questions/910612/convex-combination-of-3-point-in-r2-and-triangle">Convex Combination of 3 point in R2 and Triangle</a></p>
</li>
<li><p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/DL2 TRAINING AND QUERYING NEURAL NETWORKS WITH LOGIC/image-20200729170259031.png" alt="image-20200729170259031" style="zoom:80%;" /><strong>(什么方法？)</strong></p>
</li>
<li><p><a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Logit">Logit</a></p>
</li>
<li><p>regression taskin an unsupervised setting, namely training MLP (Multilayerperceptron)</p>
</li>
</ol>
<h3 id="ABSTRACT"><a href="#ABSTRACT" class="headerlink" title="ABSTRACT"></a>ABSTRACT</h3><p>我们提出了DL2，这是一种用于训练和查询具有逻辑约束的神经网络的系统。DL2比以前的工作更具表现力，并且可以捕获对模型的输入，输出和内部的更丰富的约束  a richer class of constraints on inputs,  outputs and internals of model。使用DL2，可以声明性地指定要在模型上训练 或 在查询期间要强制注入的领域知识，其<strong>目的是找到满足给定约束的输入</strong>。DL2的工作原理是将逻辑约束转换为具有所需数学特性的可微分损失函数 differentiable loss ，然后最小化该损失，基于标准梯度方法。</p>
<h3 id="1-INTRODUCTION"><a href="#1-INTRODUCTION" class="headerlink" title="1  INTRODUCTION"></a>1  INTRODUCTION</h3><p>一个关键挑战是<strong>使神经网络更可靠 reliable</strong>。解决这一挑战的可行方向是<strong>在培训过程中纳入约束条件 incorporating constraint</strong>（Madry等人，2017; Min-ervini等人，2017），并通过<strong>执行具体查询来检查已经受过训练的网络</strong>（Goodfellowet等人，2014b; Pei等人，2017;徐等人，2018））。尽管这些方法很有用，但它们被描述并硬编码 described and hardcoded 为特定种类的约束，从而使其难以应用于其他环境。</p>
<p>受先前工作的启发（例如，Cohen等人（2017）; Fu＆Su（2016）; Hu等人（2016））; Bach等人（2017）），我们引入了一种新的方法和系统，称为DL2（具有可微分逻辑with Differentiable Logic)的深度学习的缩写），可用于</p>
<ol>
<li><strong>查询网络中满足约束条件的输入，</strong></li>
<li><strong>训练网络以满足逻辑规范 logical specification，所有这些都是声明式的</strong></li>
</ol>
<p><strong><em>我们的约束语言 constraint language 可以使用求反，合取和析取negations, conjunctions, and disjunctions  在神经网络的输入，神经元和输出上表达算术比较arithmetic comparisons 的丰富组合</em>。</strong>得益于它的表现力，DL2使用户能够在训练期间加强领域知识或与网络进行交互，以便通过查询来了解其行为</p>
<p>DL2通过将逻辑约束<strong>转换为具有两个关键属性的非负损失函数</strong>来工作：</p>
<ol>
<li><strong>（P1）损失为零的值可以保证满足约束条件，</strong></li>
<li><strong>（P2）损失函数 都是可微分的。</strong></li>
</ol>
<p>这些属性相结合，使我们能够通过使用 现成的优化器 将损失降到最低 来 解决带有约束的神经网络 的 查询或训练的问题。</p>
<h4 id="Training-with-DL2"><a href="#Training-with-DL2" class="headerlink" title="Training with DL2"></a>Training with DL2</h4><p>为了使优化易于处理，我们<strong>排除了捕获凸集的输入约束，并将其作为优化目标的约束</strong>。我们使用<strong>投影梯度下降进行优化 projected gradient descent (PGD)</strong>，该方法<strong>在进行具有鲁棒性约束robustness constraints的训练</strong>是成功的(Madryet al., 2017). DL2的表现力以及通过PGD进行的易于处理的优化使我们能够训练新的有趣约束，比如：我们可以表达对概率的约束，而网络无法明确计算这些内容</p>
<p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/DL2 TRAINING AND QUERYING NEURAL NETWORKS WITH LOGIC/image-20200728221751057.png" alt="image-20200728221751057"></p>
<p>上面这个约束，在CIFAR-100的背景下，对于任何网络输入 x（网络由θ参数化），$people$  的概率 $p_{people}$  很小或很大。但是，CIFAR-100没有 $people$  这个类别，因此我们将其定义为 <em>a function of <strong>other probabilities</strong></em> <img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/DL2 TRAINING AND QUERYING NEURAL NETWORKS WITH LOGIC/image-20200728222100274.png" alt="image-20200728222100274" style="zoom:80%;" />我们显示，在类似的约束条件下（但有20个类），DL2在<strong>半监督的情况下</strong>提高了CIFAR-100网络的预测精度.</p>
<p>DL2 可以<strong>捕获在分类和回归任务中产生的约束</strong>。例如， GalaxyGAN （Schawinski等人，2017）要求网络遵守底层物理系统施加的约束，例如 通量flux：输入像素之和应等于输出像素之和。现在可以使用DL2，用声明性的方式表示为：$sum(x)= sum(\text{GalaxyGAN(x)})$，而不是将这种约束硬性地硬编码到网络中。</p>
<h4 id="Global-training"><a href="#Global-training" class="headerlink" title="Global training"></a>Global training</h4><p>DL2的一个<strong>突出特点是它能够训练对输入施加限制的约束 outside the training set</strong></p>
<p>先前关于约束训练的工作（例如Xu等人（2018））专注于给定的训练集，以对网络进行<strong>本地训练 local training</strong>以满足约束。使用DL2，我们可以首次 <strong>query for inputs</strong> which are <strong>outside the training set</strong>, and use them to <strong>globally train the network </strong>.</p>
<p>在 examples outside the training set 上进行训练的先前方法要么针对特定任务量身定制（Madry等，2017），要么针对网络类型（Minervini等，2017）。</p>
<p>我们的方法将全局训练的任务划分为：（i）<strong>优化器</strong>，它训练网络满足对输入的约束  the constraints for the given inputs，以及（ii）<strong>oracle</strong>，它为优化器提供旨在违反约束的新输入，考虑以下 Lipschitz 条件：</p>
<p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/DL2 TRAINING AND QUERYING NEURAL NETWORKS WITH LOGIC/image-20200728230500048.png" alt="image-20200728230500048" style="zoom:80%;" /></p>
<p>上式说明，对于训练集中的两个输入 $x^1,x^2$ ，在其 $\epsilon$ - neighborhood $(z^q,z^2)$ must satisfy the condition</p>
<p>如果满足Lipschitz条件，则神经网络会更稳定。</p>
<h4 id="Querying-with-DL2"><a href="#Querying-with-DL2" class="headerlink" title="Querying  with  DL2"></a>Querying  with  DL2</h4><p>我们还设计了一种类似于SQL的语言，该语言使用户能够通过声明式查询posing declarative queries  来与模型进行交互。例如，考虑一下近期工作研究的场景（Song等人，2018），其中作者展示了如何使用AC-GAN生成对抗性示例（Odena等人，2016）。生成器用于从某个类别（例如类别1）创建图像，而该图片会混淆分类器（例如分类为7）。对于DL2，这可以表述为：</p>
<p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/DL2 TRAINING AND QUERYING NEURAL NETWORKS WITH LOGIC/image-20200728234543352.png" alt="image-20200728234543352"></p>
<p>This <strong>query</strong></p>
<p> aims to <strong>find an input</strong> $n\in \Bbb{R}^{100}$  满足两条约束：</p>
<ol>
<li>domain constraint： 100维的 n 的每个元素都是在 -1 和 1 之间</li>
<li>ACGAN输出的结果是 本应该是类别 1 由 $\text{M_ACGAN_G(n,1)}$ 约束，  但 NN 分类的结果是 类别7   $\text{M_NN1}$ 的输出结果是 7</li>
</ol>
<p>DL2自动将此 query 转换为 DL2 的 loss，并使用现成的优化器（L-BFGS-B）对其进行优化以找到solution，在这种情况下为右侧的图像。</p>
<p>我们的语言可声明性地表述先前的许多工作，包括发现对给定预测负责 neurons responsible for a given prediction的神经元（Olah等人，2018），区分两个网络的输入（Peiet等人，2017）以及对抗性示例生成（例如Szegedy等人）等（2013年））</p>
<h4 id="Main-Contributions"><a href="#Main-Contributions" class="headerlink" title="Main Contributions"></a>Main Contributions</h4><p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/DL2 TRAINING AND QUERYING NEURAL NETWORKS WITH LOGIC/image-20200729102545691.png" alt="image-20200729102545691" style="zoom:80%;" /></p>
<h3 id="2-RELATED-WORK"><a href="#2-RELATED-WORK" class="headerlink" title="2  RELATED WORK"></a>2  RELATED WORK</h3><p><strong>Adversarial example generation</strong> 以看作是 as a fixed query to the network，while <strong>adversarial training</strong> (Madry et al., 2017) aims to enforce a specific constraint</p>
<ol>
<li><p>大多数工作旨在 ，train networks with logic <strong>impose soft constraints,</strong> 通过添加 an additional loss(正则项？) (Pathak et al., 2015; Xu et al., 2018)。</p>
</li>
<li><p>(M ́arquez-Neila et al., 2017) 表明硬约束比软约束没有经验优势。</p>
</li>
<li><p><strong>Probabilistic Soft Logic (PSL)</strong> (Kim-mig et al., 2012) translates logic into <strong>continuous functions</strong> over[0,1].  如我们所示，PSL不易于进行基于梯度的优化，因为梯度很容易变为零。 </p>
</li>
<li><p><strong>Hu</strong> et al. (2016) <strong>builds on PSL and presents a teacher-student framework which distills rules into the training phase。</strong>  idea is to <strong>formulate rule satisfaction as a convex problem</strong> with <strong>a closed-form solution</strong> (对teacher network 的 输出分布 直接通过闭式解给出 避免对网络参数的训练)。然而，这种 formulation构造的公式 仅限于关于随机变量的rules，而不能表达关于概率分布的rules。但 DL2可以表达这样的约束，例如 $p_1&gt;p_2$ 这要求类别1的网络输出概率大于类别2，而且，网络输出中 rules 的 线性性 导致的 凸性和闭式解 也是如此，这意味着非线性约束（例如，Lipschitz条件，可以用DL2表示）根本上是该方法无法实现的。</p>
</li>
<li>work of Xu et al. (2018) 还限制于对随机变量的约束，对于复杂的约束是棘手的。</li>
<li>Fu &amp; Su (2016)  reduces the satisfiability of floating-point formulas 转换成了数值优化，但是，它们的损失函数 不可微分，并且不支持对 分布 的约束。</li>
<li>没有先前的工作支持 <strong>回归任务 的约束</strong></li>
</ol>
<h3 id="3-FROM-LOGIC-TO-A-DIFFERENTIABLE-LOSS"><a href="#3-FROM-LOGIC-TO-A-DIFFERENTIABLE-LOSS" class="headerlink" title="3  FROM LOGIC  TO A DIFFERENTIABLE LOSS"></a>3  FROM LOGIC  TO A DIFFERENTIABLE LOSS</h3><h4 id="Logical-Language"><a href="#Logical-Language" class="headerlink" title="Logical Language"></a>Logical Language</h4><p>包含 quantifier-free constraints， 可以用 conjunction (∧), disjunction (∨) and negation (¬) 来构造。</p>
<p>Atomic constraints (literals) 是比较符<img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/DL2 TRAINING AND QUERYING NEURAL NETWORKS WITH LOGIC/image-20200729110408304.png" alt="image-20200729110408304" style="zoom:80%;" /> 这些比较符 是用于标量的，逐元素应用于矢量。</p>
<p>不支持 量词 (quantifier-free constraints)  </p>
<p><strong>A term $t$ is :</strong>  对 t 的约定</p>
<p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/DL2 TRAINING AND QUERYING NEURAL NETWORKS WITH LOGIC/image-20200729110918906.png" alt="image-20200729110918906" style="zoom:80%;" /></p>
<h4 id="Translation-into-loss"><a href="#Translation-into-loss" class="headerlink" title="Translation into loss"></a>Translation into loss</h4><p>把约束转化成损失函数形式，损失函数中的 变量间 逻辑运算符 再做 translation</p>
<p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/DL2 TRAINING AND QUERYING NEURAL NETWORKS WITH LOGIC/image-20200729113054171.png" alt="image-20200729113054171" style="zoom:80%;" /></p>
<p><strong>The  translation  rules：</strong></p>
<p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/DL2 TRAINING AND QUERYING NEURAL NETWORKS WITH LOGIC/image-20200729114140098.png" alt="image-20200729114140098" style="zoom:80%;" /></p>
<p><strong><em>比较符 $= \le$ 用距离函数来表示</em></strong>，L为0则表示满足约束，两元的比较符用 一个 连续的 可微的 scalar 表示</p>
<p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/DL2 TRAINING AND QUERYING NEURAL NETWORKS WITH LOGIC/image-20200729115217508.png" alt="image-20200729115217508" style="zoom:80%;" /></p>
<p>函数 $d$ 是就是对 逻辑比较符号的 translation，在论文的实现中，<strong><em>使用的是 absolute distance $\lvert t^1-t^2\rvert $</em></strong>  (因为是标量值，所以距离的度量直接是曼哈顿距离)</p>
<p>其余的比较符号：</p>
<p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/DL2 TRAINING AND QUERYING NEURAL NETWORKS WITH LOGIC/image-20200729141756243.png" alt="image-20200729141756243" style="zoom:80%;" /></p>
<p>合取析取的 translation：</p>
<p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/DL2 TRAINING AND QUERYING NEURAL NETWORKS WITH LOGIC/image-20200729141948167.png" alt="image-20200729141948167" style="zoom:80%;" /></p>
<p>当两个 formula 都满足时，loss 为0，则两个 formula 的 合取式 也满足， loss 为0</p>
<p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/DL2 TRAINING AND QUERYING NEURAL NETWORKS WITH LOGIC/image-20200729142326161.png" alt="image-20200729142326161" style="zoom:80%;" /></p>
<h4 id="Translating-negations"><a href="#Translating-negations" class="headerlink" title="Translating negations"></a>Translating negations</h4><p>包含 Negations 的 constraints 被重写为 不包含 Negations 的 等价 atomic constraint  (note that6=is not a negation). </p>
<p>对于 逻辑比较符</p>
<p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/DL2 TRAINING AND QUERYING NEURAL NETWORKS WITH LOGIC/image-20200729142716002.png" alt="image-20200729142716002" style="zoom:80%;" /></p>
<p>对于 合取析取符，</p>
<p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/DL2 TRAINING AND QUERYING NEURAL NETWORKS WITH LOGIC/image-20200729142835982.png" alt="image-20200729142835982" style="zoom:80%;" /></p>
<p>实例 $\bar x$ 带入 formula $\varphi$ 后使得 loss $L=0$ 则 <img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/DL2 TRAINING AND QUERYING NEURAL NETWORKS WITH LOGIC/image-20200729145018404.png" alt="image-20200729145018404" style="zoom:80%;" />当 loss 大于 一个 渐进于0的变量时，not satisfy</p>
<p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/DL2 TRAINING AND QUERYING NEURAL NETWORKS WITH LOGIC/image-20200729145120347.png" alt="image-20200729145120347" style="zoom:80%;" /></p>
<h3 id="4-CONSTRAINED-NEURAL-NETWORKS"><a href="#4-CONSTRAINED-NEURAL-NETWORKS" class="headerlink" title="4  CONSTRAINED NEURAL NETWORKS"></a>4  CONSTRAINED NEURAL NETWORKS</h3><p>在本节中，我们介绍了用于训练具有约束条件的神经网络的方法。我们首先定义问题，然后提供 min-max formulation，最后讨论如何解决问题</p>
<p>$[\varphi]$ 是 指示函数： <strong>1 if the predicate holds and 0 otherwise</strong> </p>
<h4 id="Training-with-constraints"><a href="#Training-with-constraints" class="headerlink" title="Training with constraints"></a>Training with constraints</h4><p>为了使用单个约束进行训练，我们考虑神经网络权重上的以下最大化问题，取值在[0,1]，最大为1</p>
<p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/DL2 TRAINING AND QUERYING NEURAL NETWORKS WITH LOGIC/image-20200729152436198.png" alt="image-20200729152436198" style="zoom:80%;" /></p>
<p>多个 constrain 的组合，通过 <strong>凸组合</strong>把 constrain 各自对应的 最大化期望问题组合起来</p>
<p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/DL2 TRAINING AND QUERYING NEURAL NETWORKS WITH LOGIC/image-20200729153711364.png" alt="image-20200729153711364" style="zoom:80%;" /></p>
<p><strong>S 为 从训练集中 采样样本</strong></p>
<p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/DL2 TRAINING AND QUERYING NEURAL NETWORKS WITH LOGIC/image-20200729154226150.png" alt="image-20200729154226150" style="zoom:80%;" /></p>
<h4 id="Formulation-as-min-max-optimization"><a href="#Formulation-as-min-max-optimization" class="headerlink" title="Formulation as min-max optimization"></a>Formulation as min-max optimization</h4><p>对上面的式子<img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/DL2 TRAINING AND QUERYING NEURAL NETWORKS WITH LOGIC/image-20200729154520611.png" alt="image-20200729154520611" style="zoom:80%;" />不直接求解这个最大化的优化问题，而是转变成<img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/DL2 TRAINING AND QUERYING NEURAL NETWORKS WITH LOGIC/image-20200729154554466.png" alt="image-20200729154554466" style="zoom:80%;" />最小化不满足约束概率的优化问题，这样可以将这个优化问题拆成两个子优化问题</p>
<p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/DL2 TRAINING AND QUERYING NEURAL NETWORKS WITH LOGIC/image-20200729154711886.png" alt="image-20200729154711886" style="zoom:80%;" /></p>
<p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/DL2 TRAINING AND QUERYING NEURAL NETWORKS WITH LOGIC/image-20200729155217164.png" alt="image-20200729155217164" style="zoom:80%;" /></p>
<p>先找到最大化冲突，即最大不满足约束的实例  $\bar x$ ，然后在已知  $\bar x$ 的条件下，求最小化该情况的期望值</p>
<h4 id="Solving-the-optimization-problems"><a href="#Solving-the-optimization-problems" class="headerlink" title="Solving the optimization problems"></a>Solving the optimization problems</h4><p>求解上面两个式子，通过第三节的方法 把 logical constraints 转换成 differentiable loss</p>
<p>对于<img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/DL2 TRAINING AND QUERYING NEURAL NETWORKS WITH LOGIC/image-20200729163700603.png" alt="image-20200729163700603" style="zoom:80%;" />我们将其 translate 到 损失函数 loss $L$ 。最大化满足 约束的逆，即让满足 约束的逆 的损失 $L$  最小：   根据 theorem1，</p>
<p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/DL2 TRAINING AND QUERYING NEURAL NETWORKS WITH LOGIC/image-20200729164530533.png" alt="image-20200729164530533" style="zoom:80%;" /></p>
<p>从上式解出 $\bar x$ 后，要使得在 约束 $\varphi$ 下出现 满足 约束的逆 的概率越小，所以要最小化下面的 损失函数</p>
<p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/DL2 TRAINING AND QUERYING NEURAL NETWORKS WITH LOGIC/image-20200729164459441.png" alt="image-20200729164459441" style="zoom:80%;" /></p>
<h4 id="Constrained-optimization"><a href="#Constrained-optimization" class="headerlink" title="Constrained optimization"></a>Constrained optimization</h4><p>通常，（4）中的损失有时可能难以优化，</p>
<p>举例：</p>
<p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/DL2 TRAINING AND QUERYING NEURAL NETWORKS WITH LOGIC/image-20200729170004311.png" alt="image-20200729170004311" style="zoom:80%;" /></p>
<p>首先对 $\varphi$ 取反，$\le$  根据<img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/DL2 TRAINING AND QUERYING NEURAL NETWORKS WITH LOGIC/image-20200729165954557.png" alt="image-20200729165954557" style="zoom:80%;display:inline" align="middle" />转成<img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/DL2 TRAINING AND QUERYING NEURAL NETWORKS WITH LOGIC/image-20200729170031260.png" alt="image-20200729170031260" style="zoom:80%;display:inline" align="middle" /><br>$\land$ 转成 <img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/DL2 TRAINING AND QUERYING NEURAL NETWORKS WITH LOGIC/image-20200729170100795.png" alt="image-20200729170100795" style="zoom:80%;display:inline" align="middle" /></p>
<p>这个式子很难优化，因为 the magnitude of the two terms is different，根据Carlini＆Wagner（2017）的报道，这导致 一阶方法 以过于贪婪的方式仅优化了单个项。</p>
<p>但是，某些约束具有闭式的解析解，<img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/DL2 TRAINING AND QUERYING NEURAL NETWORKS WITH LOGIC/image-20200729170259031.png" alt="image-20200729170259031" style="zoom:80%;" />为此，我们确定了逻辑约束，这些约束将变量限制为具有有效投影算法的凸集，<img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/DL2 TRAINING AND QUERYING NEURAL NETWORKS WITH LOGIC/image-20200729170512198.png" alt="image-20200729170512198" style="zoom:80%;" /></p>
<p>.</p>
<p><strong>算法流程：</strong></p>
<p>我们首先从训练集中形成随机样本的 mini-batch，the  oracle 找到上面 式 6 的一个解，在将该解给 optimizer来 solve 式 5。请注意，如果φ没有变量（k = 0），即只有一个 constrain 则 oracle 将变平凡，直接计算 loss</p>
<p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/DL2 TRAINING AND QUERYING NEURAL NETWORKS WITH LOGIC/image-20200729171104065.png" alt="image-20200729171104065" style="zoom:80%;" /></p>
<h3 id="5-QUERYING-NETWORKS"><a href="#5-QUERYING-NETWORKS" class="headerlink" title="5   QUERYING NETWORKS"></a>5   QUERYING NETWORKS</h3><p>我们以DL2为基础，设计了一种用于 查询网络querying networks 的声明性语言。先前工作中研究的硬编码问题现在可以用DL2查询表述：发现对给定预测负责 neurons responsible for a given prediction的神经元（Olah等人，2018），区分两个网络的输入（Peiet等人，2017）以及对抗性示例生成（例如Szegedy等人）等（2013年））</p>
<p><strong>我们支持以下类别的查询：</strong></p>
<p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/DL2 TRAINING AND QUERYING NEURAL NETWORKS WITH LOGIC/image-20200729171314064.png" alt="image-20200729171314064"></p>
<p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/DL2 TRAINING AND QUERYING NEURAL NETWORKS WITH LOGIC/image-20200729171814154.png" alt="image-20200729171814154" style="zoom:80%;" /></p>
<p>我们注意到用户可以用我们的语言指定 张量tensors（我们不假定它们被简化为矢量）。查询时，我们用逗号（，）表示连词（∧）； <strong>in</strong> 表示框约束 box-constraints，而 <strong>class</strong> 表示约束 目标标签target label，这被解释为对标签概率labels’ probabilities的约束</p>
<p>举例 几个有趣的查询。：</p>
<p>他的前两个是通过为CIFAR-10训练的网络定义的，而最后一个是针对MNIST的</p>
<ol>
<li><p>The <strong>first query</strong> is to find an <strong>adversarial example</strong> $i$ of shape(32,32,3), classified as a truck (class9) ，$i$  到 a given deer image(deer) 的距离在 6 到 24 间(距离用 $L_{\infty}$ 计算A)</p>
<p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/DL2 TRAINING AND QUERYING NEURAL NETWORKS WITH LOGIC/image-20200729204215351.png" alt="image-20200729204215351" style="zoom:80%;" /></p>
</li>
<li><p>目标是 找到 $i$ <strong>classified as a deer</strong> where <strong>a specific neuron is deactivated</strong>.</p>
<p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/DL2 TRAINING AND QUERYING NEURAL NETWORKS WITH LOGIC/image-20200729205243397.png" alt="image-20200729205243397" style="zoom:80%;" /></p>
</li>
<li><p>目标是 找到 $i$  <strong>classified differently by two networks</strong> where <strong>part of $i$ is fixed to pixels</strong> of the image <strong>nine</strong></p>
<p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/DL2 TRAINING AND QUERYING NEURAL NETWORKS WITH LOGIC/image-20200729205545246.png" alt="image-20200729205545246" style="zoom: 80%;" /></p>
</li>
</ol>
<h4 id="Solving-queries"><a href="#Solving-queries" class="headerlink" title="Solving queries"></a>Solving queries</h4><p>与训练一样，我们将 约束 编译为 损失loss，但是与训练不同，我们使用 L-BFGS-B 进行优化。虽然训练需要在PGD优化中分批输入，但查询却需要分配，因此有更多的时间使用更复杂但更慢的L-BFGS-B。我们将在附录C中讨论进一步的优化</p>
<h3 id="6-EXPERIMENTAL-EVALUATION"><a href="#6-EXPERIMENTAL-EVALUATION" class="headerlink" title="6  EXPERIMENTAL EVALUATION"></a>6  EXPERIMENTAL EVALUATION</h3><p>现在，我们对DL2在查询和训练具有逻辑约束的神经网络的有效性方面进行了全面的实验评估。我们的系统在PyTorch中实现（Paszkeet等，2017），并在Nvidia GTX 1080 Ti和4.20 GHz的Intel Core i7-7700K上进行了评估</p>
<h4 id="6-1-TRAINING-WITH-DL2"><a href="#6-1-TRAINING-WITH-DL2" class="headerlink" title="6.1    TRAINING  WITH  DL2"></a>6.1    TRAINING  WITH  DL2</h4><p>我们评估了DL2在以下四个数据集上的各种任务（有监督，半监督和无监督学习）上：MNIST，FASHION（Xiao等人，2017），CIFAR-10和CIFAR-100（Krizhevsky＆Hinton，2009）。在所有实验中，约束条件之一是交叉熵（请参见第4节），以进行优化以提高预测精度。对于每个实验，我们都描述了其他逻辑约束</p>
<h4 id="Supervised-learning"><a href="#Supervised-learning" class="headerlink" title="Supervised   learning"></a>Supervised   learning</h4><p>考虑两种 约束</p>
<ol>
<li><em>global constraints</em>，包括z-s,： </li>
<li><em>training  set  constraints ：</em> the only variables are  from the training set (no ·z-s).</li>
</ol>
<p>we write <strong>random samples</strong> (the S-s)     $x_i$ <strong>: inputs from the training set       $y_i$ : corresponding label</strong></p>
<p><strong>For local robustness (Szegedy et al., 2013) </strong> </p>
<ol>
<li><p><strong>training set constraint</strong></p>
<p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/DL2 TRAINING AND QUERYING NEURAL NETWORKS WITH LOGIC/image-20200729220549693.png" alt="image-20200729220549693" style="zoom:80%;" /></p>
</li>
<li><p><strong>Global constraint</strong> </p>
<p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/DL2 TRAINING AND QUERYING NEURAL NETWORKS WITH LOGIC/image-20200729220600062.png" alt="image-20200729220600062" style="zoom:80%;" /></p>
<p>可能指的就是 <img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/DL2 TRAINING AND QUERYING NEURAL NETWORKS WITH LOGIC/image-20200729221406131.png" alt="image-20200729221406131" style="zoom:80%;" /></p>
</li>
</ol>
<p>同样的，have <strong>two definitions</strong> for <strong>the Lipschitz condition.</strong>  </p>
<ol>
<li><p><strong>training set constraint</strong> </p>
<p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/DL2 TRAINING AND QUERYING NEURAL NETWORKS WITH LOGIC/image-20200729221704696.png" alt="image-20200729221704696" style="zoom:80%;" /></p>
</li>
<li><p><strong>global constraint</strong> </p>
<p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/DL2 TRAINING AND QUERYING NEURAL NETWORKS WITH LOGIC/image-20200729221727188.png" alt="image-20200729221727188" style="zoom:80%;" /></p>
</li>
</ol>
<p><strong>Imposing domain knowledge</strong></p>
<ol>
<li><p><strong>training set constraint</strong> </p>
<p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/DL2 TRAINING AND QUERYING NEURAL NETWORKS WITH LOGIC/image-20200729221859620.png" alt="image-20200729221859620" style="zoom:80%;" /></p>
</li>
<li><p><strong>global constraint</strong> </p>
<p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/DL2 TRAINING AND QUERYING NEURAL NETWORKS WITH LOGIC/image-20200729221911682.png" alt="image-20200729221911682" style="zoom:80%;" /></p>
</li>
</ol>
<p>最后，我们考虑一个细分约束，它要求如果输入zi在位置λ上的两个输入x1和x2之间的直线上，则其输出概率在输出概率之间的直线上的位置λ上</p>
<p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/DL2 TRAINING AND QUERYING NEURAL NETWORKS WITH LOGIC/image-20200729222035065.png" alt="image-20200729222035065" style="zoom:80%;" /></p>
<p><strong>预测精度（P）和约束精度（C）</strong></p>
<p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/DL2 TRAINING AND QUERYING NEURAL NETWORKS WITH LOGIC/image-20200729222743867.png" alt="image-20200729222743867" style="zoom:80%;" /></p>
<p>(i) crossed-entropy only (CE) and (ii) CE and the constraint. </p>
<p>P 预测精度略微下降， C 约束精度很高</p>
<p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/DL2 TRAINING AND QUERYING NEURAL NETWORKS WITH LOGIC/image-20200729223542692.png" alt="image-20200729223542692" style="zoom:80%;" /></p>
<h4 id="Semi-supervised-learning"><a href="#Semi-supervised-learning" class="headerlink" title="Semi-supervised  learning"></a>Semi-supervised  learning</h4><p>我们将重点放在CIFAR-100数据集上，并将训练集按20/60/20的比例分为标记集，未标记集和验证集。</p>
<p>本着Xu等人的实验精神  Xu et al. (2018)，我们考虑约束条件 要求 类别组 <strong>groups  of  classes</strong> 的概率要么具有非常高的概率或非常低的概率。 A group consists of classes of a similar type( e.g., the classes <em>baby,boy,girl,man, and woman</em> are part of the people group), and <strong>the group’s probability</strong> <strong>is the sum of its classes’ probabilities</strong></p>
<p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/DL2 TRAINING AND QUERYING NEURAL NETWORKS WITH LOGIC/image-20200729223906576.png" alt="image-20200729223906576" style="zoom:80%;" /> for a small $\epsilon$</p>
<p>我们使用此约束条件来比较几种方法的性能,  we use the Wide Residual Network (Zagoruyko &amp; Komodakis (2016)) as the network architecture. </p>
<p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/DL2 TRAINING AND QUERYING NEURAL NETWORKS WITH LOGIC/image-20200729224145257.png" alt="image-20200729224145257" style="zoom:80%;" /></p>
<h4 id="Unsupervised-learning"><a href="#Unsupervised-learning" class="headerlink" title="Unsupervised learning"></a>Unsupervised learning</h4><p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/DL2 TRAINING AND QUERYING NEURAL NETWORKS WITH LOGIC/image-20200729225442306.png" alt="image-20200729225442306" style="zoom:80%;" /></p>
<p>另外，我们约束 $d(0)=0$。接下来，我们以无监督的方式训练模型，使用DL2。在每个实验中，我们生成具有15个顶点的随机图，并将图分为训练（300），验证（150）和测试集（150）。作为无监督的基线，我们考虑一个始终预测 d（v）= 1的模型。我们还训练了具有均方误差（MSE）损失的监督模型。值得注意的是，我们的方法无需使用任何标签即可获得非常接近监督模型的错误。这证实了由DL2产生的损失可用于指导网络满足具有许多嵌套连接和分离的甚至非常复杂的约束。</p>
<h4 id="6-2-QUERYING-WITH-DL2"><a href="#6-2-QUERYING-WITH-DL2" class="headerlink" title="6.2   QUERYING  WITH  DL2"></a>6.2   QUERYING  WITH  DL2</h4><p>我们评估了在TensorFlow中实现的具有约束的查询任务上的DL2。我们考虑了五个图像数据集，对于每个图像集，我们至少考虑了两个分类器。我们还考虑了生成器和鉴别器（使用GAN训练（Goodfellow等，2014a））。表3（附录E）提供了有关网络的统计信息。我们的基准测试包含18个模板查询 template queries（附录E），这些查询使用不同的网络，类和图像进行实例化。表1显示了结果（-表示不适用的查询）。 Queries ran with a timeout of2minutes.。结果表明我们的系统经常找到解决方案。尚未找到没有解决方案的查询是否具有解决方案是未知的。我们观察到查询的成功取决于数据集，例如，查询9-11对于除GTSBR之外的所有数据集都是成功的。这可能归因于GTSBR网络相对于这些查询旨在寻找的对抗示例的鲁棒性。利用区分词查找对抗示例的查询14仅对CIFAR数据集成功。可能的解释是，鉴别器是针对生成器创建的真实图像或图像进行训练的，因此，鉴别器在对仿生图像进行分类时表现不佳。利用生成器的查询15在所有经过测试的数据集中都成功，但是在每个数据集中只有很少的成功。至于整体解决时间，我们的结果表明，成功执行的过程会很快结束，并且我们的系统可以很好地扩展到大型网络（例如ImageNet）。</p>
<h3 id="7-CONCLUSION"><a href="#7-CONCLUSION" class="headerlink" title="7  CONCLUSION"></a>7  CONCLUSION</h3><p>AND APPENDIX</p>
<p><a target="_blank" rel="noopener" href="https://www.sri.inf.ethz.ch/publications/fischer2019dl2">paper</a></p>

    </div>

    
    
    
        

<div>
<ul class="post-copyright">
  <li class="post-copyright-author">
    <strong>Post author:  </strong>guo jiazhen
  </li>
  <li class="post-copyright-link">
    <strong>Post link: </strong>
    <a href="https://jasonguojz.github.io/blog/2020/07/23/DL2%20TRAINING%20AND%20QUERYING%20NEURAL%20NETWORKS%20WITH%20LOGIC/" title="DL2- TRAINING AND QUERYING NEURAL NETWORKS WITH LOGIC">https://jasonguojz.github.io/blog/2020/07/23/DL2 TRAINING AND QUERYING NEURAL NETWORKS WITH LOGIC/</a>
  </li>
  <li class="post-copyright-license">
    <strong>Copyright Notice:  </strong>All articles in this blog are licensed under <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" rel="noopener" target="_blank"><i class="fa fa-fw fa-creative-commons"></i>BY-NC-SA</a> unless stating additionally.
  </li>
</ul>
</div>


      <footer class="post-footer">
          <div class="post-tags">
              <a href="/blog/tags/querying-neural-network/" rel="tag"># querying neural network</a>
              <a href="/blog/tags/differentiable-loss/" rel="tag"># differentiable loss</a>
              <a href="/blog/tags/convex-set/" rel="tag"># convex set</a>
          </div>

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/blog/2020/07/22/Harnessing%20Deep%20Neural%20Networks%20with%20Logic%20Rules/" rel="prev" title="Harnessing Deep Neural Networks with Logic Rules">
      <i class="fa fa-chevron-left"></i> Harnessing Deep Neural Networks with Logic Rules
    </a></div>
      <div class="post-nav-item">
    <a href="/blog/2020/07/25/Neural%20Module%20Networks/" rel="next" title="Neural Module Networks">
      Neural Module Networks <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  



          </div>
          
    <div class="comments" id="valine-comments"></div>

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E3%80%8E%E3%80%8F%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0"><span class="nav-number">1.</span> <span class="nav-text">『』阅读笔记</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#code-for-DL2"><span class="nav-number">1.1.</span> <span class="nav-text">code for DL2 </span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#project-%E5%9C%B0%E5%9D%80"><span class="nav-number">1.2.</span> <span class="nav-text">project 地址</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%B8%93%E6%9C%89%E5%90%8D%E8%AF%8D"><span class="nav-number">2.</span> <span class="nav-text">专有名词</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#ABSTRACT"><span class="nav-number">3.</span> <span class="nav-text">ABSTRACT</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#1-INTRODUCTION"><span class="nav-number">4.</span> <span class="nav-text">1  INTRODUCTION</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Training-with-DL2"><span class="nav-number">4.1.</span> <span class="nav-text">Training with DL2</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Global-training"><span class="nav-number">4.2.</span> <span class="nav-text">Global training</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Querying-with-DL2"><span class="nav-number">4.3.</span> <span class="nav-text">Querying  with  DL2</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Main-Contributions"><span class="nav-number">4.4.</span> <span class="nav-text">Main Contributions</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-RELATED-WORK"><span class="nav-number">5.</span> <span class="nav-text">2  RELATED WORK</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#3-FROM-LOGIC-TO-A-DIFFERENTIABLE-LOSS"><span class="nav-number">6.</span> <span class="nav-text">3  FROM LOGIC  TO A DIFFERENTIABLE LOSS</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Logical-Language"><span class="nav-number">6.1.</span> <span class="nav-text">Logical Language</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Translation-into-loss"><span class="nav-number">6.2.</span> <span class="nav-text">Translation into loss</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Translating-negations"><span class="nav-number">6.3.</span> <span class="nav-text">Translating negations</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#4-CONSTRAINED-NEURAL-NETWORKS"><span class="nav-number">7.</span> <span class="nav-text">4  CONSTRAINED NEURAL NETWORKS</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Training-with-constraints"><span class="nav-number">7.1.</span> <span class="nav-text">Training with constraints</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Formulation-as-min-max-optimization"><span class="nav-number">7.2.</span> <span class="nav-text">Formulation as min-max optimization</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Solving-the-optimization-problems"><span class="nav-number">7.3.</span> <span class="nav-text">Solving the optimization problems</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Constrained-optimization"><span class="nav-number">7.4.</span> <span class="nav-text">Constrained optimization</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#5-QUERYING-NETWORKS"><span class="nav-number">8.</span> <span class="nav-text">5   QUERYING NETWORKS</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Solving-queries"><span class="nav-number">8.1.</span> <span class="nav-text">Solving queries</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#6-EXPERIMENTAL-EVALUATION"><span class="nav-number">9.</span> <span class="nav-text">6  EXPERIMENTAL EVALUATION</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#6-1-TRAINING-WITH-DL2"><span class="nav-number">9.1.</span> <span class="nav-text">6.1    TRAINING  WITH  DL2</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Supervised-learning"><span class="nav-number">9.2.</span> <span class="nav-text">Supervised   learning</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Semi-supervised-learning"><span class="nav-number">9.3.</span> <span class="nav-text">Semi-supervised  learning</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Unsupervised-learning"><span class="nav-number">9.4.</span> <span class="nav-text">Unsupervised learning</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#6-2-QUERYING-WITH-DL2"><span class="nav-number">9.5.</span> <span class="nav-text">6.2   QUERYING  WITH  DL2</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#7-CONCLUSION"><span class="nav-number">10.</span> <span class="nav-text">7  CONCLUSION</span></a></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name"></p>
  <div class="site-description" itemprop="description">谦卑</div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/blog/archives/">
        
          <span class="site-state-item-count">21</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/blog/categories/">
          
        <span class="site-state-item-count">28</span>
        <span class="site-state-item-name">categories</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/blog/tags/">
          
        <span class="site-state-item-count">77</span>
        <span class="site-state-item-name">tags</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
        <a href="https://github.com/JasonGuojz" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;JasonGuojz" rel="noopener" target="_blank"><i class="fa fa-fw fa-github"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="/blog/jzguovulcan@gmail.com" title="E-Mail → jzguovulcan@gmail.com"><i class="fa fa-fw fa-envelope"></i>E-Mail</a>
      </span>
      <span class="links-of-author-item">
        <a href="skype:yourname?call|chat" title="Skype → skype:yourname?call|chat" rel="noopener" target="_blank"><i class="fa fa-fw fa-skype"></i>Skype</a>
      </span>
  </div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2020</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder"></span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-area-chart"></i>
    </span>
    <span title="Symbols count total">191k</span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-coffee"></i>
    </span>
    <span title="Reading time total">2:54</span>
</div>
  <div class="powered-by">Powered by <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://muse.theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Muse</a>
  </div>

        








      </div>
    </footer>
  </div>

  
  <script src="/blog/lib/anime.min.js"></script>
  <script src="/blog/lib/velocity/velocity.min.js"></script>
  <script src="/blog/lib/velocity/velocity.ui.min.js"></script>

<script src="/blog/js/utils.js"></script>

<script src="/blog/js/motion.js"></script>


<script src="/blog/js/schemes/muse.js"></script>


<script src="/blog/js/next-boot.js"></script>




  




  
<script src="/blog/js/local-search.js"></script>













  

  
      

<script>
  if (typeof MathJax === 'undefined') {
    window.MathJax = {
      loader: {
          load: ['[tex]/mhchem'],
        source: {
          '[tex]/amsCd': '[tex]/amscd',
          '[tex]/AMScd': '[tex]/amscd'
        }
      },
      tex: {
        inlineMath: {'[+]': [['$', '$']]},
          packages: {'[+]': ['mhchem']},
        tags: 'ams'
      },
      options: {
        renderActions: {
          findScript: [10, doc => {
            document.querySelectorAll('script[type^="math/tex"]').forEach(node => {
              const display = !!node.type.match(/; *mode=display/);
              const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
              const text = document.createTextNode('');
              node.parentNode.replaceChild(text, node);
              math.start = {node: text, delim: '', n: 0};
              math.end = {node: text, delim: '', n: 0};
              doc.math.push(math);
            });
          }, '', false],
          insertedScript: [200, () => {
            document.querySelectorAll('mjx-container').forEach(node => {
              let target = node.parentNode;
              if (target.nodeName.toLowerCase() === 'li') {
                target.parentNode.classList.add('has-jax');
              }
            });
          }, '', false]
        }
      }
    };
    (function () {
      var script = document.createElement('script');
      script.src = '//cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js';
      script.defer = true;
      document.head.appendChild(script);
    })();
  } else {
    MathJax.startup.document.state(0);
    MathJax.texReset();
    MathJax.typeset();
  }
</script>

    

  


<script>
NexT.utils.loadComments(document.querySelector('#valine-comments'), () => {
  NexT.utils.getScript('//cdn.jsdelivr.net/npm/valine@1/dist/Valine.min.js', () => {
    var GUEST = ['nick', 'mail', 'link'];
    var guest = 'nick,mail,link';
    guest = guest.split(',').filter(item => {
      return GUEST.includes(item);
    });
    new Valine({
      el         : '#valine-comments',
      verify     : false,
      notify     : false,
      appId      : '2M2aiiBff85KzN3JvTFsCV2J-9Nh9j0Va',
      appKey     : '7n1fFOWyaLnTBNpNjRhYsF0W',
      placeholder: "Please write your comments here",
      avatar     : 'mm',
      meta       : guest,
      pageSize   : '10' || 10,
      visitor    : true,
      lang       : 'zh-cn' || 'zh-cn',
      path       : location.pathname,
      recordIP   : false,
      serverURLs : ''
    });
  }, window.Valine);
});
</script><!-- hexo-inject:begin --><!-- hexo-inject:end -->

</body>
</html>
