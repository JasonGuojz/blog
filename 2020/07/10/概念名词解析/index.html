<!DOCTYPE html>
<html lang="en">
<head>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 5.0.2">
  <link rel="apple-touch-icon" sizes="180x180" href="/blog/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/blog/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/blog/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/blog/images/logo.svg" color="#222">

<link rel="stylesheet" href="/blog/css/main.css">


<link rel="stylesheet" href="/blog/lib/font-awesome/css/font-awesome.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"jasonguojz.github.io","root":"/blog/","scheme":"Muse","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":true,"show_result":true,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},"path":"search.xml"};
  </script>

  <meta name="description" content="nlp&#x2F;ml&#x2F;dl related terms">
<meta property="og:type" content="article">
<meta property="og:title" content="概念名词解析">
<meta property="og:url" content="https://jasonguojz.github.io/blog/2020/07/10/%E6%A6%82%E5%BF%B5%E5%90%8D%E8%AF%8D%E8%A7%A3%E6%9E%90/index.html">
<meta property="og:site_name" content="Guo Jiazhen&#39;s Blog">
<meta property="og:description" content="nlp&#x2F;ml&#x2F;dl related terms">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/概念名词解析/image-20200806103226995.png">
<meta property="og:image" content="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/概念名词解析/image-20200808170218438.png">
<meta property="og:image" content="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/概念名词解析/image-20200808170106351.png">
<meta property="og:image" content="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/概念名词解析/image-20200808170316162.png">
<meta property="og:image" content="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/概念名词解析/image-20200808170633114.png">
<meta property="og:image" content="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/概念名词解析/image-20200808170527436.png">
<meta property="og:image" content="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/概念名词解析/image-20200813154936884.png">
<meta property="og:image" content="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/概念名词解析/image-20200809095354724.png">
<meta property="og:image" content="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/概念名词解析/image-20200809110609620.png">
<meta property="og:image" content="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/概念名词解析/image-20200809101143166.png">
<meta property="og:image" content="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/概念名词解析/image-20200809101547986.png">
<meta property="og:image" content="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/概念名词解析/image-20200809101755184.png">
<meta property="og:image" content="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/概念名词解析/image-20200813153441759.png">
<meta property="og:image" content="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/概念名词解析/image-20200809103434298.png">
<meta property="og:image" content="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/概念名词解析/image-20200809110639296.png">
<meta property="og:image" content="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/概念名词解析/image-20200808171310420.png">
<meta property="og:image" content="https://www.zhihu.com/equation?tex=%5Ctheta_j%5E%7B%28t%29%7D%3D%5Ctheta_j%5E%7B%28t-1%29%7D-%5Calpha%5Csum_%7Bk%3D1%7D%5E%7BN%7D%5Cleft%5C%7B+%5Cleft%5B+%5Cphi_j%28%5Chat%5Clambda_%7Bij%7D%5E%7B%28k%29%7D%2C+%5Chat+y_i%5E%7B%28k%29%7D%29+%5Cright%5D_%7B%7B%5Chat%5CLambda_i%5E%7B%28k%29%7D%2C+%5Chat+y_i%5E%7B%28k%29%7D+%5Csim+P%28%5CLambda_i%2C+y_i%29%7D%7D+-%5Cleft%5B+%5Cphi_j%28%5Clambda_%7Bij%7D%2C+%5Chat+y_i%5E%7B%28k%29%7D%29+%5Cright%5D_%7B%5Chat+y_i%5E%7B%28k%29%7D+%5Csim+P%28y_i%7C%5CLambda_i%29%7D+%5Cright%5C%7D">
<meta property="og:image" content="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/概念名词解析/image-20200816172814181.png">
<meta property="og:image" content="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/概念名词解析/3987bf963ef4ab9a7920cbb1d57056c3">
<meta property="article:published_time" content="2020-07-09T16:00:00.000Z">
<meta property="article:modified_time" content="2020-08-25T00:45:04.617Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/概念名词解析/image-20200806103226995.png">

<link rel="canonical" href="https://jasonguojz.github.io/blog/2020/07/10/%E6%A6%82%E5%BF%B5%E5%90%8D%E8%AF%8D%E8%A7%A3%E6%9E%90/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'en'
  };
</script>

  <title>概念名词解析 | Guo Jiazhen's Blog</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript><!-- hexo-inject:begin --><!-- hexo-inject:end -->

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/blog/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">Guo Jiazhen's Blog</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="menu">
        <li class="menu-item menu-item-home">

    <a href="/blog/" rel="section"><i class="fa fa-fw fa-home"></i>Home</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/blog/tags/" rel="section"><i class="fa fa-fw fa-tags"></i>Tags<span class="badge">79</span></a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/blog/categories/" rel="section"><i class="fa fa-fw fa-th"></i>Categories<span class="badge">30</span></a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/blog/archives/" rel="section"><i class="fa fa-fw fa-archive"></i>Archives<span class="badge">25</span></a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>Search
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off"
           placeholder="Searching..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div id="search-result">
  <div id="no-result">
    <i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>
  </div>
</div>

    </div>
  </div>

</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content post posts-expand">
            

    
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://jasonguojz.github.io/blog/2020/07/10/%E6%A6%82%E5%BF%B5%E5%90%8D%E8%AF%8D%E8%A7%A3%E6%9E%90/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/blog/images/avatar.gif">
      <meta itemprop="name" content="">
      <meta itemprop="description" content="谦卑">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Guo Jiazhen's Blog">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          概念名词解析
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2020-07-10 00:00:00" itemprop="dateCreated datePublished" datetime="2020-07-10T00:00:00+08:00">2020-07-10</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2020-08-25 08:45:04" itemprop="dateModified" datetime="2020-08-25T08:45:04+08:00">2020-08-25</time>
              </span>

          
            <span id="/blog/2020/07/10/%E6%A6%82%E5%BF%B5%E5%90%8D%E8%AF%8D%E8%A7%A3%E6%9E%90/" class="post-meta-item leancloud_visitors" data-flag-title="概念名词解析" title="Views">
              <span class="post-meta-item-icon">
                <i class="fa fa-eye"></i>
              </span>
              <span class="post-meta-item-text">Views: </span>
              <span class="leancloud-visitors-count"></span>
            </span>
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="fa fa-comment-o"></i>
      </span>
      <span class="post-meta-item-text">Valine: </span>
    
    <a title="valine" href="/blog/2020/07/10/%E6%A6%82%E5%BF%B5%E5%90%8D%E8%AF%8D%E8%A7%A3%E6%9E%90/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/blog/2020/07/10/%E6%A6%82%E5%BF%B5%E5%90%8D%E8%AF%8D%E8%A7%A3%E6%9E%90/" itemprop="commentCount"></span>
    </a>
  </span>
  
  <br>
            <span class="post-meta-item" title="Symbols count in article">
              <span class="post-meta-item-icon">
                <i class="fa fa-file-word-o"></i>
              </span>
                <span class="post-meta-item-text">Symbols count in article: </span>
              <span>8.3k</span>
            </span>
            <span class="post-meta-item" title="Reading time">
              <span class="post-meta-item-icon">
                <i class="fa fa-clock-o"></i>
              </span>
                <span class="post-meta-item-text">Reading time &asymp;</span>
              <span>8 mins.</span>
            </span>
            <div class="post-description"><div align=center>nlp/ml/dl related terms</div></div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <a id="more"></a>
<ol>
<li><p>Dirichlet 过程   <a target="_blank" rel="noopener" href="https://juejin.im/entry/58e09c2cda2f60005fcd5573">参考1 掘金</a> </p>
</li>
<li><p>贝叶斯推断</p>
</li>
<li><p>贝叶斯网络  <a target="_blank" rel="noopener" href="https://humboldt-wi.github.io/blog/research/information_systems_1819/uncertainty-and-credit-scoring/">Uncertainty in Profit Scoring (Bayesian Deep Learning)</a>  <a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/81170602">知乎大佬Bayesian Neural Networks：贝叶斯神经网络</a></p>
</li>
<li><p>无偏蒙特卡洛梯度 <a href="[https://www.google.com/search?q=%E6%97%A0%E5%81%8F%E8%92%99%E7%89%B9%E5%8D%A1%E6%B4%9B%E6%A2%AF%E5%BA%A6&amp;oq=%E6%97%A0%E5%81%8F%E8%92%99%E7%89%B9%E5%8D%A1%E6%B4%9B%E6%A2%AF%E5%BA%A6&amp;aqs=chrome..69i57.408j0j1&amp;sourceid=chrome&amp;ie=UTF-8](https://www.google.com/search?q=无偏蒙特卡洛梯度&amp;oq=无偏蒙特卡洛梯度&amp;aqs=chrome..69i57.408j0j1&amp;sourceid=chrome&amp;ie=UTF-8">参考</a>)</p>
</li>
<li><p>蒙特卡罗方法（Monte Carlo method）<a target="_blank" rel="noopener" href="https://oneraynyday.github.io/ml/2018/05/24/Reinforcement-Learning-Monte-Carlo/">Reinforcement-Learning-Monte-Carlo</a></p>
</li>
<li><p>蒙特卡洛dropout<a target="_blank" rel="noopener" href="https://datascience.stackexchange.com/questions/44065/what-is-monte-carlo-dropout">What is Monte Carlo dropout?</a></p>
</li>
<li><p>蒙特卡洛积分 <a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/61611088">Monte Carlo数学原理</a>  <a target="_blank" rel="noopener" href="https://www.jianshu.com/p/3d30070932a8">随机模拟-Monte Carlo积分及采样（详述直接采样、接受-拒绝采样、重要性采样）</a></p>
</li>
<li><p>Dropout variational inference Dropout变分推理</p>
</li>
<li><p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/56986840">reference—深度学习中的两种不确定性</a></p>
</li>
<li><p><a target="_blank" rel="noopener" href="http://www.cs.ox.ac.uk/people/yarin.gal/website/blog_3d801aa532c1ce.html"><em>What My Deep Model Doesn’t Know</em></a></p>
<ul>
<li>prediction uncertainty 预测不确定性</li>
</ul>
</li>
<li><p>变分贝叶斯方法   <a target="_blank" rel="noopener" href="https://blog.csdn.net/aws3217150/article/details/57072827">cnblog讲解</a></p>
</li>
<li><p>深度学习 回归任务 高斯噪声</p>
</li>
<li><p>prediction uncertainty 在分类问题中，预测不确定性可以利用蒙特卡洛积分来近似</p>
</li>
<li><p>混合尺度高斯先验（scale mixture gaussian prior）</p>
</li>
<li><p>自动编码器</p>
<p>自动编码器的基本问题在于，它们将其输入转换成其编码矢量，其所在的潜在空间可能不连续，或者允许简单的插值。</p>
</li>
<li><p>变分自动编码器</p>
</li>
<li><p>变分推理variational inference <a href="[http://blog.rexking6.top/2019/05/30/%E5%8F%98%E5%88%86%E6%8E%A8%E7%90%86/](http://blog.rexking6.top/2019/05/30/变分推理/">变分推理</a>)   <a target="_blank" rel="noopener" href="https://www.zhihu.com/question/324099754/answer/696409097">变分推断 贝叶斯神经网络有什么论文可以推荐阅读吗？</a></p>
</li>
<li><p>残差</p>
<ul>
<li><p>普通残差：</p>
<p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/概念名词解析/image-20200806103226995.png" alt="image-20200806103226995"  /></p>
</li>
<li><p>残差图：估计观察或预测到的误差error(残差residuals)与随机误差(stochastic error)是否一致</p>
</li>
</ul>
</li>
<li><p><strong>减弱 错误标签 的影响</strong> <a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/110959020">PaperReading：Learning with Noisy Label-深度学习廉价落地</a></p>
</li>
<li><p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/65137250">利用不确定性来衡量多任务学习中的损失函数</a></p>
</li>
<li><p>高斯过程 <a target="_blank" rel="noopener" href="https://kivy-cn.github.io/Stanford-CS-229-CN/#/Markdown/cs229-gaussian_processes">CS229——Gaussian processes</a>       <a href="cs.cornell.edu/courses/cs4780/2018fa/lectures/lecturenote15.html">cornell——Lecture 15: Gaussian Processes</a>     <a target="_blank" rel="noopener" href="https://www.kesci.com/home/project/5d8da105037db3002d3a4c4a">高斯过程Gaussian Process教程</a>     <a target="_blank" rel="noopener" href="http://krasserm.github.io/2018/03/19/gaussian-processes/">krasserm blog——code contained</a></p>
<p><a target="_blank" rel="noopener" href="http://www.gaussianprocess.org/gpml/chapters/">Gaussian Processes for Machine Learning——book</a></p>
</li>
<li><p>深度高斯过程</p>
</li>
<li><p>点估计 区间估计 </p>
</li>
<li><p><a target="_blank" rel="noopener" href="https://www.cnblogs.com/hapjin/p/8834794.html">贝叶斯推断之最大后验概率(MAP)</a>     花书 19.3节</p>
</li>
<li><p>Epsilon greedy search </p>
</li>
<li><p>Confidence calibration 置信度校正    模型的校正度：</p>
<ul>
<li>校正的目的是 makes the confidence scores reflect true probabilities.</li>
<li>A simple way to visualize calibration is plotting accuracy as a function of confidence (known as a <strong><a target="_blank" rel="noopener" href="http://www.datascienceassn.org/sites/default/files/Predicting good probabilities with supervised learning.pdf">reliability diagram</a></strong>). </li>
<li>“On Calibration of Modern Neural Networks”</li>
</ul>
</li>
<li><p><a target="_blank" rel="noopener" href="https://stackoverflow.com/questions/41455101/what-is-the-meaning-of-the-word-logits-in-tensorflow">What is the meaning of the word logits in TensorFlow?</a>      logits    <a target="_blank" rel="noopener" href="https://datascience.stackexchange.com/questions/31041/what-does-logits-in-machine-learning-mean">What does Logits in machine learning mean?</a></p>
</li>
<li><p>Batch Normalization <a href="[http://www.huaxiaozhuan.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/chapters/4_optimization.html](http://www.huaxiaozhuan.com/深度学习/chapters/4_optimization.html">第十节——Batch Normalization</a>)</p>
</li>
<li><p>Isotonic Regression   <a href="[http://vividfree.github.io/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/2015/12/21/classifier-calibration-with-isotonic-regression](http://vividfree.github.io/机器学习/2015/12/21/classifier-calibration-with-isotonic-regression">使用 Isotonic Regression 校准分类器</a>)</p>
</li>
<li><p>共轭梯度法  <a href="[https://alkane0050.fun/2019/05/18/%E5%85%B1%E8%BD%AD%E6%A2%AF%E5%BA%A6%E6%B3%95%E5%88%9D%E6%AD%A5/](https://alkane0050.fun/2019/05/18/共轭梯度法初步/">共轭梯度法的简单分析</a>)</p>
</li>
<li><p>远程监督：主要是对知识库与非结构化文本对齐来自动构建大量训练数据，减少模型对人工标注数据的依赖，增强模型跨领域适应能力。但有  noise  problem </p>
<p><strong>基本假设：</strong>两个实体如果在知识库中存在某种关系，则包含该两个实体的非结构化句子均能表示出这种关系</p>
<p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/44772023">知识抽取-实体及关系抽取—DS</a></p>
</li>
<li><p>Knowledge Graph</p>
<ul>
<li><p>Entity-Centric Knowledge Graph</p>
<p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/概念名词解析/image-20200808170218438.png" alt="image-20200808170218438"></p>
<p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/概念名词解析/image-20200808170106351.png" alt="image-20200808170106351" style="zoom:80%;" /></p>
</li>
<li><p>Event-Centric Knowledge Graph</p>
<p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/概念名词解析/image-20200808170316162.png" alt="image-20200808170316162"></p>
</li>
<li></li>
</ul>
</li>
<li><p>事件提取  Event Extraction</p>
<p>定义： Identify the relation between $\color{red}{an event and an entity}$</p>
<p>Event定义：An event is defined as a specific occurrence involving participants</p>
<p>要找到Event trigger, Event Type, Event argument, Argument role</p>
<p>Event 一般与 trigger有紧密关系(Event Identification(TriggerWords))，且 trigger一般为 verb </p>
<p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/概念名词解析/image-20200808170633114.png" alt="image-20200808170633114"></p>
<p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/概念名词解析/image-20200808170527436.png" alt="image-20200808170527436"></p>
</li>
<li><p>开放域事件提取 Open Domain Event Extraction</p>
<ul>
<li><p><strong>Features  Representation</strong> </p>
<ul>
<li><p>Traditional Methods for Feature Representation</p>
<ul>
<li>Human designed features</li>
<li>Too much rely on imprecise NLP tools for feature extraction</li>
<li>Limitations for low-resources languages</li>
</ul>
</li>
<li><p>Dynamic CNN</p>
</li>
<li><p>Argument Attention(Event arguments) </p>
<p>arguments 识别对Event Detection有很大帮助</p>
<p>If we consider the argument phrase “former protege” (Role=Position), we will have more confidence to predict it as an End-·ition event</p>
<ul>
<li>从 contextual words 和 entities 的信息找 arguments—— context representation learning(CRL) 学到 contextual words 和 entities的representation(embedding或是其它)，与对应的attention $\alpha$ 内积</li>
</ul>
</li>
</ul>
</li>
<li><p>Training Data Generation</p>
<ul>
<li><p>External Resources</p>
<ul>
<li><p>Employing <strong>FrameNet</strong>( semantic role descriptions in FrameNet, VerbNet (Kipper etal., 2008) and Propbank (Palmer et al., 2005).) <a target="_blank" rel="noopener" href="https://blog.csdn.net/qq_36771895/article/details/91355166">FrameNet &amp; FrameNet Python API </a></p>
<p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/概念名词解析/image-20200813154936884.png" alt="image-20200813154936884" style="zoom:80%;" /></p>
<p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/概念名词解析/image-20200809095354724.png" alt="image-20200809095354724"></p>
<p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/概念名词解析/image-20200809110609620.png" alt="image-20200809110609620"></p>
<p><strong>How to generate training data in FrameNet</strong></p>
<ul>
<li><p>方法1 [Open Domain Event Extraction from Texts]<img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/概念名词解析/image-20200809101143166.png" alt="image-20200809101143166"></p>
<p>对生成数据准确度的评价</p>
<p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/概念名词解析/image-20200809101547986.png" alt="image-20200809101547986"></p>
</li>
<li></li>
</ul>
</li>
<li><p>Employing <strong>Freebase</strong> 2016年，谷歌宣布将Freebase的数据和API服务都迁移至Wikidata，并正式关闭了Freebase  <a target="_blank" rel="noopener" href="https://developer.aliyun.com/article/717320">知识图谱调研-Freebase</a></p>
</li>
</ul>
</li>
<li><p>Generating Labeled Data from <strong>Structured KB</strong></p>
<ul>
<li><p>Distant Supervision(Weak) Supervision in <strong>Relation Extraction</strong>($\color{red}{doesn’t}$ work for Event Extraction)</p>
<p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/概念名词解析/image-20200809101755184.png" alt="image-20200809101755184"></p>
<p><code>Automatically Labeled Data Generation for Large Scale Event Extraction</code>文中对Freebase 的介绍</p>
<p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/概念名词解析/image-20200813153441759.png" alt="image-20200813153441759" style="zoom:80%;" /></p>
</li>
<li><p><strong>Triggers</strong> are not given out in existing knowledge bases 所以没法直接用existing  <strong>Structured KB</strong></p>
<p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/概念名词解析/image-20200809103434298.png" alt="image-20200809103434298"></p>
<p>所以可以根据<strong>Structured KB</strong>中的 Key Arguments label back，依据假设提取Trigger：</p>
<ol>
<li><p>Event <strong>Trigger Words Extraction</strong></p>
<p>假设：The sentences mention <strong>all arguments denote such events</strong></p>
</li>
<li><p>Argument Extraction/Role Identification</p>
<p>根据 Trigger words and Entities</p>
<p>语言学上的规律：Arguments for a specific event instance are usually mentioned in multiple sentences，<strong>Only 0.02% of instances can find all argument mentions in one sentence</strong></p>
</li>
</ol>
</li>
<li><p>method</p>
<ol>
<li><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/概念名词解析/image-20200809110639296.png" alt="image-20200809110639296"></li>
</ol>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li><p>关系抽取 Relation Extraction</p>
<p>定义： Identify the relation between $\color{}{}$ $\color{red}{two given entities}$</p>
<p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/概念名词解析/image-20200808171310420.png" alt="image-20200808171310420"></p>
<p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/44772023">实体及关系抽取</a></p>
<p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/50903358">事件抽取</a></p>
</li>
<li><p>Event Extraction(EE) 事件提取</p>
<p><a href="[https://chriszhangcx.github.io/%E5%A6%82%E4%BD%95%E7%8C%9C%E5%87%BA%E5%A5%B3%E6%9C%8B%E5%8F%8B%E8%AF%9D%E4%B8%AD%E7%9A%84%E5%90%AB%E4%B9%89%EF%BC%9F%E2%80%94%E2%80%94%E5%85%B3%E4%BA%8E%E4%BA%8B%E4%BB%B6%E6%8A%BD%E5%8F%96-Event-Extraction/#fn_%E5%8D%9A%E5%AE%A2](https://chriszhangcx.github.io/如何猜出女朋友话中的含义？——关于事件抽取-Event-Extraction/#fn_博客">reference1—chriszhangcx blog</a>) and <a target="_blank" rel="noopener" href="http://www.caojiarun.com/2019/11/Introduction-of-Event-Extraction/">2—Introduction of Event Extraction</a></p>
<p><a target="_blank" rel="noopener" href="https://pdfs.semanticscholar.org/0eef/643c744ac3e4ffd68d4328b5f445dbf9e10e.pdf">A Survey of Open Domain Event Extraction</a></p>
<p><a target="_blank" rel="noopener" href="https://chriszhangcx.github.io/如何猜出女朋友话中的含义？——关于事件抽取-Event-Extraction/">事件抽取(Event Extraction)经典模型</a></p>
</li>
<li><p>POS tagged pos标记<a target="_blank" rel="noopener" href="https://www.tutorialspoint.com/natural_language_processing/natural_language_processing_part_of_speech_tagging.htm">Part of Speech (PoS) Tagging</a></p>
<ul>
<li>概率方法 (CRF GMM) <a target="_blank" rel="noopener" href="https://medium.com/analytics-vidhya/pos-tagging-using-conditional-random-fields-92077e5eaa31">Identifying Part of Speech Tags using Conditional Random Fields</a></li>
</ul>
</li>
<li><p>ACE Corpus：ACE2005: 529 Training, 33 Development, 40 Testing</p>
</li>
<li><p>NLTK <a target="_blank" rel="noopener" href="https://www.nltk.org/">Natural Language Toolkit3.5</a></p>
</li>
<li><p>[Attention Mechanism](<a target="_blank" rel="noopener" href="https://blog.floydhub.com/attention-mechanism">https://blog.floydhub.com/attention-mechanism</a></p>
</li>
<li><p>截断梯度法  <a target="_blank" rel="noopener" href="https://zr9558.com/2016/01/12/truncated-gradient/">TRUNCATED GRADIENT </a></p>
</li>
<li><p>burn-in (Gibbs sampling) <a target="_blank" rel="noopener" href="http://users.stat.umn.edu/~geyer/mcmc/burn.html">Burn-In is Unnecessary</a></p>
</li>
<li><p>LDA 主题模型 <a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/31470216">一文详解LDA主题模型</a></p>
</li>
<li><p><a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/G-test">G-test</a></p>
</li>
<li><p>共指和指代消解 <a href="[https://looperxx.github.io/CS224n-2019-16-Coreference%20Resolution/](https://looperxx.github.io/CS224n-2019-16-Coreference Resolution/">Coreference Resolution</a>)</p>
</li>
<li><p>semantic role labeling representation(SRL) <a target="_blank" rel="noopener" href="https://web.stanford.edu/~jurafsky/slp3/20.pdf">Semantic    Role    Labeling</a></p>
<p> meaning  representations：Abstract  Meaning  Representation  (AMR)、Stanford  Typed  Dependencies 、FrameNet  <a target="_blank" rel="noopener" href="https://towardsdatascience.com/meaning-representation-and-srl-assuming-there-is-some-meaning-741f35bfdd6">Meaning Representation and SRL: assuming there is some meaning</a></p>
<p><strong><a target="_blank" rel="noopener" href="http://people.cs.georgetown.edu/nschneid/cosc672/s17/amr-papers.html">Advanced Semantic Representation</a></strong></p>
<p><strong><a target="_blank" rel="noopener" href="https://github.com/nschneid/amr-tutorial/">AMR Tutorial</a></strong></p>
<p><a target="_blank" rel="noopener" href="https://github.com/amrisi/amr-guidelines/blob/master/amr.md">Abstract Meaning Representation (AMR) 1.2Specification</a></p>
</li>
<li><p><a target="_blank" rel="noopener" href="http://blog.openkg.cn/%E7%BB%BC%E8%BF%B0-%E4%BA%8B%E4%BB%B6%E6%8A%BD%E5%8F%96%E5%8F%8A%E6%8E%A8%E7%90%86-%E4%B8%8A/">综述 | 事件抽取及推理 (上)</a></p>
</li>
<li><p>word sense 词的意思<a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Word_sense">Word sense</a></p>
</li>
<li><p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/109122090">NLP的任务</a></p>
</li>
<li><p>Word2Vec — <a href="[http://www.huaxiaozhuan.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/chapters/8_word_representation.html](http://www.huaxiaozhuan.com/深度学习/chapters/8_word_representation.html">Skip-Gram</a>) and CBOW </p>
</li>
<li><p>WordNet sense 到 <a target="_blank" rel="noopener" href="https://catalog.ldc.upenn.edu/LDC2013T19">OntoNotes sense</a>的 mapping tool </p>
</li>
<li><p><a target="_blank" rel="noopener" href="http://clear.colorado.edu/compsem/index.php?page=lexicalresources&amp;sub=ontonotes">Ontonotes Sense Groups</a></p>
</li>
<li><p>分布语义，Distributional Semantic Representation，基于分布假设：<em>linguistic items with similar distributions have similar meanings.</em></p>
</li>
<li><p>GRU   <a target="_blank" rel="noopener" href="https://zh.d2l.ai/chapter_recurrent-neural-networks/gru.html">动手深度学习GRU</a></p>
</li>
<li><p>DAG有向无环图：</p>
</li>
<li><p>syntactic parsing语法分析:</p>
<ul>
<li>短语结构树(phrase structure tree 对应语法 context-free grammar CFG 上下文无关法)</li>
<li>依存句法树(dependency parse tree)： 直观来讲，依存句法分析识别句子中的“主谓宾”、“定状补”这些语法成分，并分析各语法成分之间的关系。</li>
</ul>
</li>
<li><p>语义依存分析 (Semantic Dependency Parsing, SDP)：分析句子各个语言单位之间的语义关联，并将语义关联以依存结构呈现</p>
<p><a target="_blank" rel="noopener" href="https://my.oschina.net/duanvincent/blog/761108">依存句法分析与语义依存分析的区别</a></p>
<p><a target="_blank" rel="noopener" href="https://blog.csdn.net/glory1234work2115/article/details/54906343">Stanford-parser依存句法关系解释</a></p>
</li>
<li><p>Distributional Representation和Distributed Representation <a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/22386230">聊聊文本的分布式表示—邱锡鹏</a></p>
</li>
<li><p><strong>ACE2005:</strong> </p>
<p>ACE2005定义的事件抽取是：(1) 以句子级为单位，识别句子中出现的trigger词及类型，(2) 针对每个trigger词，判断其的论元argument以及论元类型。下图即是ACE2005任务的一个示例。</p>
</li>
<li><p>RNN及变体和BPTT <a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/27485750">RNN 其常见架构</a></p>
</li>
<li><p>dependency parsing <a target="_blank" rel="noopener" href="https://looperxx.github.io/CS224n-2019-05-Linguistic Structure Dependency Parsing/">笔记1</a>  <a target="_blank" rel="noopener" href="https://www.hankcs.com/nlp/cs224n-dependency-parsing.html">笔记2</a>  <a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/66268929">笔记3</a></p>
</li>
<li><p>bootstrapping 自助法</p>
</li>
<li><p>ELMo  <a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/38254332">ELMo最好用词向量Deep Contextualized Word Representations</a></p>
</li>
<li><p><a target="_blank" rel="noopener" href="https://gombru.github.io/2019/04/03/ranking_loss/">Understanding Ranking Loss, Contrastive Loss, Margin Loss, Triplet Loss, Hinge Loss and all those confusing names</a></p>
</li>
<li><p><strong>Multi-instance Learning (MIL)</strong> 多实例学习</p>
<p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/40812750">知乎参考1</a></p>
<p><a target="_blank" rel="noopener" href="http://www.lamda.nju.edu.cn/CH.Data.ashx?AspxAutoDetectCookieSupport=1#code">南大周志华教授 miVLAD and miFV,</a></p>
</li>
<li><p>Snorkel - 基于弱监督学习的数据标注工具</p>
<p>snorkel <a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/55138499">Sonrkel—从0开始构建机器学习项目</a></p>
<p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/78699409">reference1</a></p>
<p>可以视为弱监督源的示例包括：</p>
<ul>
<li>领域启发式搜索，例如：常见模式、经验法则等</li>
<li>已有的正确标注的数据，虽然不完全适用于当前的任务，但有一定的作用。这在传统上被称为远程监督</li>
<li>不可靠的非专家标注人，例如：众包标注</li>
</ul>
<p>标准函数中编码了领域相关的推理规则，可以使用入正则表达式、经验规则等常见的模式进行标注。这样生成的标注是包含噪声的，并且可能彼此冲突。</p>
<p>常见类型的标注函数：</p>
<ul>
<li>硬编码的推导：通常使用正则表达式</li>
<li>语义结构：例如，使用<a href="https://link.zhihu.com/?target=http%3A//sc.hubwiz.com/codebag/zh-spacy-model/">spacy</a>得到的依存关系结构</li>
<li>远程监督：例如使用外部的知识库</li>
<li>有噪声人工标注：例如众包标注</li>
<li>外部模型：其他可以给出有用标注信号的模型</li>
</ul>
<p>当编写好标注函数后，Snorkel将利用这些不同的标注函数之间的冲突训练一个<strong>标注模型（Label Model）</strong>来估算不同标注函数的标注准确度。通过观察标注函数之间的彼此一致性，标注模型能够学习到每个监督源的准确度。</p>
<p>例如，如果一个标注函数的标注结果总是得到其他标注函数的认可，那么这个标注函数将有一个高准确率，而如果一个标注函数总是与其他标注函数的结果不一致，那么这个标注函数将得到一个较低的准确率。通过整合所有的标注函数的投票结果（以其估算准确度作为权重），我们就可以为每个数据样本<strong>分配一个包含噪声的标注（0~1之间）</strong>，而不是一个硬标注（要么0，要么1）。</p>
<p>接下来，当标注一个新的数据点时，每一个标注函数都会对分类进行投票：正、负或弃权。基于这些投票以及标注函数的估算精度，标注模型能够程序化到为上百万的数据点给出概率性标注。最终的目标是训练出一个可以超越标注函数的泛化能力的分类器.通过这种方法得到海量的低质量监督，然后使用统计技术处理有噪标注，我们可以训练出高质量的模型。</p>
<p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/55138499">参考—Sonrkel—从0开始构建机器学习项目（完善中）</a></p>
<p>sample_and_sgd函数:    (计算在某一分布下的期望时，用蒙特卡洛积分近似， 去掉极限可以看成是采样点的均值)</p>
<p><img src="https://www.zhihu.com/equation?tex=%5Ctheta_j%5E%7B%28t%29%7D%3D%5Ctheta_j%5E%7B%28t-1%29%7D-%5Calpha%5Csum_%7Bk%3D1%7D%5E%7BN%7D%5Cleft%5C%7B+%5Cleft%5B+%5Cphi_j%28%5Chat%5Clambda_%7Bij%7D%5E%7B%28k%29%7D%2C+%5Chat+y_i%5E%7B%28k%29%7D%29+%5Cright%5D_%7B%7B%5Chat%5CLambda_i%5E%7B%28k%29%7D%2C+%5Chat+y_i%5E%7B%28k%29%7D+%5Csim+P%28%5CLambda_i%2C+y_i%29%7D%7D+-%5Cleft%5B+%5Cphi_j%28%5Clambda_%7Bij%7D%2C+%5Chat+y_i%5E%7B%28k%29%7D%29+%5Cright%5D_%7B%5Chat+y_i%5E%7B%28k%29%7D+%5Csim+P%28y_i%7C%5CLambda_i%29%7D+%5Cright%5C%7D" alt="[公式]"></p>
<p>为了获得指定分布的样本点，我们需要进行采样。对于高维的联合分布，我们通常使用Gibbs采样算法</p>
</li>
<li><p>Gibbs采样算法  <a target="_blank" rel="noopener" href="http://nitro.biosci.arizona.edu/courses/EEB596/handouts/Gibbs.pdf">Gibbs采样的原理</a></p>
</li>
<li><p>PGM 概率图模型 </p>
<p><a href="https://link.zhihu.com/?target=http%3A//www.isiweb.ee.ethz.ch/papers/arch/aloe-2004-spmagffg.pdf">An Introduction to Factor Graphs</a></p>
<p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/55138499">Snorkel、PGM and sampling、SGD相关论文</a></p>
</li>
<li><p><a target="_blank" rel="noopener" href="https://www.cs.toronto.edu/~radford/csc2506/factor.pdf">Factor Graphs and the Sum-Product Algorithm</a></p>
</li>
<li><p>结构学习 structure learning   </p>
<p>贝叶斯网路的学习包括：参数学习、<a target="_blank" rel="noopener" href="http://www.huaxiaozhuan.com/统计学习/chapters/16_CRF.html">结构学习</a></p>
<p>李宏毅 4 episode <a target="_blank" rel="noopener" href="https://www.youtube.com/watch?v=5OYu0vxXEv8&amp;t=16s">Structured Learning 1: Introduction</a></p>
</li>
<li><p>半监督 <a target="_blank" rel="noopener" href="https://www.youtube.com/watch?v=fX_guE7JNnY&amp;list=PLJV_el3uVTsPy9oCRY30oBPNLCo89yu49&amp;index=21">ML Lecture 12: Semi-supervised</a></p>
</li>
<li><p>利用生成模型从噪声标签源合成标签：</p>
</li>
<li><p>玻尔兹曼机 RBM</p>
<p><a target="_blank" rel="noopener" href="https://www.cnblogs.com/pinard/p/6530523.html">受限玻尔兹曼机（RBM）原理总结</a></p>
</li>
<li><p>命名实体 NER  <a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/135453456">命名实体识别 NER 论文综述</a></p>
</li>
<li><p>Highway Networks  <a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/38130339">Highway Networks及HBilstm Network</a></p>
</li>
<li><p>entity  span  detection：找出 文本中指向同一实体的所有文段，这是因为，人们对同一个实体往往有多种不同的说法，如代词、省略词、别名等等。 <a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/126544790">reference—基于span prediction的共指消解模型</a></p>
<p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/概念名词解析/image-20200816172814181.png" alt="image-20200816172814181" style="zoom:80%;" /></p>
</li>
<li><p><a target="_blank" rel="noopener" href="https://www.zhihu.com/question/62399257">如何理解LSTM后接CRF？</a></p>
<p><a target="_blank" rel="noopener" href="https://www.zhihu.com/question/46688107">CRF和LSTM 模型在序列标注上的优劣？</a></p>
</li>
<li><p>Viterbi(维特比算法)<a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/59889195">HMM+Viterbi(维特比算法)+最短路径分析</a></p>
</li>
<li><p>知识图谱上的<strong>实体消歧</strong>  <a target="_blank" rel="noopener" href="http://kugwzk.info/index.php/archives/3204">一些关于NER任务调研的小思考</a></p>
</li>
<li><p>实体词典：entity dictionary</p>
</li>
<li><p><strong>What are Chunks ?</strong><br>Chunks are made up of words and the kinds of words are defined using the part-of-speech tags. One can even define a pattern or words that can’t be a part of chuck and such words are known as chinks.</p>
<p><strong>What are IOB tags ?</strong><br>It is a format for chunks. These tags are similar to part-of-speech tags but provide can denote the inside, utside, and the beginning of a chunk. Not just noun phrase but multiple different chunk phrase types are allowed here.</p>
<p><a target="_blank" rel="noopener" href="https://www.geeksforgeeks.org/nlp-iob-tags/">code</a></p>
<p><a target="_blank" rel="noopener" href="https://www.nltk.org/book/ch07.html">7. Extracting Information from Text—nltk</a></p>
</li>
<li><p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/38163970">Karush-Kuhn-Tucker (KKT)条件</a></p>
</li>
<li><p><a target="_blank" rel="noopener" href="http://faculty.marshall.usc.edu/gareth-james/ISL/">An Introduction to Statistical Learning with Applications in R</a></p>
</li>
<li><p><a target="_blank" rel="noopener" href="https://link.springer.com/referenceworkentry/10.1007%2F978-0-387-30164-8_140">collective classification</a>  <em>jointly</em> determine the correct label assignments of all the objects in the network.</p>
</li>
<li><p><a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Ontology_alignment">ontology alignment</a> 本体对齐</p>
</li>
<li><p><a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Personalized_medicine">personalized medicine</a> 个性化医学</p>
</li>
<li><p><a target="_blank" rel="noopener" href="https://link.springer.com/referenceworkentry/10.1007%2F978-1-4939-7131-2_379">opinion diffusion</a> 意见传播</p>
</li>
<li><p>trust in social networksolollllllllllllllllllll+</p>
</li>
<li><p><a target="_blank" rel="noopener" href="https://www.jianshu.com/p/24fcf19b78da">graph summarization</a></p>
</li>
<li><p><a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/T-norm">t-norm</a>:    t-norm is a binary algebraic operation on the interval [0, 1],  三角范数，用于模糊逻辑</p>
</li>
<li><p><a target="_blank" rel="noopener" href="https://blog.csdn.net/jbb0523/article/details/79437497"> MPE inference</a> 贝叶斯网络与最大可能解释(MPE)问题 MostProbable Explanation, MPE</p>
</li>
<li><p>共识优化  <a target="_blank" rel="noopener" href="https://www.cvxpy.org/examples/applications/consensus_opt.html">consensus optimization </a></p>
</li>
<li><p><strong>knowledge distillation知识蒸馏：</strong> <a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/51563760">知乎1</a>,  <a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/53864403">知乎2</a>,  <a target="_blank" rel="noopener" href="https://github.com/lhyfst/knowledge-distillation-papers">paper reading list</a></p>
</li>
<li><p>后验正则化（posterior regularization）方法</p>
</li>
<li><p>K-dimensional  probability  simplex</p>
<p><img src="https://raw.githubusercontent.com/JasonGuojz/JasonGuojz.github.io/master/images/概念名词解析/3987bf963ef4ab9a7920cbb1d57056c3" alt="img"></p>
</li>
<li><p>max-over-time 池化层，NLP中的CNN:  <a target="_blank" rel="noopener" href="https://blog.csdn.net/malefactor/article/details/51078135">参考1cnblog</a>  <a target="_blank" rel="noopener" href="https://stackoverflow.com/questions/48549670/pooling-vs-pooling-over-time">Pooling vs Pooling-over-time</a></p>
</li>
<li><p><a target="_blank" rel="noopener" href="http://www.gabormelli.com/RKB/Bidirectional_LSTM-CNN_(BLSTM-CNN">Bidirectional LSTM-CNN (BLSTM-CNN) Training System</a>_Training_System)</p>
</li>
<li><p>projected gradient descent (PGD)投影梯度下降 </p>
<p><a target="_blank" rel="noopener" href="https://medium.com/數學-人工智慧與蟒蛇/投影梯度下降法解正則化問題-以lasso回歸為例-6fc70e4efe65">投影梯度下降法解正则化问题：以Lasso回归为例</a></p>
<p><a target="_blank" rel="noopener" href="http://maths.nju.edu.cn/~hebma/New-VS/SF10C-PG.pdf">Professor Bingsheng He—基于梯度投影的凸优化收缩算法和下降算法</a></p>
</li>
<li><p>利普西茨条件 </p>
<p><a target="_blank" rel="noopener" href="https://math.berkeley.edu/~mgu/MA128ASpring2017/MA128ALectureWeek9.pdf">Lipschitz condition - Berkeley Math</a></p>
<p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/27554191">非凸优化基石：Lipschitz Condition - 知乎</a></p>
<p><a target="_blank" rel="noopener" href="https://mathcs.holycross.edu/~spl/old_courses/304_fall_2008/handouts/existunique.pdf">Existence and Uniqueness 1 Lipschitz Conditions</a></p>
</li>
<li><p><a target="_blank" rel="noopener" href="https://bindog.github.io/blog/2018/02/10/model-explanation/">CAM 和 Grad-CAM</a></p>
<p>热力图？Class Activation Mapping</p>
</li>
</ol>
<h4 id="相关论文"><a href="#相关论文" class="headerlink" title="相关论文"></a><strong>相关论文</strong></h4><ol>
<li>Joint event extraction via recurrent neural networks <a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/63215208">论文解读</a></li>
<li><a target="_blank" rel="noopener" href="https://www.cnblogs.com/kisetsu/p/11906681.html">【论文笔记】Graph Convolutional Networks with Argument-Aware Pooling for Event Detection</a>      <a target="_blank" rel="noopener" href="https://www.codenong.com/cs105391780/">笔记2</a></li>
<li>Jointly Extracting Event Triggers and Arguments by Dependency-Bridge RNN and Tensor-Based Argument Interaction   <a target="_blank" rel="noopener" href="https://www.jianshu.com/p/9030d25215e3">笔记1</a>   <a target="_blank" rel="noopener" href="https://blog.csdn.net/JYZ4MFC/article/details/83309135">笔记2</a></li>
</ol>

    </div>

    
    
    
        

<div>
<ul class="post-copyright">
  <li class="post-copyright-author">
    <strong>Post author:  </strong>guo jiazhen
  </li>
  <li class="post-copyright-link">
    <strong>Post link: </strong>
    <a href="https://jasonguojz.github.io/blog/2020/07/10/%E6%A6%82%E5%BF%B5%E5%90%8D%E8%AF%8D%E8%A7%A3%E6%9E%90/" title="概念名词解析">https://jasonguojz.github.io/blog/2020/07/10/概念名词解析/</a>
  </li>
  <li class="post-copyright-license">
    <strong>Copyright Notice:  </strong>All articles in this blog are licensed under <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" rel="noopener" target="_blank"><i class="fa fa-fw fa-creative-commons"></i>BY-NC-SA</a> unless stating additionally.
  </li>
</ul>
</div>


      <footer class="post-footer">

        


        
    <div class="post-nav">
      <div class="post-nav-item"></div>
      <div class="post-nav-item">
    <a href="/blog/2020/07/11/Open%20Domain%20Event%20Extraction%20from%20Twitter/" rel="next" title="Open Domain Event Extraction from Twitter">
      Open Domain Event Extraction from Twitter <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  



          </div>
          
    <div class="comments" id="valine-comments"></div>

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E7%9B%B8%E5%85%B3%E8%AE%BA%E6%96%87"><span class="nav-number">1.</span> <span class="nav-text">相关论文</span></a></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name"></p>
  <div class="site-description" itemprop="description">谦卑</div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/blog/archives/">
        
          <span class="site-state-item-count">25</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/blog/categories/">
          
        <span class="site-state-item-count">30</span>
        <span class="site-state-item-name">categories</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/blog/tags/">
          
        <span class="site-state-item-count">79</span>
        <span class="site-state-item-name">tags</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
        <a href="https://github.com/JasonGuojz" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;JasonGuojz" rel="noopener" target="_blank"><i class="fa fa-fw fa-github"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="/blog/jzguovulcan@gmail.com" title="E-Mail → jzguovulcan@gmail.com"><i class="fa fa-fw fa-envelope"></i>E-Mail</a>
      </span>
      <span class="links-of-author-item">
        <a href="skype:1142346305?call|chat" title="Skype → skype:1142346305?call|chat" rel="noopener" target="_blank"><i class="fa fa-fw fa-skype"></i>Skype</a>
      </span>
  </div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2020</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder"></span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-area-chart"></i>
    </span>
    <span title="Symbols count total">192k</span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-coffee"></i>
    </span>
    <span title="Reading time total">2:54</span>
</div>
  <div class="powered-by">Powered by <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://muse.theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Muse</a>
  </div>

        








      </div>
    </footer>
  </div>

  
  <script src="/blog/lib/anime.min.js"></script>
  <script src="/blog/lib/velocity/velocity.min.js"></script>
  <script src="/blog/lib/velocity/velocity.ui.min.js"></script>

<script src="/blog/js/utils.js"></script>

<script src="/blog/js/motion.js"></script>


<script src="/blog/js/schemes/muse.js"></script>


<script src="/blog/js/next-boot.js"></script>




  




  
<script src="/blog/js/local-search.js"></script>













  

  
      

<script>
  if (typeof MathJax === 'undefined') {
    window.MathJax = {
      loader: {
          load: ['[tex]/mhchem'],
        source: {
          '[tex]/amsCd': '[tex]/amscd',
          '[tex]/AMScd': '[tex]/amscd'
        }
      },
      tex: {
        inlineMath: {'[+]': [['$', '$']]},
          packages: {'[+]': ['mhchem']},
        tags: 'ams'
      },
      options: {
        renderActions: {
          findScript: [10, doc => {
            document.querySelectorAll('script[type^="math/tex"]').forEach(node => {
              const display = !!node.type.match(/; *mode=display/);
              const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
              const text = document.createTextNode('');
              node.parentNode.replaceChild(text, node);
              math.start = {node: text, delim: '', n: 0};
              math.end = {node: text, delim: '', n: 0};
              doc.math.push(math);
            });
          }, '', false],
          insertedScript: [200, () => {
            document.querySelectorAll('mjx-container').forEach(node => {
              let target = node.parentNode;
              if (target.nodeName.toLowerCase() === 'li') {
                target.parentNode.classList.add('has-jax');
              }
            });
          }, '', false]
        }
      }
    };
    (function () {
      var script = document.createElement('script');
      script.src = '//cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js';
      script.defer = true;
      document.head.appendChild(script);
    })();
  } else {
    MathJax.startup.document.state(0);
    MathJax.texReset();
    MathJax.typeset();
  }
</script>

    

  


<script>
NexT.utils.loadComments(document.querySelector('#valine-comments'), () => {
  NexT.utils.getScript('//cdn.jsdelivr.net/npm/valine@1/dist/Valine.min.js', () => {
    var GUEST = ['nick', 'mail', 'link'];
    var guest = 'nick,mail,link';
    guest = guest.split(',').filter(item => {
      return GUEST.includes(item);
    });
    new Valine({
      el         : '#valine-comments',
      verify     : false,
      notify     : false,
      appId      : '2M2aiiBff85KzN3JvTFsCV2J-9Nh9j0Va',
      appKey     : '7n1fFOWyaLnTBNpNjRhYsF0W',
      placeholder: "Please write your comments here",
      avatar     : 'mm',
      meta       : guest,
      pageSize   : '10' || 10,
      visitor    : true,
      lang       : 'zh-cn' || 'zh-cn',
      path       : location.pathname,
      recordIP   : false,
      serverURLs : ''
    });
  }, window.Valine);
});
</script><!-- hexo-inject:begin --><!-- hexo-inject:end -->

</body>
</html>
